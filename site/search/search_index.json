{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Home","text":"<p>SingleCellNet predicts the cell type of query scRNA-seq data by Random forest multi-class classification. See Tan 2019 for more details. It was originally written in R. PySingleCellNet (PySCN) is the Python version, and it is compatible with Scanpy. PySCN was crafted to aid in the analysis of engineered cell populations (i.e. cells derived via directed differentiation of pluripotent stem cells or via direct conversion), but can just as easily be used to perform cell typing on data dervived from other sources as long as adequate training data is available.</p> PySCN returns both cell type label predictions, and it annotates those predictions as either 'Singular', 'Intermediate', 'Hybrid', 'None', or 'Random'."},{"location":"classifier.html","title":"classifier functions","text":"<p>Functions that create or require the classifier <code>clf</code> object.</p>"},{"location":"classifier.html#pySingleCellNet.classify.categorize_classification","title":"categorize_classification","text":"<pre><code>categorize_classification(adata_c, thresholds, graph=None, k=3, columns_to_ignore=['rand'], inplace=True, class_obs_name='SCN_class_argmax')\n</code></pre> <p>Classify cells based on SCN scores and thresholds, then categorize  multi-class cells as either 'Intermediate' or 'Hybrid'.</p> Classification rules <ul> <li>If exactly one cell type exceeds threshold: \"Singular\"</li> <li>If zero cell types exceed threshold: \"None\"</li> <li>If more than one cell type exceeds threshold:<ul> <li>If all pairs of high-scoring cell types are within <code>k</code> edges    in the provided graph: \"Intermediate\"</li> <li>Otherwise: \"Hybrid\"</li> </ul> </li> <li>If predicted cell type is 'rand': Set classification to \"Rand\"</li> </ul> <p>Parameters:</p> <ul> <li> <code>adata_c</code>               (<code>AnnData</code>)           \u2013            <p>Annotated data matrix containing: - <code>.obsm[\"SCN_score\"]</code>: DataFrame of SCN scores for each cell type. - <code>.obs[class_obs_name]</code>: Predicted cell type (argmax classification).</p> </li> <li> <code>thresholds</code>               (<code>DataFrame</code>)           \u2013            <p>Thresholds for each cell type. Expected to  match the columns in <code>SCN_score</code>.</p> </li> <li> <code>graph</code>               (<code>Graph</code>, default:                   <code>None</code> )           \u2013            <p>An iGraph describing relationships between cell types.  Must have vertex names matching the cell-type columns in SCN_score.</p> </li> <li> <code>k</code>               (<code>int</code>, default:                   <code>3</code> )           \u2013            <p>Maximum graph distance to consider cell types \"Intermediate\". Defaults to 3.</p> </li> <li> <code>columns_to_ignore</code>               (<code>list</code>, default:                   <code>['rand']</code> )           \u2013            <p>List of SCN score columns to ignore. Defaults to [\"rand\"].</p> </li> <li> <code>inplace</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If True, modify <code>adata_c</code> in place. Otherwise, return a new AnnData object. Defaults to True.</p> </li> <li> <code>class_obs_name</code>               (<code>str</code>, default:                   <code>'SCN_class_argmax'</code> )           \u2013            <p>The name of the <code>.obs</code> column with argmax classification. Defaults to 'SCN_class_argmax'.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If <code>graph</code> is None.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If \"SCN_score\" is missing in <code>adata_c.obsm</code>.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If <code>class_obs_name</code> is not found in <code>adata_c.obs</code>.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If the provided graph does not have vertex \"name\" attributes.</p> </li> </ul> <p>Returns:</p> <ul> <li>           \u2013            <p>AnnData or None: Returns modified AnnData if <code>inplace</code> is False, otherwise None.</p> </li> </ul> Source code in <code>src/pySingleCellNet/classify/categorize.py</code> <pre><code>def categorize_classification(\n    adata_c: AnnData,\n    thresholds: pd.DataFrame,\n    graph: ig.Graph = None,\n    k: int = 3,\n    columns_to_ignore: list = [\"rand\"],\n    inplace: bool = True,\n    class_obs_name: str = 'SCN_class_argmax'\n):\n    \"\"\"Classify cells based on SCN scores and thresholds, then categorize \n    multi-class cells as either 'Intermediate' or 'Hybrid'.\n\n    Classification rules:\n      - If exactly one cell type exceeds threshold: \"Singular\"\n      - If zero cell types exceed threshold: \"None\"\n      - If more than one cell type exceeds threshold:\n          * If all pairs of high-scoring cell types are within `k` edges \n            in the provided graph: \"Intermediate\"\n          * Otherwise: \"Hybrid\"\n      - If predicted cell type is 'rand': Set classification to \"Rand\"\n\n    Args:\n        adata_c (AnnData): Annotated data matrix containing:\n            - `.obsm[\"SCN_score\"]`: DataFrame of SCN scores for each cell type.\n            - `.obs[class_obs_name]`: Predicted cell type (argmax classification).\n        thresholds (pd.DataFrame): Thresholds for each cell type. Expected to \n            match the columns in `SCN_score`.\n        graph (ig.Graph): An iGraph describing relationships between cell types. \n            Must have vertex names matching the cell-type columns in SCN_score.\n        k (int, optional): Maximum graph distance to consider cell types \"Intermediate\". Defaults to 3.\n        columns_to_ignore (list, optional): List of SCN score columns to ignore. Defaults to [\"rand\"].\n        inplace (bool, optional): If True, modify `adata_c` in place. Otherwise, return a new AnnData object. Defaults to True.\n        class_obs_name (str, optional): The name of the `.obs` column with argmax classification. Defaults to 'SCN_class_argmax'.\n\n    Raises:\n        ValueError: If `graph` is None.\n        ValueError: If \"SCN_score\" is missing in `adata_c.obsm`.\n        ValueError: If `class_obs_name` is not found in `adata_c.obs`.\n        ValueError: If the provided graph does not have vertex \"name\" attributes.\n\n    Returns:\n        AnnData or None: Returns modified AnnData if `inplace` is False, otherwise None.\n    \"\"\"\n    if graph is None:\n        raise ValueError(\"A valid iGraph 'graph' must be provided. None was given.\")\n\n    if \"SCN_score\" not in adata_c.obsm:\n        raise ValueError(\"No 'SCN_score' in adata_c.obsm. Please provide SCN scores.\")\n\n    SCN_scores = adata_c.obsm[\"SCN_score\"].copy()\n    SCN_scores.drop(columns=columns_to_ignore, inplace=True, errors='ignore')\n\n    exceeded = SCN_scores.sub(thresholds.squeeze(), axis=1) &gt; 0\n    true_counts = exceeded.sum(axis=1)\n\n    result_list = [\n        [col for col in exceeded.columns[exceeded.iloc[row].values]]\n        for row in range(exceeded.shape[0])\n    ]\n\n    class_type = pd.Series([\"None\"] * len(true_counts), index=true_counts.index, name=\"SCN_class_type\")\n\n    singular_mask = (true_counts == 1)\n    class_type.loc[singular_mask] = \"Singular\"\n\n    if \"name\" in graph.vs.attributes():\n        type2index = {graph.vs[i][\"name\"]: i for i in range(graph.vcount())}\n    else:\n        raise ValueError(\"graph does not have a 'name' attribute for vertices.\")\n\n    def is_all_within_k_edges(cell_types):\n        \"\"\"Check if all pairs of cell types are within k edges in the graph.\n\n        Args:\n            cell_types (list): List of cell type names.\n\n        Returns:\n            bool: True if all pairs are within k edges, False otherwise.\n        \"\"\"\n        if len(cell_types) &lt;= 1:\n            return True\n        for i in range(len(cell_types)):\n            for j in range(i + 1, len(cell_types)):\n                ct1, ct2 = cell_types[i], cell_types[j]\n                if ct1 not in type2index or ct2 not in type2index:\n                    return False\n                idx1 = type2index[ct1]\n                idx2 = type2index[ct2]\n                dist = graph.shortest_paths(idx1, idx2)[0][0]\n                if dist &gt;= k:\n                    return False\n        return True\n\n    multi_mask = (true_counts &gt; 1)\n    multi_indices = np.where(multi_mask)[0]\n\n    for i in multi_indices:\n        c_types = result_list[i]\n        if is_all_within_k_edges(c_types):\n            class_type.iloc[i] = \"Intermediate\"\n        else:\n            class_type.iloc[i] = \"Hybrid\"\n\n    ans = ['_'.join(lst) if lst else 'None' for lst in result_list]\n\n    adata_c.obs['SCN_class_emp'] = ans\n    adata_c.obs['SCN_class_type'] = class_type\n\n    if class_obs_name not in adata_c.obs:\n        raise ValueError(f\"{class_obs_name} not found in adata_c.obs.\")\n\n    adata_c.obs['SCN_class_emp'] = adata_c.obs.apply(\n        lambda row: 'Rand' if row[class_obs_name] == 'rand' else row['SCN_class_emp'],\n        axis=1\n    )\n    adata_c.obs['SCN_class_type'] = adata_c.obs.apply(\n        lambda row: 'Rand' if row[class_obs_name] == 'rand' else row['SCN_class_type'],\n        axis=1\n    )\n\n    _add_scn_class_cat(adata_c)\n\n    if inplace:\n        return None\n    else:\n        return adata_c\n</code></pre>"},{"location":"classifier.html#pySingleCellNet.classify.classify_anndata","title":"classify_anndata","text":"<pre><code>classify_anndata(adata, rf_tsp, nrand=0)\n</code></pre> <p>Classifies cells in the <code>adata</code> object based on the given gene expression and cross-pair information using a random forest classifier in rf_tsp trained with the provided xpairs genes.</p>"},{"location":"classifier.html#pySingleCellNet.classify.classify_anndata--parameters","title":"Parameters:","text":"<p>adata: <code>AnnData</code>     An annotated data matrix containing the gene expression information for cells. rf_tsp: List[float]     A list of random forest classifier parameters used for classification. nrand: int     Number of random permutations for the null distribution. Default is 0.</p>"},{"location":"classifier.html#pySingleCellNet.classify.classify_anndata--returns","title":"Returns:","text":"<p>Updates adata with classification results</p> Source code in <code>src/pySingleCellNet/classify/classifier.py</code> <pre><code>def classify_anndata(adata: AnnData, rf_tsp, nrand: int = 0):\n    \"\"\"\n    Classifies cells in the `adata` object based on the given gene expression and cross-pair information using a\n    random forest classifier in rf_tsp trained with the provided xpairs genes.\n\n    Parameters:\n    -----------\n    adata: `AnnData`\n        An annotated data matrix containing the gene expression information for cells.\n    rf_tsp: List[float]\n        A list of random forest classifier parameters used for classification.\n    nrand: int\n        Number of random permutations for the null distribution. Default is 0.\n\n    Returns:\n    --------\n    Updates adata with classification results \n    \"\"\"\n\n    # Classify cells using the `_scn_predict` function\n    classRes = _scn_predict(rf_tsp, adata, nrand=nrand)\n\n    # add the classification result as to `obsm`\n    # adNew = AnnData(classRes, obs=adata.obs, var=pd.DataFrame(index=categories))\n    adata.obsm['SCN_score'] = classRes\n\n    # Get the categories (i.e., predicted cell types) from the classification result\n    # categories = classRes.columns.values\n    # possible_classes = rf_tsp['classifier'].classes_\n    possible_classes = pd.Categorical(classRes.columns)\n    # Add a new column to `obs` for the predicted cell types\n    predicted_classes = classRes.idxmax(axis=1)\n    adata.obs['SCN_class_argmax'] = pd.Categorical(predicted_classes, categories=possible_classes, ordered=True)\n\n    # store this for consistent coloring\n    # adata.uns['SCN_class_colors'] = rf_tsp['ctColors']        \n\n    # import matplotlib.colors as mcolors\n    # celltype_colors = rf_tsp['ctColors']\n    # mycolors = [celltype_colors[ct] for ct in adata.obs['SCN_class_argmax'].cat.categories]\n    # cmap = mcolors.ListedColormap(mycolors)\n    adata.uns['SCN_class_argmax_colors'] = rf_tsp['ctColors']\n</code></pre>"},{"location":"classifier.html#pySingleCellNet.classify.collect_gsea_results_from_dict","title":"collect_gsea_results_from_dict","text":"<pre><code>collect_gsea_results_from_dict(gsea_dict2, fdr_thr=0.25, top_n=3)\n</code></pre> <p>Collect and filter GSEA results from a dictionary of GSEA objects.</p> For each cell type <ol> <li>Sets NES=0 for any gene set with FDR &gt; fdr_thr.</li> <li>Selects up to top_n sets with the largest positive NES and     top_n with the most negative NES.</li> </ol> <p>The final output is limited to the union of all such selected sets across all cell types, with zeroes preserved for cell types in which the pathway is not among the top_n or fails the FDR threshold.</p> <p>Parameters:</p> <ul> <li> <code>gsea_dict2</code>               (<code>dict</code>)           \u2013            <p>Dictionary mapping cell types to GSEA result objects. Each object has a .res2d DataFrame with columns [\"Term\", \"NES\", \"FDR q-val\"].</p> </li> <li> <code>fdr_thr</code>               (<code>float</code>, default:                   <code>0.25</code> )           \u2013            <p>FDR threshold above which NES values are set to 0.  Defaults to 0.25.</p> </li> <li> <code>top_n</code>               (<code>int</code>, default:                   <code>3</code> )           \u2013            <p>Maximum number of positive and negative results  (by NES) to keep per cell type. Defaults to 10.</p> </li> </ul> <p>Returns:</p> <ul> <li>           \u2013            <p>pd.DataFrame: A DataFrame whose rows are the union of selected gene sets  across all cell types, and whose columns are cell types. Entries  are filtered NES values (0 where FDR fails, or if not in the top_n).</p> </li> </ul> Source code in <code>src/pySingleCellNet/classify/comparison.py</code> <pre><code>def collect_gsea_results_from_dict(\n    gsea_dict2: dict,\n    fdr_thr: float = 0.25,\n    top_n: int = 3\n):\n    \"\"\"\n    Collect and filter GSEA results from a dictionary of GSEA objects.\n\n    For each cell type:\n      1. Sets NES=0 for any gene set with FDR &gt; fdr_thr.\n      2. Selects up to top_n sets with the largest positive NES and \n         top_n with the most negative NES.\n\n    The final output is limited to the union of all such selected sets\n    across all cell types, with zeroes preserved for cell types in which\n    the pathway is not among the top_n or fails the FDR threshold.\n\n    Args:\n        gsea_dict2 (dict): Dictionary mapping cell types to GSEA result objects.\n            Each object has a .res2d DataFrame with columns [\"Term\", \"NES\", \"FDR q-val\"].\n        fdr_thr (float, optional): FDR threshold above which NES values are set to 0. \n            Defaults to 0.25.\n        top_n (int, optional): Maximum number of positive and negative results \n            (by NES) to keep per cell type. Defaults to 10.\n\n    Returns:\n        pd.DataFrame: A DataFrame whose rows are the union of selected gene sets \n            across all cell types, and whose columns are cell types. Entries \n            are filtered NES values (0 where FDR fails, or if not in the top_n).\n    \"\"\"\n    import copy\n\n    # Make a copy of the input to avoid in-place modifications\n    gsea_dict = copy.deepcopy(gsea_dict2)\n\n    # Collect all possible gene set names and cell types\n    pathways = pd.Index([])\n    cell_types = list(gsea_dict.keys())\n\n    for cell_type in cell_types:\n        tmpRes = gsea_dict[cell_type].res2d\n        gene_set_names = list(tmpRes['Term'])\n        pathways = pathways.union(gene_set_names)\n\n    # Initialize NES DataFrame\n    nes_df = pd.DataFrame(0, columns=cell_types, index=pathways)\n\n    # Apply FDR threshold and fill NES\n    for cell_type in cell_types:\n        ct_df = gsea_dict[cell_type].res2d.copy()\n        ct_df.index = ct_df['Term']\n        # Zero out NES where FDR is too high\n        ct_df.loc[ct_df['FDR q-val'] &gt; fdr_thr, \"NES\"] = 0\n        nes_df[cell_type] = ct_df[\"NES\"]\n\n    # Convert NES to numeric just in case\n    nes_df = nes_df.apply(pd.to_numeric, errors='coerce')\n\n    # Determine top_n positive and top_n negative for each cell type\n    selected_sets = set()\n    for cell_type in cell_types:\n        ct_values = nes_df[cell_type]\n        # Filter non-zero for positives and negatives\n        pos_mask = ct_values &gt; 0\n        neg_mask = ct_values &lt; 0\n\n        # Select top_n largest positive NES\n        top_pos_index = ct_values[pos_mask].sort_values(ascending=False).head(top_n).index\n        # Select top_n most negative NES (smallest ascending)\n        top_neg_index = ct_values[neg_mask].sort_values(ascending=True).head(top_n).index\n\n        selected_sets.update(top_pos_index)\n        selected_sets.update(top_neg_index)\n\n    # Restrict DataFrame to the union of selected sets, converting the set to a list\n    selected_sets_list = list(selected_sets)\n    nes_df = nes_df.loc[selected_sets_list]\n\n    return nes_df\n</code></pre>"},{"location":"classifier.html#pySingleCellNet.classify.comp_ct_thresh","title":"comp_ct_thresh","text":"<pre><code>comp_ct_thresh(adata_c, qTile=0.05, obs_name='SCN_class_argmax')\n</code></pre> <p>Compute quantile thresholds for each cell type based on SCN scores.</p> <p>For each cell type (excluding \"rand\"), this function calculates the qTile  quantile of the SCN scores for cells predicted to belong to that type.</p> <p>Parameters:</p> <ul> <li> <code>adata_c</code>               (<code>AnnData</code>)           \u2013            <p>Annotated data matrix with: - <code>.obsm[\"SCN_score\"]</code>: DataFrame of SCN scores. - <code>.obs</code>: Observation metadata containing predictions.</p> </li> <li> <code>qTile</code>               (<code>int</code>, default:                   <code>0.05</code> )           \u2013            <p>The quantile to compute (e.g., 0.05 for 5th percentile). Defaults to 0.05.</p> </li> <li> <code>obs_name</code>               (<code>str</code>, default:                   <code>'SCN_class_argmax'</code> )           \u2013            <p>The column in <code>.obs</code> containing cell type predictions. Defaults to 'SCN_class_argmax'.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>pd.DataFrame: A DataFrame where each row corresponds to a cell type </p> </li> <li> <code>DataFrame</code>           \u2013            <p>(excluding 'rand') and contains the computed quantile threshold.</p> </li> <li> <code>DataFrame</code>           \u2013            <p>Returns None if 'SCN_score' is not present in <code>adata_c.obsm</code>.</p> </li> </ul> Source code in <code>src/pySingleCellNet/classify/categorize.py</code> <pre><code>def comp_ct_thresh(adata_c: AnnData, qTile: int = 0.05, obs_name='SCN_class_argmax') -&gt; pd.DataFrame:\n    \"\"\"Compute quantile thresholds for each cell type based on SCN scores.\n\n    For each cell type (excluding \"rand\"), this function calculates the qTile \n    quantile of the SCN scores for cells predicted to belong to that type.\n\n    Args:\n        adata_c (AnnData): Annotated data matrix with:\n            - `.obsm[\"SCN_score\"]`: DataFrame of SCN scores.\n            - `.obs`: Observation metadata containing predictions.\n        qTile (int, optional): The quantile to compute (e.g., 0.05 for 5th percentile). Defaults to 0.05.\n        obs_name (str, optional): The column in `.obs` containing cell type predictions. Defaults to 'SCN_class_argmax'.\n\n    Returns:\n        pd.DataFrame: A DataFrame where each row corresponds to a cell type \n        (excluding 'rand') and contains the computed quantile threshold.\n        Returns None if 'SCN_score' is not present in `adata_c.obsm`.\n    \"\"\"\n    if \"SCN_score\" not in adata_c.obsm_keys():\n        print(\"No .obsm['SCN_score'] was found in the AnnData provided. You may need to run PySingleCellNet.scn_classify()\")\n        return\n    else:\n        sampTab = adata_c.obs.copy()\n        scnScores = adata_c.obsm[\"SCN_score\"].copy()\n\n        cts = scnScores.columns.drop('rand')\n        thrs = pd.DataFrame(np.repeat(0, len(cts)), index=cts)\n\n        for ct in cts:\n            # print(ct)\n            templocs = sampTab[sampTab[obs_name] == ct].index\n            tempscores = scnScores.loc[templocs, ct]\n            thrs.loc[ct, 0] = np.quantile(tempscores, q=qTile)\n\n        return thrs\n</code></pre>"},{"location":"classifier.html#pySingleCellNet.classify.convert_diffExp_to_dict","title":"convert_diffExp_to_dict","text":"<pre><code>convert_diffExp_to_dict(adata, uns_name='rank_genes_groups')\n</code></pre> <p>Convert differential expression results from AnnData into a dictionary of DataFrames.</p> <p>This function extracts differential expression results stored in <code>adata.uns[uns_name]</code>  using Scanpy's <code>get.rank_genes_groups_df</code>, cleans the data, and organizes it into  a dictionary where each key corresponds to a group and each value is a DataFrame  of differential expression results for that group.</p> <p>Parameters:</p> <ul> <li> <code>adata</code>               (<code>AnnData</code>)           \u2013            <p>Annotated data matrix containing differential expression results  in <code>adata.uns</code>.</p> </li> <li> <code>uns_name</code>               (<code>str</code>, default:                   <code>'rank_genes_groups'</code> )           \u2013            <p>Key in <code>adata.uns</code> where rank_genes_groups results  are stored. Defaults to 'rank_genes_groups'.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>dict</code>          \u2013            <p>Dictionary mapping each group to a DataFrame of its differential </p> </li> <li>           \u2013            <p>expression results, with rows corresponding to genes and relevant statistics </p> </li> <li>           \u2013            <p>for each gene.</p> </li> </ul> Source code in <code>src/pySingleCellNet/classify/comparison.py</code> <pre><code>def convert_diffExp_to_dict(\n    adata,\n    uns_name: str = 'rank_genes_groups'\n):\n    \"\"\"Convert differential expression results from AnnData into a dictionary of DataFrames.\n\n    This function extracts differential expression results stored in `adata.uns[uns_name]` \n    using Scanpy's `get.rank_genes_groups_df`, cleans the data, and organizes it into \n    a dictionary where each key corresponds to a group and each value is a DataFrame \n    of differential expression results for that group.\n\n    Args:\n        adata (AnnData): Annotated data matrix containing differential expression results \n            in `adata.uns`.\n        uns_name (str, optional): Key in `adata.uns` where rank_genes_groups results \n            are stored. Defaults to 'rank_genes_groups'.\n\n    Returns:\n        dict: Dictionary mapping each group to a DataFrame of its differential \n        expression results, with rows corresponding to genes and relevant statistics \n        for each gene.\n    \"\"\"\n    import scanpy as sc  # Ensure Scanpy is imported\n    tempTab = sc.get.rank_genes_groups_df(adata, group=None, key=uns_name)\n    tempTab = tempTab.dropna()\n    groups = tempTab['group'].cat.categories.to_list()\n\n    ans = {}\n    for g in groups:\n        ans[g] = tempTab[tempTab['group'] == g].copy()\n    return ans\n</code></pre>"},{"location":"classifier.html#pySingleCellNet.classify.create_classifier_report","title":"create_classifier_report","text":"<pre><code>create_classifier_report(adata, ground_truth, prediction)\n</code></pre> <p>Generate a classification report as a pandas DataFrame from an AnnData object.</p> <p>This function computes a classification report using ground truth and prediction columns in <code>adata.obs</code>. It supports both string and dictionary outputs from <code>sklearn.metrics.classification_report</code> and transforms them into a standardized DataFrame format.</p> <p>Parameters:</p> <ul> <li> <code>adata</code>               (<code>AnnData</code>)           \u2013            <p>An annotated data matrix containing observations with categorical truth and prediction labels.</p> </li> <li> <code>ground_truth</code>               (<code>str</code>)           \u2013            <p>The column name in <code>adata.obs</code> containing the true class labels.</p> </li> <li> <code>prediction</code>               (<code>str</code>)           \u2013            <p>The column name in <code>adata.obs</code> containing the predicted class labels.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>pd.DataFrame: A DataFrame with columns [\"Label\", \"Precision\", \"Recall\",</p> </li> <li> <code>DataFrame</code>           \u2013            <p>\"F1-Score\", \"Support\"] summarizing classification metrics for each class.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the classification report is neither a string nor a dictionary.</p> </li> </ul> Source code in <code>src/pySingleCellNet/classify/classifier.py</code> <pre><code>def create_classifier_report(adata: AnnData,\n    ground_truth: str,\n    prediction: str) -&gt; pd.DataFrame:\n    \"\"\"\n    Generate a classification report as a pandas DataFrame from an AnnData object.\n\n    This function computes a classification report using ground truth and prediction\n    columns in `adata.obs`. It supports both string and dictionary outputs from\n    `sklearn.metrics.classification_report` and transforms them into a standardized\n    DataFrame format.\n\n    Args:\n        adata (AnnData): An annotated data matrix containing observations with\n            categorical truth and prediction labels.\n        ground_truth (str): The column name in `adata.obs` containing the true\n            class labels.\n        prediction (str): The column name in `adata.obs` containing the predicted\n            class labels.\n\n    Returns:\n        pd.DataFrame: A DataFrame with columns [\"Label\", \"Precision\", \"Recall\",\n        \"F1-Score\", \"Support\"] summarizing classification metrics for each class.\n\n    Raises:\n        ValueError: If the classification report is neither a string nor a dictionary.\n    \"\"\"\n\n    report = classification_report(adata.obs[ground_truth], adata.obs[prediction],labels=adata.obs[ground_truth].cat.categories, output_dict = True)\n    # Parse the sklearn classification report into a DataFrame\n    if isinstance(report, str):\n        lines = report.split('\\n')\n        rows = []\n        for line in lines[2:]:\n            if line.strip() == '':\n                continue\n            row = line.split()\n            if row[0] == 'micro' or row[0] == 'macro' or row[0] == 'weighted':\n                row[0] = ' '.join(row[:2])\n                row = [row[0]] + row[2:]\n            elif len(row) &gt; 5:\n                row[0] = ' '.join(row[:2])\n                row = [row[0]] + row[2:]\n            rows.append(row)\n\n        df = pd.DataFrame(rows, columns=[\"Label\", \"Precision\", \"Recall\", \"F1-Score\", \"Support\"])\n        df[\"Precision\"] = pd.to_numeric(df[\"Precision\"], errors='coerce')\n        df[\"Recall\"] = pd.to_numeric(df[\"Recall\"], errors='coerce')\n        df[\"F1-Score\"] = pd.to_numeric(df[\"F1-Score\"], errors='coerce')\n        df[\"Support\"] = pd.to_numeric(df[\"Support\"], errors='coerce')\n    elif isinstance(report, dict):\n        df = pd.DataFrame(report).T.reset_index()\n        df.columns = [\"Label\", \"Precision\", \"Recall\", \"F1-Score\", \"Support\"]\n    else:\n        raise ValueError(\"Report must be a string or a dictionary.\")\n    return df\n</code></pre>"},{"location":"classifier.html#pySingleCellNet.classify.deg","title":"deg","text":"<pre><code>deg(adata, sample_obsvals=[], limitto_obsvals=[], cellgrp_obsname='comb_cellgrp', groupby_obsname='comb_sampname', ncells_per_sample=30, test_name='t-test', mask_var='highly_variable')\n</code></pre> <p>Perform differential expression analysis on an AnnData object across specified cell groups and samples.</p> <p>This function iterates over specified or all cell groups within the <code>adata</code> object and performs differential expression analysis using the specified statistical test (e.g., t-test). It filters groups based on the minimum number of cells per sample and returns the results in a structured dictionary.</p> <p>Parameters:</p> <ul> <li> <code>adata</code>               (<code>AnnData</code>)           \u2013            <p>The annotated data matrix containing observations and variables.</p> </li> <li> <code>sample_obsvals</code>               (<code>list</code>, default:                   <code>[]</code> )           \u2013            <p>List of sample observation values to include. Defaults to an empty list. Impacts the sign of the test statistic.</p> </li> <li> <code>limitto_obsvals</code>               (<code>list</code>, default:                   <code>[]</code> )           \u2013            <p>List of cell group observation values to limit the analysis to. If empty, all cell groups in <code>adata</code> are tested. Defaults to an empty list.</p> </li> <li> <code>cellgrp_obsname</code>               (<code>str</code>, default:                   <code>'comb_cellgrp'</code> )           \u2013            <p>The <code>.obs</code> column name in <code>adata</code> that holds the cell sub-groups. Defaults to 'comb_cellgrp'.</p> </li> <li> <code>groupby_obsname</code>               (<code>str</code>, default:                   <code>'comb_sampname'</code> )           \u2013            <p>The <code>.obs</code> column name in <code>adata</code> used to group observations for differential expression. Defaults to 'comb_sampname'.</p> </li> <li> <code>ncells_per_sample</code>               (<code>int</code>, default:                   <code>30</code> )           \u2013            <p>The minimum number of cells per sample required to perform the test. Groups with fewer cells are skipped. Defaults to 30.</p> </li> <li> <code>test_name</code>               (<code>str</code>, default:                   <code>'t-test'</code> )           \u2013            <p>The name of the statistical test to use for differential expression. Defaults to 't-test'.</p> </li> <li> <code>mask_var</code>               (<code>str</code>, default:                   <code>'highly_variable'</code> )           \u2013            <p>The name of the .var column indicating highly variable genes Defaults to 'highly_variable'.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>dict</code> (              <code>dict</code> )          \u2013            <p>A dictionary containing: - 'sample_names': List of sample names used in the analysis. - 'geneTab_dict': A dictionary where each key is a cell group name and each value is a DataFrame   of differential expression results for that group.</p> </li> </ul> Source code in <code>src/pySingleCellNet/classify/comparison.py</code> <pre><code>def deg(\n    adata: AnnData,\n    sample_obsvals: list = [],  # Impacts the sign of the test statistic\n    limitto_obsvals: list = [],  # Specifies which cell groups to test; if empty, tests all\n    cellgrp_obsname: str = 'comb_cellgrp',  # .obs column name holding the cell sub-groups to iterate over\n    groupby_obsname: str = 'comb_sampname',  # .obs column name to group by for differential expression\n    ncells_per_sample: int = 30,  # Minimum number of cells per sample required to perform the test\n    test_name: str = 't-test',  # Name of the statistical test to use\n    mask_var: str = 'highly_variable'\n) -&gt; dict:\n    \"\"\"\n    Perform differential expression analysis on an AnnData object across specified cell groups and samples.\n\n    This function iterates over specified or all cell groups within the `adata` object and performs\n    differential expression analysis using the specified statistical test (e.g., t-test). It filters\n    groups based on the minimum number of cells per sample and returns the results in a structured dictionary.\n\n    Args:\n        adata (AnnData): The annotated data matrix containing observations and variables.\n        sample_obsvals (list, optional): List of sample observation values to include. Defaults to an empty list.\n            Impacts the sign of the test statistic.\n        limitto_obsvals (list, optional): List of cell group observation values to limit the analysis to.\n            If empty, all cell groups in `adata` are tested. Defaults to an empty list.\n        cellgrp_obsname (str, optional): The `.obs` column name in `adata` that holds the cell sub-groups.\n            Defaults to 'comb_cellgrp'.\n        groupby_obsname (str, optional): The `.obs` column name in `adata` used to group observations for differential expression.\n            Defaults to 'comb_sampname'.\n        ncells_per_sample (int, optional): The minimum number of cells per sample required to perform the test.\n            Groups with fewer cells are skipped. Defaults to 30.\n        test_name (str, optional): The name of the statistical test to use for differential expression.\n            Defaults to 't-test'.\n        mask_var (str, optional): The name of the .var column indicating highly variable genes\n            Defaults to 'highly_variable'.\n\n    Returns:\n        dict: A dictionary containing:\n            - 'sample_names': List of sample names used in the analysis.\n            - 'geneTab_dict': A dictionary where each key is a cell group name and each value is a DataFrame\n              of differential expression results for that group.\n    \"\"\"\n    ans = dict()\n\n    # Keys for the rank_genes_groups object\n    subset_keys = ['names', 'scores', 'pvals', 'pvals_adj', 'logfoldchanges']\n\n    # If no specific sample observation values are provided, use all unique values from adata\n    if len(sample_obsvals) == 0:\n        sample_obsvals = adata.obs[groupby_obsname].unique().tolist()\n\n    # Store the sample names in the result dictionary for later ordering of differential expression DataFrame\n    ans['sample_names'] = sample_obsvals\n\n    # Retrieve unique cell group names from the AnnData object\n    cellgroup_names_in_anndata = adata.obs[cellgrp_obsname].unique()\n\n    # If limitto_obsvals is provided, validate and set the cell groups to test\n    if len(limitto_obsvals) &gt; 0:\n        # Identify any provided cell groups that are not present in adata\n        unique_to_input = [x for x in limitto_obsvals if x not in cellgroup_names_in_anndata]\n        if len(unique_to_input) &gt; 0:\n            print(f\"The argument cellgrp_obsname has values that are not present in adata: {unique_to_input}\")\n        else:\n            cellgroup_names = limitto_obsvals\n    else:\n        # If no limit is set, use all available cell groups\n        cellgroup_names = cellgroup_names_in_anndata\n\n    # Initialize a temporary dictionary to store differential expression results\n    tmp_dict = dict()\n\n    # Create a mask to filter adata for the specified sample observation values\n    mask = adata.obs[groupby_obsname].isin(sample_obsvals)\n    adata = adata[mask].copy()\n\n    def convert_rankGeneGroup_to_df(rgg: dict, list_of_keys: list) -&gt; pd.DataFrame:\n        \"\"\"\n        Convert the rank_genes_groups result from AnnData to a pandas DataFrame.\n\n        Args:\n            rgg (dict): The rank_genes_groups result from AnnData.\n            list_of_keys (list): List of keys to extract from the rank_genes_groups result.\n\n        Returns:\n            pd.DataFrame: A DataFrame containing the extracted rank genes information.\n        \"\"\"\n        # Initialize a dictionary to hold arrays for each key\n        arrays_dict = {}\n        for key in list_of_keys:\n            recarray = rgg[key]\n            field_name = recarray.dtype.names[0]  # Get the first field name from the structured array\n            arrays_dict[key] = recarray[field_name]\n\n        # Convert the dictionary of arrays to a DataFrame\n        return pd.DataFrame(arrays_dict)\n\n    # Iterate over each cell group to perform differential expression analysis\n    for cell_group in cellgroup_names:\n        print(f\"cell group: {cell_group}\")\n\n        # Subset the AnnData object for the current cell group\n        adTmp = adata[adata.obs[cellgrp_obsname] == cell_group].copy()\n\n        # Count the number of cells per sample within the cell group\n        vcounts = adTmp.obs[groupby_obsname].value_counts()\n\n        # Check if there are exactly two samples and each has at least ncells_per_sample cells\n        if (len(vcounts) == 2) and (vcounts &gt;= ncells_per_sample).all():\n            # Perform differential expression analysis using the specified test\n            sc.tl.rank_genes_groups(\n                adTmp,\n                use_raw=False,\n                groupby=groupby_obsname,\n                groups=[sample_obsvals[0]],\n                reference=sample_obsvals[1],\n                method=test_name,\n                mask_var=mask_var\n            )\n\n            # Convert the rank_genes_groups result to a DataFrame and store it in tmp_dict\n            tmp_dict[cell_group] = convert_rankGeneGroup_to_df(adTmp.uns['rank_genes_groups'].copy(), subset_keys)\n            # Alternative method to get the DataFrame (commented out)\n            # tmp_dict[cell_group] = sc.get.rank_genes_groups_df(adTmp, cell_group)\n\n    # Store the differential expression results in the result dictionary\n    ans['geneTab_dict'] = tmp_dict\n\n    return ans\n</code></pre>"},{"location":"classifier.html#pySingleCellNet.classify.graph_from_nodes_and_edges","title":"graph_from_nodes_and_edges","text":"<pre><code>graph_from_nodes_and_edges(edge_dataframe, node_dataframe, attribution_column_names, directed=True)\n</code></pre> <p>Create an iGraph graph from provided node and edge dataframes.</p> <p>This function constructs an iGraph graph using nodes defined in  <code>node_dataframe</code> and edges defined in <code>edge_dataframe</code>. Each vertex  is assigned attributes based on specified columns, and edges are  created according to 'from' and 'to' columns in the edge dataframe.</p> <p>Parameters:</p> <ul> <li> <code>edge_dataframe</code>               (<code>DataFrame</code>)           \u2013            <p>A DataFrame containing edge  information with at least 'from' and 'to' columns indicating  source and target node identifiers.</p> </li> <li> <code>node_dataframe</code>               (<code>DataFrame</code>)           \u2013            <p>A DataFrame containing node  information. Must include an 'id' column for vertex identifiers  and any other columns specified in <code>attribution_column_names</code>.</p> </li> <li> <code>attribution_column_names</code>               (<code>list of str</code>)           \u2013            <p>List of column names from  <code>node_dataframe</code> whose values will be assigned as attributes  to the corresponding vertices in the graph.</p> </li> <li> <code>directed</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether the graph should be directed.  Defaults to True.</p> </li> </ul> <p>Returns:</p> <ul> <li>           \u2013            <p>ig.Graph: An iGraph graph constructed from the given nodes and edges, </p> </li> <li>           \u2013            <p>with vertex attributes and labels set according to the provided data.</p> </li> </ul> Source code in <code>src/pySingleCellNet/classify/categorize.py</code> <pre><code>def graph_from_nodes_and_edges(edge_dataframe, node_dataframe, attribution_column_names, directed=True):\n    \"\"\"Create an iGraph graph from provided node and edge dataframes.\n\n    This function constructs an iGraph graph using nodes defined in \n    `node_dataframe` and edges defined in `edge_dataframe`. Each vertex \n    is assigned attributes based on specified columns, and edges are \n    created according to 'from' and 'to' columns in the edge dataframe.\n\n    Args:\n        edge_dataframe (pd.DataFrame): A DataFrame containing edge \n            information with at least 'from' and 'to' columns indicating \n            source and target node identifiers.\n        node_dataframe (pd.DataFrame): A DataFrame containing node \n            information. Must include an 'id' column for vertex identifiers \n            and any other columns specified in `attribution_column_names`.\n        attribution_column_names (list of str): List of column names from \n            `node_dataframe` whose values will be assigned as attributes \n            to the corresponding vertices in the graph.\n        directed (bool, optional): Whether the graph should be directed. \n            Defaults to True.\n\n    Returns:\n        ig.Graph: An iGraph graph constructed from the given nodes and edges, \n        with vertex attributes and labels set according to the provided data.\n    \"\"\"\n    gra = ig.Graph(directed=directed)\n    attr = {}\n    for attr_names in attribution_column_names:\n        attr[attr_names] = node_dataframe[attr_names].to_numpy()\n\n    gra.add_vertices(n=node_dataframe.id.to_numpy(), attributes=attr)\n    for ind in edge_dataframe.index:\n        tempsource = edge_dataframe.loc[ind].loc['from']\n        temptarget = edge_dataframe.loc[ind].loc['to']\n        gra.add_edges([(tempsource, temptarget)])\n\n    gra.vs[\"label\"] = gra.vs[\"id\"]\n    return gra\n</code></pre>"},{"location":"classifier.html#pySingleCellNet.classify.gsea_on_deg","title":"gsea_on_deg","text":"<pre><code>gsea_on_deg(deg_res, genesets_name, genesets, permutation_num=100, threads=4, seed=3, min_size=10, max_size=500)\n</code></pre> <p>Perform Gene Set Enrichment Analysis (GSEA) on differential expression results.</p> <p>Applies GSEA using <code>gseapy.prerank</code> for each group in the differential  expression results dictionary against provided gene sets.</p> <p>Parameters:</p> <ul> <li> <code>deg_res</code>               (<code>dict</code>)           \u2013            <p>Dictionary mapping cell group names to DataFrames  of differential expression results. Each DataFrame must contain  columns 'names' (gene names) and 'scores' (ranking scores).</p> </li> <li> <code>genesets_name</code>               (<code>str</code>)           \u2013            <p>Name of the gene set collection (not actively used).</p> </li> <li> <code>genesets</code>               (<code>dict</code>)           \u2013            <p>Dictionary of gene sets where keys are gene set  names and values are lists of genes.</p> </li> <li> <code>permutation_num</code>               (<code>int</code>, default:                   <code>100</code> )           \u2013            <p>Number of permutations for GSEA.  Defaults to 100.</p> </li> <li> <code>threads</code>               (<code>int</code>, default:                   <code>4</code> )           \u2013            <p>Number of parallel threads to use. Defaults to 4.</p> </li> <li> <code>seed</code>               (<code>int</code>, default:                   <code>3</code> )           \u2013            <p>Random seed for reproducibility. Defaults to 3.</p> </li> <li> <code>min_size</code>               (<code>int</code>, default:                   <code>10</code> )           \u2013            <p>Minimum gene set size to consider. Defaults to 10.</p> </li> <li> <code>max_size</code>               (<code>int</code>, default:                   <code>500</code> )           \u2013            <p>Maximum gene set size to consider. Defaults to 500.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>dict</code> (              <code>dict</code> )          \u2013            <p>Dictionary where keys are cell group names and values are  GSEA result objects returned by <code>gseapy.prerank</code>.</p> </li> </ul> Example <p>deg_results = { ...     'Cluster1': pd.DataFrame({'names': ['GeneA', 'GeneB'], 'scores': [2.5, -1.3]}), ...     'Cluster2': pd.DataFrame({'names': ['GeneC', 'GeneD'], 'scores': [1.2, -2.1]}) ... } gene_sets = {'Pathway1': ['GeneA', 'GeneC'], 'Pathway2': ['GeneB', 'GeneD']} results = gsea_on_deg(deg_results, 'ExampleGeneSets', gene_sets)</p> Source code in <code>src/pySingleCellNet/classify/comparison.py</code> <pre><code>def gsea_on_deg(\n    deg_res: dict,\n    genesets_name: str,\n    genesets: dict,\n    permutation_num: int = 100,\n    threads: int = 4,\n    seed: int = 3,\n    min_size: int = 10,\n    max_size: int = 500\n) -&gt; dict:\n    \"\"\"Perform Gene Set Enrichment Analysis (GSEA) on differential expression results.\n\n    Applies GSEA using `gseapy.prerank` for each group in the differential \n    expression results dictionary against provided gene sets.\n\n    Args:\n        deg_res (dict): Dictionary mapping cell group names to DataFrames \n            of differential expression results. Each DataFrame must contain \n            columns 'names' (gene names) and 'scores' (ranking scores).\n        genesets_name (str): Name of the gene set collection (not actively used).\n        genesets (dict): Dictionary of gene sets where keys are gene set \n            names and values are lists of genes.\n        permutation_num (int, optional): Number of permutations for GSEA. \n            Defaults to 100.\n        threads (int, optional): Number of parallel threads to use. Defaults to 4.\n        seed (int, optional): Random seed for reproducibility. Defaults to 3.\n        min_size (int, optional): Minimum gene set size to consider. Defaults to 10.\n        max_size (int, optional): Maximum gene set size to consider. Defaults to 500.\n\n    Returns:\n        dict: Dictionary where keys are cell group names and values are \n            GSEA result objects returned by `gseapy.prerank`.\n\n    Example:\n        &gt;&gt;&gt; deg_results = {\n        ...     'Cluster1': pd.DataFrame({'names': ['GeneA', 'GeneB'], 'scores': [2.5, -1.3]}),\n        ...     'Cluster2': pd.DataFrame({'names': ['GeneC', 'GeneD'], 'scores': [1.2, -2.1]})\n        ... }\n        &gt;&gt;&gt; gene_sets = {'Pathway1': ['GeneA', 'GeneC'], 'Pathway2': ['GeneB', 'GeneD']}\n        &gt;&gt;&gt; results = gsea_on_deg(deg_results, 'ExampleGeneSets', gene_sets)\n    \"\"\"\n    ans = dict()\n    diff_gene_tables = deg_res\n    cellgrp_vals = list(diff_gene_tables.keys())\n    for cellgrp in cellgrp_vals:\n        atab = diff_gene_tables[cellgrp]\n        atab = atab[['names', 'scores']]\n        atab.columns = ['0', '1']\n        pre_res = gp.prerank(\n            rnk=atab,\n            gene_sets=genesets,\n            permutation_num=permutation_num,\n            ascending=False,\n            threads=threads,\n            no_plot=True,\n            seed=seed,\n            min_size=min_size,\n            max_size=max_size\n        )\n        ans[cellgrp] = pre_res\n    return ans\n</code></pre>"},{"location":"classifier.html#pySingleCellNet.classify.paga_connectivities_to_igraph","title":"paga_connectivities_to_igraph","text":"<pre><code>paga_connectivities_to_igraph(adInput, n_neighbors=10, use_rep='X_pca', n_comps=30, threshold=0.05, paga_key='paga', connectivities_key='connectivities', group_key='auto_cluster')\n</code></pre> <p>Convert a PAGA adjacency matrix to an undirected iGraph object and add 'ncells'  attribute for each vertex based on the number of cells in each cluster.</p> <p>This function extracts the PAGA connectivity matrix from <code>adata.uns</code>, thresholds  the edges, constructs an undirected iGraph graph, and assigns vertex names and  the number of cells in each cluster.</p> <p>Parameters:</p> <ul> <li> <code>adInput</code>               (<code>AnnData</code>)           \u2013            <p>The AnnData object containing: - <code>adata.uns[paga_key][connectivities_key]</code>: The PAGA adjacency matrix (CSR format). - <code>adata.obs[group_key].cat.categories</code>: The node labels.</p> </li> <li> <code>n_neighbors</code>               (<code>int</code>, default:                   <code>10</code> )           \u2013            <p>Number of neighbors for computing nearest neighbors. Defaults to 10.</p> </li> <li> <code>use_rep</code>               (<code>str</code>, default:                   <code>'X_pca'</code> )           \u2013            <p>The representation to use. Defaults to 'X_pca'.</p> </li> <li> <code>n_comps</code>               (<code>int</code>, default:                   <code>30</code> )           \u2013            <p>Number of principal components. Defaults to 30.</p> </li> <li> <code>threshold</code>               (<code>float</code>, default:                   <code>0.05</code> )           \u2013            <p>Minimum edge weight to include. Defaults to 0.05.</p> </li> <li> <code>paga_key</code>               (<code>str</code>, default:                   <code>'paga'</code> )           \u2013            <p>Key in <code>adata.uns</code> for PAGA results. Defaults to \"paga\".</p> </li> <li> <code>connectivities_key</code>               (<code>str</code>, default:                   <code>'connectivities'</code> )           \u2013            <p>Key for connectivity matrix in <code>adata.uns[paga_key]</code>. Defaults to \"connectivities\".</p> </li> <li> <code>group_key</code>               (<code>str</code>, default:                   <code>'auto_cluster'</code> )           \u2013            <p>The <code>.obs</code> column name with cluster labels. Defaults to \"auto_cluster\".</p> </li> </ul> <p>Returns:</p> <ul> <li>           \u2013            <p>ig.Graph: An undirected graph with edges meeting the threshold, edge weights assigned, </p> </li> <li>           \u2013            <p>vertex names set to cluster categories when possible, and each vertex has an 'ncells' attribute.</p> </li> </ul> Source code in <code>src/pySingleCellNet/classify/categorize.py</code> <pre><code>def paga_connectivities_to_igraph(\n    adInput,\n    n_neighbors=10,\n    use_rep='X_pca',\n    n_comps=30,\n    threshold=0.05, \n    paga_key=\"paga\", \n    connectivities_key=\"connectivities\", \n    group_key=\"auto_cluster\"\n):\n    \"\"\"Convert a PAGA adjacency matrix to an undirected iGraph object and add 'ncells' \n    attribute for each vertex based on the number of cells in each cluster.\n\n    This function extracts the PAGA connectivity matrix from `adata.uns`, thresholds \n    the edges, constructs an undirected iGraph graph, and assigns vertex names and \n    the number of cells in each cluster.\n\n    Args:\n        adInput (AnnData): The AnnData object containing:\n            - `adata.uns[paga_key][connectivities_key]`: The PAGA adjacency matrix (CSR format).\n            - `adata.obs[group_key].cat.categories`: The node labels.\n        n_neighbors (int, optional): Number of neighbors for computing nearest neighbors. Defaults to 10.\n        use_rep (str, optional): The representation to use. Defaults to 'X_pca'.\n        n_comps (int, optional): Number of principal components. Defaults to 30.\n        threshold (float, optional): Minimum edge weight to include. Defaults to 0.05.\n        paga_key (str, optional): Key in `adata.uns` for PAGA results. Defaults to \"paga\".\n        connectivities_key (str, optional): Key for connectivity matrix in `adata.uns[paga_key]`. Defaults to \"connectivities\".\n        group_key (str, optional): The `.obs` column name with cluster labels. Defaults to \"auto_cluster\".\n\n    Returns:\n        ig.Graph: An undirected graph with edges meeting the threshold, edge weights assigned, \n        vertex names set to cluster categories when possible, and each vertex has an 'ncells' attribute.\n    \"\"\"\n    # Copy so as to avoid altering the original AnnData object\n    adata = adInput.copy()\n\n    # Compute PCA, knn, and PAGA\n    sc.tl.pca(adata, n_comps, mask_var='highly_variable')\n    sc.pp.neighbors(adata, n_neighbors=n_neighbors, use_rep=use_rep, n_pcs=n_comps)\n    sc.tl.paga(adata, groups=group_key)\n\n    # Extract the PAGA connectivity matrix\n    adjacency_csr = adata.uns[paga_key][connectivities_key]\n    adjacency_coo = adjacency_csr.tocoo()\n\n    # Build edge list based on threshold\n    edges = []\n    weights = []\n    for i, j, val in zip(adjacency_coo.row, adjacency_coo.col, adjacency_coo.data):\n        if i &lt; j and val &gt;= threshold:\n            edges.append((i, j))\n            weights.append(val)\n\n    # Create the graph\n    g = ig.Graph(n=adjacency_csr.shape[0], edges=edges, directed=False)\n    g.es[\"weight\"] = weights\n\n    # Assign vertex names and 'ncells' attribute if group_key exists in adata.obs\n    if group_key in adata.obs:\n        # Get cluster categories\n        categories = adata.obs[group_key].cat.categories\n\n        # Calculate the number of cells per category\n        cell_counts_series = adata.obs[group_key].value_counts().reindex(categories, fill_value=0)\n        cell_counts = list(cell_counts_series)\n\n        if len(categories) == adjacency_csr.shape[0]:\n            # Assign vertex names and 'ncells' attribute\n            g.vs[\"name\"] = list(categories)\n            g.vs[\"label\"] = list(categories)\n            g.vs[\"ncells\"] = cell_counts\n        else:\n            print(\n                f\"Warning: adjacency matrix size ({adjacency_csr.shape[0]}) \"\n                f\"differs from number of categories ({len(categories)}). \"\n                \"Vertex names and 'ncells' will not be fully assigned.\"\n            )\n            # Even if the sizes don't match, still assign available 'ncells' for existing categories\n            g.vs[\"ncells\"] = cell_counts\n    else:\n        print(\n            f\"Warning: {group_key} not found in adata.obs; \"\n            \"vertex names and 'ncells' will not be assigned.\"\n        )\n\n    return g\n</code></pre>"},{"location":"install.html","title":"Installation","text":"<p>PySingleCellnet depends on several packages, most of which can be installed with pip, and some are available in conda channels.</p> <p>I recommend pre-installing the following:</p> <pre><code>pip install scanpy python-igraph leidenalg\n</code></pre> <p>Then, you should be able to install pySingleCellNet with PIP as follows:</p> <pre><code>pip install git+https://github.com/CahanLab/pySingleCellNet.git\n</code></pre> <p>This will install any remaining required packages, too</p>"},{"location":"plotting.html","title":"plotting functions","text":"<p>Various plotting functions.</p>"},{"location":"plotting.html#pySingleCellNet.plotting.bar_classifier_f1","title":"bar_classifier_f1","text":"<pre><code>bar_classifier_f1(adata, ground_truth='celltype', class_prediction='SCN_class', bar_height=0.8)\n</code></pre> <p>Plots a bar graph of F1 scores per class based on ground truth and predicted classifications.</p> <p>Parameters:</p> <ul> <li> <code>adata</code>               (<code>AnnData</code>)           \u2013            <p>Annotated data matrix.</p> </li> <li> <code>ground_truth</code>               (<code>str</code>, default:                   <code>'celltype'</code> )           \u2013            <p>The column name in <code>adata.obs</code> containing the true class labels. Defaults to \"celltype\".</p> </li> <li> <code>class_prediction</code>               (<code>str</code>, default:                   <code>'SCN_class'</code> )           \u2013            <p>The column name in <code>adata.obs</code> containing the predicted class labels. Defaults to \"SCN_class\".</p> </li> </ul> <p>Returns:</p> <ul> <li>           \u2013            <p>None</p> </li> </ul> Source code in <code>src/pySingleCellNet/plotting/bar.py</code> <pre><code>def bar_classifier_f1(adata: AnnData, ground_truth: str = \"celltype\", class_prediction: str = \"SCN_class\", bar_height=0.8):\n    \"\"\"\n    Plots a bar graph of F1 scores per class based on ground truth and predicted classifications.\n\n    Args:\n        adata (AnnData): Annotated data matrix.\n        ground_truth (str, optional): The column name in `adata.obs` containing the true class labels. Defaults to \"celltype\".\n        class_prediction (str, optional): The column name in `adata.obs` containing the predicted class labels. Defaults to \"SCN_class\".\n\n    Returns:\n        None\n    \"\"\"\n    # Calculate F1 scores\n    fscore = f1_score(\n        adata.obs[ground_truth], \n        adata.obs[class_prediction], \n        average=None, \n        labels=adata.obs[ground_truth].cat.categories\n    )\n\n    # Get category names\n    cates = list(adata.obs[ground_truth].cat.categories)\n\n    # Create a DataFrame for F1 scores\n    f1_scores_df = pd.DataFrame({\n        'Class': cates,\n        'F1-Score': fscore,\n        'Count': adata.obs[ground_truth].value_counts().reindex(cates).values\n    })\n\n    # Get colors from the .uns dictionary\n    f1_scores_df['Color'] = f1_scores_df['Class'].map(adata.uns['SCN_class_colors'])\n\n    plt.rcParams['figure.constrained_layout.use'] = True\n    # sns.set_theme(style=\"whitegrid\")\n\n    # fig, ax = plt.subplots(layout=\"constrained\")\n    fig, ax = plt.subplots()\n\n    text_size = max(min(12 - len(cates) // 2, 10), 7) # Adjust text size\n    # Plot the F1 scores with colors\n    ax = f1_scores_df.plot.barh(\n        x='Class', \n        y='F1-Score', \n        color=f1_scores_df['Color'], \n        legend=False,\n        width=bar_height\n    )\n\n    ax.set_xlabel('F1-Score')\n    ax.set_title('F1-Scores per Class')\n    ax.set_xlim(0, 1.1)  # Set x-axis limits to ensure visibility of all bars\n\n    # Add the number of observations per class as text within the barplot\n    for i, (count, fscore) in enumerate(zip(f1_scores_df['Count'], f1_scores_df['F1-Score'])):\n        ax.text(0.03, i, f\"n = {count}\", ha='left', va='center', color='white' if fscore &gt;= 0.20 else 'black', fontsize=text_size)\n\n    # plt.show()\n    return fig\n</code></pre>"},{"location":"plotting.html#pySingleCellNet.plotting.bar_compare_celltype_composition","title":"bar_compare_celltype_composition","text":"<pre><code>bar_compare_celltype_composition(adata1, adata2, celltype_col, min_delta, colors=None, metric='log_ratio')\n</code></pre> <p>Compare cell type proportions between two AnnData objects and plot either log-ratio or differences for significant changes.</p> <p>Parameters:</p> <ul> <li> <code>adata1</code>               (<code>AnnData</code>)           \u2013            <p>First AnnData object.</p> </li> <li> <code>adata2</code>               (<code>AnnData</code>)           \u2013            <p>Second AnnData object.</p> </li> <li> <code>celltype_col</code>               (<code>str</code>)           \u2013            <p>Column name in <code>.obs</code> indicating cell types.</p> </li> <li> <code>min_delta</code>               (<code>float</code>)           \u2013            <p>Minimum absolute difference in percentages to include in the plot.</p> </li> <li> <code>colors</code>               (<code>dict</code>, default:                   <code>None</code> )           \u2013            <p>Dictionary with cell types as keys and colors as values for the bars.</p> </li> <li> <code>metric</code>               (<code>str</code>, default:                   <code>'log_ratio'</code> )           \u2013            <p>\"log_ratio\" (default) or \"difference\" to specify which metric to plot.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>None</code>          \u2013            <p>Displays the bar plot.</p> </li> </ul> Source code in <code>src/pySingleCellNet/plotting/bar.py</code> <pre><code>def bar_compare_celltype_composition(adata1, adata2, celltype_col, min_delta, colors=None, metric=\"log_ratio\"):\n    \"\"\"\n    Compare cell type proportions between two AnnData objects and plot either log-ratio or differences for significant changes.\n\n    Parameters:\n        adata1 (AnnData): First AnnData object.\n        adata2 (AnnData): Second AnnData object.\n        celltype_col (str): Column name in `.obs` indicating cell types.\n        min_delta (float): Minimum absolute difference in percentages to include in the plot.\n        colors (dict, optional): Dictionary with cell types as keys and colors as values for the bars.\n        metric (str, optional): \"log_ratio\" (default) or \"difference\" to specify which metric to plot.\n\n    Returns:\n        None: Displays the bar plot.\n    \"\"\"\n    # Compute cell type percentages for both AnnData objects\n    def compute_percentages(adata, celltype_col):\n        cell_counts = adata.obs[celltype_col].value_counts(normalize=True) * 100\n        return cell_counts\n\n    percentages_adata1 = compute_percentages(adata1, celltype_col)\n    percentages_adata2 = compute_percentages(adata2, celltype_col)\n\n    # Align indices to ensure comparison\n    all_celltypes = percentages_adata1.index.union(percentages_adata2.index)\n    percentages_adata1 = percentages_adata1.reindex(all_celltypes, fill_value=0)\n    percentages_adata2 = percentages_adata2.reindex(all_celltypes, fill_value=0)\n\n    # Compute the differences and log-ratio\n    differences = percentages_adata1 - percentages_adata2\n    log_ratios = np.log2((percentages_adata1 + 1e-6) / (percentages_adata2 + 1e-6))  # Avoid division by zero\n\n    # Choose the metric to plot\n    if metric == \"log_ratio\":\n        plot_values = log_ratios\n        xlabel = \"Log2(Percent in A / Percent in B)\"\n        title = \"Log2 Ratio of Cell Type Percentages\"\n    elif metric == \"difference\":\n        plot_values = differences\n        xlabel = \"Difference in Percentages (A - B)\"\n        title = \"Difference in Cell Type Percentages\"\n    else:\n        raise ValueError(\"Invalid metric. Choose either 'log_ratio' or 'difference'.\")\n\n    # Filter cell types by the threshold\n    significant_celltypes = plot_values[abs(differences) &gt; min_delta].index\n\n    # Prepare data for plotting\n    plot_data = plot_values[significant_celltypes].sort_values()\n\n    # Determine colors for the bars (align with sorted data)\n    if colors:\n        bar_colors = [tuple(map(float, colors[cell_type])) if cell_type in colors else 'skyblue' for cell_type in plot_data.index]\n    else:\n        bar_colors = 'skyblue'\n\n    # Debugging: Log the bar colors and sorted cell types\n    # print(\"Sorted Cell Types:\", plot_data.index.tolist())\n    # print(\"Bar Colors:\", bar_colors)\n\n    # Create the horizontal bar plot\n    plt.figure(figsize=(10, 6))\n    plot_data.plot(kind='barh', color=bar_colors, edgecolor='black')\n    # plt.axvline(0, color='gray', linestyle='--', linewidth=1)\n    plt.axvline(0, color='black', linewidth=1)\n    # plt.title(title)\n    plt.xlabel(xlabel)\n    # plt.ylabel(\"Cell Types\")\n    plt.tight_layout()\n    plt.show()\n</code></pre>"},{"location":"plotting.html#pySingleCellNet.plotting.heatmap_gsea","title":"heatmap_gsea","text":"<pre><code>heatmap_gsea(gmat, clean_signatures=False, clean_cells=False, column_colors=None, figsize=(8, 6), label_font_size=7, cbar_pos=[0.2, 0.92, 0.6, 0.02], dendro_ratio=(0.3, 0.1), cbar_title='NES', col_cluster=False, row_cluster=False)\n</code></pre> <p>Generates a heatmap with hierarchical clustering for gene set enrichment analysis (GSEA) results.</p> <p>Parameters:</p> <ul> <li> <code>gmat</code>               (<code>DataFrame</code>)           \u2013            <p>A matrix of GSEA scores with gene sets as rows and samples as columns.</p> </li> <li> <code>clean_signatures</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If True, removes gene sets with zero enrichment scores across all samples. Defaults to False.</p> </li> <li> <code>clean_cells</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If True, removes samples with zero enrichment scores across all gene sets. Defaults to False.</p> </li> <li> <code>column_colors</code>               (<code>Series or DataFrame</code>, default:                   <code>None</code> )           \u2013            <p>Colors to annotate columns, typically representing sample groups. Defaults to None.</p> </li> <li> <code>figsize</code>               (<code>tuple</code>, default:                   <code>(8, 6)</code> )           \u2013            <p>Figure size in inches (width, height). Defaults to (8, 6).</p> </li> <li> <code>label_font_size</code>               (<code>int</code>, default:                   <code>7</code> )           \u2013            <p>Font size for axis and colorbar labels. Defaults to 7.</p> </li> <li> <code>cbar_pos</code>               (<code>list</code>, default:                   <code>[0.2, 0.92, 0.6, 0.02]</code> )           \u2013            <p>Position of the colorbar [left, bottom, width, height]. Defaults to [0.2, 0.92, 0.6, 0.02] for a horizontal top placement.</p> </li> <li> <code>dendro_ratio</code>               (<code>tuple</code>, default:                   <code>(0.3, 0.1)</code> )           \u2013            <p>Proportion of the figure allocated to the row and column dendrograms. Defaults to (0.3, 0.1).</p> </li> <li> <code>cbar_title</code>               (<code>str</code>, default:                   <code>'NES'</code> )           \u2013            <p>Title of the colorbar. Defaults to 'NES'.</p> </li> <li> <code>col_cluster</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If True, performs hierarchical clustering on columns. Defaults to False.</p> </li> <li> <code>row_cluster</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If True, performs hierarchical clustering on rows. Defaults to False.</p> </li> </ul> <p>Returns:</p> <ul> <li>           \u2013            <p>None</p> </li> </ul> Displays <p>A heatmap with optional hierarchical clustering and a horizontal colorbar at the top.</p> Source code in <code>src/pySingleCellNet/plotting/heatmap.py</code> <pre><code>def heatmap_gsea(\n    gmat,\n    clean_signatures=False,\n    clean_cells=False,\n    column_colors=None,\n    figsize=(8, 6),\n    label_font_size=7,\n    cbar_pos=[0.2, 0.92, 0.6, 0.02],  # Positioned at the top\n    dendro_ratio=(0.3, 0.1),\n    cbar_title='NES',\n    col_cluster=False,\n    row_cluster=False,\n):\n    \"\"\"\n    Generates a heatmap with hierarchical clustering for gene set enrichment analysis (GSEA) results.\n\n    Args:\n        gmat (pd.DataFrame):\n            A matrix of GSEA scores with gene sets as rows and samples as columns.\n        clean_signatures (bool, optional):\n            If True, removes gene sets with zero enrichment scores across all samples. Defaults to False.\n        clean_cells (bool, optional):\n            If True, removes samples with zero enrichment scores across all gene sets. Defaults to False.\n        column_colors (pd.Series or pd.DataFrame, optional):\n            Colors to annotate columns, typically representing sample groups. Defaults to None.\n        figsize (tuple, optional):\n            Figure size in inches (width, height). Defaults to (8, 6).\n        label_font_size (int, optional):\n            Font size for axis and colorbar labels. Defaults to 7.\n        cbar_pos (list, optional):\n            Position of the colorbar [left, bottom, width, height]. Defaults to [0.2, 0.92, 0.6, 0.02] for a horizontal top placement.\n        dendro_ratio (tuple, optional):\n            Proportion of the figure allocated to the row and column dendrograms. Defaults to (0.3, 0.1).\n        cbar_title (str, optional):\n            Title of the colorbar. Defaults to 'NES'.\n        col_cluster (bool, optional):\n            If True, performs hierarchical clustering on columns. Defaults to False.\n        row_cluster (bool, optional):\n            If True, performs hierarchical clustering on rows. Defaults to False.\n\n    Returns:\n        None\n\n    Displays:\n        A heatmap with optional hierarchical clustering and a horizontal colorbar at the top.\n    \"\"\"\n    gsea_matrix = gmat.copy()\n    if clean_cells:\n        gsea_matrix = gsea_matrix.loc[:, gsea_matrix.sum(0) != 0]\n    if clean_signatures:\n        gsea_matrix = gsea_matrix.loc[gsea_matrix.sum(1) != 0, :]\n\n    # plt.figure(constrained_layout=True)\n    ax = sns.clustermap(\n        data=gsea_matrix,\n        cmap=Roma_20.mpl_colormap.reversed(),\n        center=0,\n        yticklabels=1,\n        xticklabels=1,\n        linewidth=.05,\n        linecolor='white',\n        method='average',\n        metric='euclidean',\n        dendrogram_ratio=dendro_ratio,\n        col_colors=column_colors,\n        figsize=figsize,\n        row_cluster=row_cluster,\n        col_cluster=col_cluster,\n        cbar_pos=cbar_pos,\n        cbar_kws={'orientation': 'horizontal'}\n    )\n\n    ax.ax_cbar.set_title(cbar_title, fontsize=label_font_size, pad=10)\n    ax.ax_cbar.tick_params(labelsize=label_font_size, direction='in')\n\n    # Adjust tick labels and heatmap appearance\n    ax.ax_row_dendrogram.set_visible(False)\n    ax.ax_col_dendrogram.set_visible(False)\n    ax.ax_heatmap.set_yticklabels(ax.ax_heatmap.get_ymajorticklabels(), fontsize=label_font_size)\n    ax.ax_heatmap.set_xticklabels(ax.ax_heatmap.get_xmajorticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\", fontsize=label_font_size)\n\n    # plt.subplots_adjust(top=0.85)\n    plt.show()\n</code></pre>"},{"location":"plotting.html#pySingleCellNet.plotting.heatmap_scores","title":"heatmap_scores","text":"<pre><code>heatmap_scores(adata, groupby, vmin=0, vmax=1, obsm_name='SCN_score', order_by=None, figure_subplot_bottom=0.4)\n</code></pre> <p>Plots a heatmap of single cell scores, grouping cells according to a specified .obs column and optionally ordering within each group.</p> <p>Parameters:</p> <ul> <li> <code>adata</code>               (<code>AnnData</code>)           \u2013            <p>An AnnData object containing the single cell data.</p> </li> <li> <code>groupby</code>               (<code>str</code>)           \u2013            <p>The name of the column in .obs used for grouping cells in the heatmap.</p> </li> <li> <code>vmin</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>Minimum value for color scaling. Defaults to 0.</p> </li> <li> <code>vmax</code>               (<code>float</code>, default:                   <code>1</code> )           \u2013            <p>Maximum value for color scaling. Defaults to 1.</p> </li> <li> <code>obsm_name</code>               (<code>str</code>, default:                   <code>'SCN_score'</code> )           \u2013            <p>The key in .obsm to retrieve the matrix for plotting. Defaults to 'SCN_score'.</p> </li> <li> <code>order_by</code>               (<code>str</code>, default:                   <code>None</code> )           \u2013            <p>The name of the column in .obs used for ordering cells within each group. Defaults to None.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>None</code>          \u2013            <p>The function plots a heatmap and does not return any value.</p> </li> </ul> Source code in <code>src/pySingleCellNet/plotting/heatmap.py</code> <pre><code>def heatmap_scores(\n    adata: AnnData, \n    groupby: str, \n    vmin: float = 0, \n    vmax: float = 1, \n    obsm_name='SCN_score', \n    order_by: str = None,\n    figure_subplot_bottom: float = 0.4\n):\n    \"\"\"\n    Plots a heatmap of single cell scores, grouping cells according to a specified .obs column and optionally ordering within each group.\n\n    Args:\n        adata (AnnData): An AnnData object containing the single cell data.\n        groupby (str): The name of the column in .obs used for grouping cells in the heatmap.\n        vmin (float, optional): Minimum value for color scaling. Defaults to 0.\n        vmax (float, optional): Maximum value for color scaling. Defaults to 1.\n        obsm_name (str, optional): The key in .obsm to retrieve the matrix for plotting. Defaults to 'SCN_score'.\n        order_by (str, optional): The name of the column in .obs used for ordering cells within each group. Defaults to None.\n\n    Returns:\n        None: The function plots a heatmap and does not return any value.\n    \"\"\"\n    # Create a temporary AnnData object with the scores matrix and all original observations\n    adTemp = AnnData(adata.obsm[obsm_name], obs=adata.obs)\n\n    # Determine sorting criteria\n    if order_by is not None:\n        sort_criteria = [groupby, order_by]\n    else:\n        sort_criteria = [groupby]\n\n    # Determine the order of cells by sorting based on the criteria\n    sorted_order = adTemp.obs.sort_values(by=sort_criteria).index\n\n    # Reorder adTemp according to the sorted order\n    adTemp = adTemp[sorted_order, :]\n\n    # Set figure dimensions and subplot adjustments\n    # fsize = [5, 6]\n    # plt.rcParams['figure.subplot.bottom'] = figure_subplot_bottom\n\n    # Plot the heatmap with the sorted and grouped data\n    with plt.rc_context({'figure.subplot.bottom': figure_subplot_bottom}):\n        sc.pl.heatmap(adTemp, adTemp.var_names.values, groupby=groupby, cmap=Batlow_20.mpl_colormap,dendrogram=False, swap_axes=True, vmin=vmin, vmax=vmax)\n</code></pre>"},{"location":"plotting.html#pySingleCellNet.plotting.make_bivariate_cmap","title":"make_bivariate_cmap","text":"<pre><code>make_bivariate_cmap(c00='#f0f0f0', c10='#e31a1c', c01='#1f78b4', c11='#ffff00', n=128)\n</code></pre> <p>Create a bivariate colormap by bilinear\u2010interpolating four corner colors.</p> <p>This builds an (n \u00d7 n) grid of RGB colors, blending smoothly between the specified corner colors:   - c00 at (low, low)   - c10 at (high, low)   - c01 at (low, high)   - c11 at (high, high)</p> <p>Parameters:</p> <ul> <li> <code>c00</code>               (<code>str</code>, default:                   <code>'#f0f0f0'</code> )           \u2013            <p>Matplotlib color spec (hex, name, or RGB tuple) for the low/low corner.</p> </li> <li> <code>c10</code>               (<code>str</code>, default:                   <code>'#e31a1c'</code> )           \u2013            <p>Color for the high/low corner.</p> </li> <li> <code>c01</code>               (<code>str</code>, default:                   <code>'#1f78b4'</code> )           \u2013            <p>Color for the low/high corner.</p> </li> <li> <code>c11</code>               (<code>str</code>, default:                   <code>'#ffff00'</code> )           \u2013            <p>Color for the high/high corner.</p> </li> <li> <code>n</code>               (<code>int</code>, default:                   <code>128</code> )           \u2013            <p>Resolution per axis. The total length of the returned colormap is n*n.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ListedColormap</code> (              <code>ListedColormap</code> )          \u2013            <p>A colormap with n*n entries blending between the four corners.</p> </li> </ul> Source code in <code>src/pySingleCellNet/plotting/helpers.py</code> <pre><code>def make_bivariate_cmap(\n    c00: str = \"#f0f0f0\",\n    c10: str = \"#e31a1c\",\n    c01: str = \"#1f78b4\",\n    c11: str = \"#ffff00\",\n    n: int = 128\n) -&gt; ListedColormap:\n    \"\"\"Create a bivariate colormap by bilinear\u2010interpolating four corner colors.\n\n    This builds an (n \u00d7 n) grid of RGB colors, blending smoothly between\n    the specified corner colors:\n      - c00 at (low, low)\n      - c10 at (high, low)\n      - c01 at (low, high)\n      - c11 at (high, high)\n\n    Args:\n        c00: Matplotlib color spec (hex, name, or RGB tuple) for the low/low corner.\n        c10: Color for the high/low corner.\n        c01: Color for the low/high corner.\n        c11: Color for the high/high corner.\n        n:   Resolution per axis. The total length of the returned colormap is n*n.\n\n    Returns:\n        ListedColormap: A colormap with n*n entries blending between the four corners.\n    \"\"\"\n    # Convert corner colors to RGB arrays\n    corners = {\n        (0, 0): np.array(to_rgb(c00)),\n        (1, 0): np.array(to_rgb(c10)),\n        (0, 1): np.array(to_rgb(c01)),\n        (1, 1): np.array(to_rgb(c11)),\n    }\n\n    # Build an (n, n, 3) grid by bilinear interpolation\n    lut = np.zeros((n, n, 3), dtype=float)\n    xs = np.linspace(0, 1, n)\n    ys = np.linspace(0, 1, n)\n    for j, y in enumerate(ys):\n        for i, x in enumerate(xs):\n            lut[j, i] = (\n                corners[(0, 0)] * (1 - x) * (1 - y) +\n                corners[(1, 0)] * x       * (1 - y) +\n                corners[(0, 1)] * (1 - x) * y       +\n                corners[(1, 1)] * x       * y\n            )\n\n    # Flatten to (n*n, 3) and return as a ListedColormap\n    return ListedColormap(lut.reshape(n * n, 3))\n</code></pre>"},{"location":"plotting.html#pySingleCellNet.plotting.scatter_genes_oneper","title":"scatter_genes_oneper","text":"<pre><code>scatter_genes_oneper(adata, genes, embedding_key='X_spatial', spot_size=2, alpha=0.9, clip_percentiles=(0, 99.5), log_transform=True, cmap='Reds', figsize=None, panel_width=4.0, n_rows=1)\n</code></pre> <p>Plot expression of multiple genes on a 2D embedding arranged in a grid.</p> <p>Each gene is optionally log-transformed, percentile-clipped, and rescaled to [0,1]. Cells are plotted on the embedding, colored by expression, with highest values drawn on top. A single colorbar is placed to the right of the grid. If <code>figsize</code> is None, each panel has width <code>panel_width</code> and height proportional to the embedding's aspect ratio; total figure dims reflect <code>n_rows</code> and computed columns.</p> <p>Parameters:</p> <ul> <li> <code>adata</code>               (<code>AnnData</code>)           \u2013            <p>AnnData containing the embedding in <code>adata.obsm[embedding_key]</code>.</p> </li> <li> <code>embedding_key</code>               (<code>str</code>, default:                   <code>'X_spatial'</code> )           \u2013            <p>Key in <code>.obsm</code> for an (n_obs, 2) coordinate array.</p> </li> <li> <code>genes</code>               (<code>Sequence[str]</code>)           \u2013            <p>List of gene names to plot (must be in <code>adata.var_names</code>).</p> </li> <li> <code>spot_size</code>               (<code>float</code>, default:                   <code>2</code> )           \u2013            <p>Marker size for scatter plots. Default 2.</p> </li> <li> <code>alpha</code>               (<code>float</code>, default:                   <code>0.9</code> )           \u2013            <p>Transparency for markers. Default 0.9.</p> </li> <li> <code>clip_percentiles</code>               (<code>tuple</code>, default:                   <code>(0, 99.5)</code> )           \u2013            <p>(low_pct, high_pct) to clip expression before rescaling.</p> </li> <li> <code>log_transform</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If True, apply <code>np.log1p</code> to raw expression.</p> </li> <li> <code>cmap</code>               (<code>Union[str, Colormap]</code>, default:                   <code>'Reds'</code> )           \u2013            <p>Colormap or name for all plots.</p> </li> <li> <code>figsize</code>               (<code>Optional[tuple]</code>, default:                   <code>None</code> )           \u2013            <p>(width, height) of entire figure. If None, computed from <code>panel_width</code>, <code>n_rows</code>, and embedding aspect ratio.</p> </li> <li> <code>panel_width</code>               (<code>float</code>, default:                   <code>4.0</code> )           \u2013            <p>Width (in inches) of each panel when <code>figsize</code> is None.</p> </li> <li> <code>n_rows</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>Number of rows in the grid. Default 1.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If embedding is missing/malformed or genes not found.</p> </li> </ul> Source code in <code>src/pySingleCellNet/plotting/spatial.py</code> <pre><code>def scatter_genes_oneper(\n    adata: AnnData,\n    genes: Sequence[str],\n    embedding_key: str = \"X_spatial\",\n    spot_size: float = 2,\n    alpha: float = 0.9,\n    clip_percentiles: tuple = (0, 99.5),\n    log_transform: bool = True,\n    cmap: Union[str, plt.Colormap] = 'Reds',\n    figsize: Optional[tuple] = None,\n    panel_width: float = 4.0,\n    n_rows: int = 1\n) -&gt; None:\n    \"\"\"Plot expression of multiple genes on a 2D embedding arranged in a grid.\n\n    Each gene is optionally log-transformed, percentile-clipped, and rescaled to [0,1].\n    Cells are plotted on the embedding, colored by expression, with highest values\n    drawn on top. A single colorbar is placed to the right of the grid.\n    If `figsize` is None, each panel has width `panel_width` and height\n    proportional to the embedding's aspect ratio; total figure dims reflect\n    `n_rows` and computed columns.\n\n    Args:\n        adata: AnnData containing the embedding in `adata.obsm[embedding_key]`.\n        embedding_key: Key in `.obsm` for an (n_obs, 2) coordinate array.\n        genes: List of gene names to plot (must be in `adata.var_names`).\n        spot_size: Marker size for scatter plots. Default 2.\n        alpha: Transparency for markers. Default 0.9.\n        clip_percentiles: (low_pct, high_pct) to clip expression before rescaling.\n        log_transform: If True, apply `np.log1p` to raw expression.\n        cmap: Colormap or name for all plots.\n        figsize: (width, height) of entire figure. If None, computed from\n            `panel_width`, `n_rows`, and embedding aspect ratio.\n        panel_width: Width (in inches) of each panel when `figsize` is None.\n        n_rows: Number of rows in the grid. Default 1.\n\n    Raises:\n        ValueError: If embedding is missing/malformed or genes not found.\n    \"\"\"\n    # Helper to extract array\n    def _get_array(x):\n        return x.toarray().flatten() if hasattr(x, 'toarray') else x.flatten()\n\n    coords = adata.obsm.get(embedding_key)\n    if coords is None or coords.ndim != 2 or coords.shape[1] &lt; 2:\n        raise ValueError(f\"adata.obsm['{embedding_key}'] must be an (n_obs, 2) array.\")\n    x_vals, y_vals = coords[:, 0], coords[:, 1]\n\n    n_genes = len(genes)\n    cols = math.ceil(n_genes / n_rows)\n    # Compute figsize if not provided\n    if figsize is None:\n        x_range = x_vals.max() - x_vals.min()\n        y_range = y_vals.max() - y_vals.min()\n        aspect = x_range / y_range if y_range &gt; 0 else 1.0\n        panel_height = panel_width / aspect\n        fig_width = panel_width * cols\n        fig_height = panel_height * n_rows\n    else:\n        fig_width, fig_height = figsize\n\n    fig, axes = plt.subplots(n_rows, cols, figsize=(fig_width, fig_height), squeeze=False)\n    axes_flat = axes.flatten()\n\n    scatters = []\n    for idx, gene in enumerate(genes):\n        ax = axes_flat[idx]\n        if gene not in adata.var_names:\n            raise ValueError(f\"Gene '{gene}' not found in adata.var_names.\")\n        vals = _get_array(adata[:, gene].X)\n        if log_transform:\n            vals = np.log1p(vals)\n        lo, hi = np.percentile(vals, clip_percentiles)\n        clipped = np.clip(vals, lo, hi)\n        norm = (clipped - lo) / (hi - lo) if hi &gt; lo else np.zeros_like(clipped)\n\n        order = np.argsort(norm)\n        sc = ax.scatter(\n            x_vals[order],\n            y_vals[order],\n            c=norm[order],\n            cmap=cmap,\n            s=spot_size,\n            alpha=alpha,\n            vmin=0, vmax=1\n        )\n        ax.set_title(gene)\n        ax.set_xticks([]); ax.set_yticks([])\n        scatters.append(sc)\n\n    # Turn off unused axes\n    for j in range(len(genes), n_rows*cols):\n        axes_flat[j].axis('off')\n\n    # Adjust subplots to make room for colorbar\n    fig.subplots_adjust(right=0.85)\n\n    # Colorbar axis on the right, spanning full height (15% margin)\n    cbar_ax = fig.add_axes([0.88, 0.05, 0.02, 0.9])\n    cb = fig.colorbar(scatters[0], cax=cbar_ax)\n    cb.set_label('normalized expression')\n\n    plt.tight_layout(rect=[0, 0, 0.85, 1])\n    plt.show()\n</code></pre>"},{"location":"plotting.html#pySingleCellNet.plotting.scatter_qc_adata","title":"scatter_qc_adata","text":"<pre><code>scatter_qc_adata(adata, title_suffix='')\n</code></pre> <p>Creates a figure with two scatter plot panels for visualizing data from an AnnData object.</p> <p>The first panel shows 'total_counts' vs 'n_genes_by_counts', colored by 'pct_counts_mt'. The second panel shows 'n_genes_by_counts' vs 'pct_counts_mt'. An optional title suffix can be added to customize the axis titles.</p> <p>Parameters:</p> <ul> <li> <code>adata</code>               (<code>AnnData</code>)           \u2013            <p>The AnnData object containing the dataset.              Must contain 'total_counts', 'n_genes_by_counts', and 'pct_counts_mt' in <code>adata.obs</code>.</p> </li> <li> <code>title_suffix</code>               (<code>str</code>, default:                   <code>''</code> )           \u2013            <p>A string to append to the axis titles, useful for specifying                           experimental conditions (e.g., \"C11 day 2\"). Defaults to an empty string.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>None</code>          \u2013            <p>The function displays a matplotlib figure with two scatter plots.</p> </li> </ul> Example <p>plot_scatter_with_contours(adata, title_suffix=\"C11 day 2\")</p> Source code in <code>src/pySingleCellNet/plotting/scatter.py</code> <pre><code>def scatter_qc_adata(adata, title_suffix=\"\"):\n    \"\"\"\n    Creates a figure with two scatter plot panels for visualizing data from an AnnData object.\n\n    The first panel shows 'total_counts' vs 'n_genes_by_counts', colored by 'pct_counts_mt'.\n    The second panel shows 'n_genes_by_counts' vs 'pct_counts_mt'. An optional title suffix\n    can be added to customize the axis titles.\n\n    Args:\n        adata (AnnData): The AnnData object containing the dataset.\n                         Must contain 'total_counts', 'n_genes_by_counts', and 'pct_counts_mt' in `adata.obs`.\n        title_suffix (str, optional): A string to append to the axis titles, useful for specifying\n                                      experimental conditions (e.g., \"C11 day 2\"). Defaults to an empty string.\n\n    Returns:\n        None: The function displays a matplotlib figure with two scatter plots.\n\n    Example:\n        &gt;&gt;&gt; plot_scatter_with_contours(adata, title_suffix=\"C11 day 2\")\n    \"\"\"\n\n    # Extract necessary columns from the adata object\n    total_counts = adata.obs['total_counts']\n    n_genes_by_counts = adata.obs['n_genes_by_counts']\n    pct_counts_mt = adata.obs['pct_counts_mt']\n\n    # Create a figure with two subplots (1 row, 2 columns)\n    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n\n    # First subplot: total_counts vs n_genes_by_counts, colored by pct_counts_mt\n    scatter1 = axes[0].scatter(total_counts, n_genes_by_counts, c=pct_counts_mt, cmap='viridis', alpha=0.5, s=1)\n    axes[0].set_xlabel(f'Total Counts ({title_suffix})')\n    axes[0].set_ylabel(f'Number of Genes by Counts ({title_suffix})')\n    axes[0].set_title(f'Total Counts vs Genes ({title_suffix})')\n    # Add a colorbar\n    fig.colorbar(scatter1, ax=axes[0], label='% Mito')\n\n    # Second subplot: n_genes_by_counts vs pct_counts_mt\n    scatter2 = axes[1].scatter(n_genes_by_counts, pct_counts_mt, alpha=0.5, s=1)\n    axes[1].set_xlabel(f'Number of Genes by Counts ({title_suffix})')\n    axes[1].set_ylabel(f'% Mito ({title_suffix})')\n    axes[1].set_title(f'Genes vs % Mito ({title_suffix})')\n\n    # Adjust layout to avoid overlap\n    plt.tight_layout()\n\n    # Show the plot\n    plt.show()\n</code></pre>"},{"location":"plotting.html#pySingleCellNet.plotting.spatial_contours","title":"spatial_contours","text":"<pre><code>spatial_contours(adata, genes, spatial_key='spatial', summary_func=np.mean, spot_size=30, alpha=0.8, log_transform=True, clip_percentiles=(1, 99), cmap='viridis', contour_kwargs=None, scatter_kwargs=None)\n</code></pre> <p>Scatter spatial expression of one or more genes with smooth contour overlay.</p> <p>If multiple genes are provided, each is preprocessed (log1p \u2192 clip \u2192 normalize), then combined per cell via <code>summary_func</code> (e.g. mean, sum, max) on the normalized values. A smooth contour of the summarized signal is overlaid onto the spatial scatter.</p> <p>Parameters:</p> <ul> <li> <code>adata</code>               (<code>AnnData</code>)           \u2013            <p>AnnData with spatial coordinates in <code>adata.obsm[spatial_key]</code>.</p> </li> <li> <code>genes</code>               (<code>Union[str, Sequence[str]]</code>)           \u2013            <p>Single gene name or list of gene names to plot (must be in <code>adata.var_names</code>).</p> </li> <li> <code>spatial_key</code>               (<code>str</code>, default:                   <code>'spatial'</code> )           \u2013            <p>Key in <code>.obsm</code> for an (n_obs, 2) coords array.</p> </li> <li> <code>summary_func</code>               (<code>Callable[[ndarray], ndarray]</code>, default:                   <code>mean</code> )           \u2013            <p>Function to combine multiple normalized gene arrays (takes an (n_obs, n_genes) array, returns length-n_obs array). Defaults to <code>np.mean</code>.</p> </li> <li> <code>spot_size</code>               (<code>float</code>, default:                   <code>30</code> )           \u2013            <p>Scatter marker size.</p> </li> <li> <code>alpha</code>               (<code>float</code>, default:                   <code>0.8</code> )           \u2013            <p>Scatter alpha transparency.</p> </li> <li> <code>log_transform</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If True, apply <code>np.log1p</code> to raw expression before clipping.</p> </li> <li> <code>clip_percentiles</code>               (<code>tuple</code>, default:                   <code>(1, 99)</code> )           \u2013            <p>Tuple <code>(low_pct, high_pct)</code> percentiles to clip each gene.</p> </li> <li> <code>cmap</code>               (<code>str</code>, default:                   <code>'viridis'</code> )           \u2013            <p>Colormap name for the scatter (e.g. 'viridis').</p> </li> <li> <code>contour_kwargs</code>               (<code>dict</code>, default:                   <code>None</code> )           \u2013            <p>Dict of parameters for smoothing &amp; contouring: - levels: int or list of levels (default 6) - grid_res: int grid resolution (default 200) - smooth_sigma: float Gaussian blur sigma (default 2) - contour_kwargs: dict of line style kwargs (default {'colors':'k','linewidths':1})</p> </li> <li> <code>scatter_kwargs</code>               (<code>dict</code>, default:                   <code>None</code> )           \u2013            <p>Extra kwargs passed to <code>ax.scatter</code>.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If any gene is missing or spatial coords are malformed.</p> </li> </ul> Source code in <code>src/pySingleCellNet/plotting/spatial.py</code> <pre><code>def spatial_contours(\n    adata: AnnData,\n    genes: Union[str, Sequence[str]],\n    spatial_key: str = 'spatial',\n    summary_func: Callable[[np.ndarray], np.ndarray] = np.mean,\n    spot_size: float = 30,\n    alpha: float = 0.8,\n    log_transform: bool = True,\n    clip_percentiles: tuple = (1, 99),\n    cmap: str = 'viridis',\n    contour_kwargs: dict = None,\n    scatter_kwargs: dict = None\n) -&gt; None:\n    \"\"\"Scatter spatial expression of one or more genes with smooth contour overlay.\n\n    If multiple genes are provided, each is preprocessed (log1p \u2192 clip\n    \u2192 normalize), then combined per cell via `summary_func` (e.g. mean, sum,\n    max) on the normalized values. A smooth contour of the summarized signal\n    is overlaid onto the spatial scatter.\n\n    Args:\n        adata: AnnData with spatial coordinates in `adata.obsm[spatial_key]`.\n        genes: Single gene name or list of gene names to plot (must be in `adata.var_names`).\n        spatial_key: Key in `.obsm` for an (n_obs, 2) coords array.\n        summary_func: Function to combine multiple normalized gene arrays\n            (takes an (n_obs, n_genes) array, returns length-n_obs array).\n            Defaults to `np.mean`.\n        spot_size: Scatter marker size.\n        alpha: Scatter alpha transparency.\n        log_transform: If True, apply `np.log1p` to raw expression before clipping.\n        clip_percentiles: Tuple `(low_pct, high_pct)` percentiles to clip each gene.\n        cmap: Colormap name for the scatter (e.g. 'viridis').\n        contour_kwargs: Dict of parameters for smoothing &amp; contouring:\n            - levels: int or list of levels (default 6)\n            - grid_res: int grid resolution (default 200)\n            - smooth_sigma: float Gaussian blur sigma (default 2)\n            - contour_kwargs: dict of line style kwargs (default {'colors':'k','linewidths':1})\n        scatter_kwargs: Extra kwargs passed to `ax.scatter`.\n\n    Raises:\n        ValueError: If any gene is missing or spatial coords are malformed.\n    \"\"\"\n    # ensure genes is list\n    gene_list = [genes] if isinstance(genes, str) else list(genes)\n    for g in gene_list:\n        if g not in adata.var_names:\n            raise ValueError(f\"Gene '{g}' not found in adata.var_names.\")\n\n    # helper to extract numpy\n    def _get_array(x):\n        return x.toarray().flatten() if hasattr(x, 'toarray') else x.flatten()\n\n    # preprocess each gene: extract, log1p, clip, normalize to [0,1]\n    normed = []\n    for g in gene_list:\n        vals = _get_array(adata[:, g].X)\n        if log_transform:\n            vals = np.log1p(vals)\n        lo, hi = np.percentile(vals, clip_percentiles)\n        vals = np.clip(vals, lo, hi)\n        normed.append((vals - lo) / (hi - lo) if hi &gt; lo else np.zeros_like(vals))\n    # stack into (n_obs, n_genes)\n    M = np.column_stack(normed)\n    # summarize across genes\n    summary = summary_func(M, axis=1)\n\n    # fetch spatial coords\n    coords = adata.obsm.get(spatial_key)\n    if coords is None or coords.shape[1] &lt; 2:\n        raise ValueError(f\"adata.obsm['{spatial_key}'] must be an (n_obs, 2) array.\")\n    x, y = coords[:, 0], coords[:, 1]\n\n    # scatter\n    fig, ax = plt.subplots(figsize=(6, 6))\n    sc_kw = {\"c\": summary, \"cmap\": cmap, \"s\": spot_size, \"alpha\": alpha}\n    if scatter_kwargs:\n        sc_kw.update(scatter_kwargs)\n    sc = ax.scatter(x, y, **sc_kw)\n    ax.set_aspect('equal')\n    title = (\n        gene_list[0] if len(gene_list) == 1\n        else f\"{len(gene_list)} genes ({summary_func.__name__})\"\n    )\n    ax.set_title(f\"Spatial expression: {title}\")\n    ax.set_xlabel('x'); ax.set_ylabel('y')\n    fig.colorbar(sc, ax=ax, label=\"summarized (normalized)\")\n\n    # smooth + contour\n    # default contour params\n    ck = {\n        \"levels\": 6,\n        \"grid_res\": 200,\n        \"smooth_sigma\": 2,\n        \"contour_kwargs\": {\"colors\": \"k\", \"linewidths\": 1}\n    }\n    if contour_kwargs:\n        ck.update(contour_kwargs)\n    _smooth_contour(\n        x, y, summary,\n        levels=ck[\"levels\"],\n        grid_res=ck[\"grid_res\"],\n        smooth_sigma=ck[\"smooth_sigma\"],\n        contour_kwargs=ck[\"contour_kwargs\"]\n    )\n    plt.tight_layout()\n    plt.show()\n</code></pre>"},{"location":"plotting.html#pySingleCellNet.plotting.spatial_two_genes","title":"spatial_two_genes","text":"<pre><code>spatial_two_genes(adata, gene1, gene2, cmap, spot_size=2, alpha=0.9, spatial_key='X_spatial', log_transform=False, clip_percentiles=(0, 99.5), priority_metric='sum', show_xcoords=False, show_ycoords=False, show_bbox=False, show_legend=True, width_ratios=(10, 1))\n</code></pre> <p>Plot two\u2010gene spatial expression with a bivariate colormap.</p> <p>Parameters:</p> <ul> <li> <code>adata</code>               (<code>AnnData</code>)           \u2013            <p>AnnData with spatial coords in <code>adata.obsm[spatial_key]</code>.</p> </li> <li> <code>gene1</code>               (<code>str</code>)           \u2013            <p>First gene name (must be in <code>adata.var_names</code>).</p> </li> <li> <code>gene2</code>               (<code>str</code>)           \u2013            <p>Second gene name.</p> </li> <li> <code>cmap</code>               (<code>ListedColormap</code>)           \u2013            <p>Bivariate colormap from <code>make_bivariate_cmap</code> (n\u00d7n LUT).</p> </li> <li> <code>spot_size</code>               (<code>float</code>, default:                   <code>2</code> )           \u2013            <p>Scatter point size.</p> </li> <li> <code>alpha</code>               (<code>float</code>, default:                   <code>0.9</code> )           \u2013            <p>Point alpha transparency.</p> </li> <li> <code>spatial_key</code>               (<code>str</code>, default:                   <code>'X_spatial'</code> )           \u2013            <p>Key in <code>adata.obsm</code> for an (n_obs, 2) coords array.</p> </li> <li> <code>log_transform</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If True, apply <code>np.log1p</code> to raw expression.</p> </li> <li> <code>clip_percentiles</code>               (<code>tuple</code>, default:                   <code>(0, 99.5)</code> )           \u2013            <p>Tuple <code>(low_pct, high_pct)</code> to clip each gene.</p> </li> <li> <code>priority_metric</code>               (<code>str</code>, default:                   <code>'sum'</code> )           \u2013            <p>Which metric to sort drawing order by: - 'sum': u + v (default) - 'gene1': u only - 'gene2': v only</p> </li> <li> <code>show_xcoords</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to display x-axis ticks and labels.</p> </li> <li> <code>show_ycoords</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to display y-axis ticks and labels.</p> </li> <li> <code>show_bbox</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to display the bounding box (spines).</p> </li> <li> <code>show_legend</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to display the legend/colorbar.</p> </li> <li> <code>width_ratios</code>               (<code>Tuple[float, float]</code>, default:                   <code>(10, 1)</code> )           \u2013            <p>2\u2010tuple giving the relative widths of       (scatter_panel, legend_panel). Defaults to (3,1).</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If spatial coords are missing/malformed or         if <code>priority_metric</code> is invalid.</p> </li> </ul> Source code in <code>src/pySingleCellNet/plotting/spatial.py</code> <pre><code>def spatial_two_genes(\n    adata: AnnData,\n    gene1: str,\n    gene2: str,\n    cmap: ListedColormap,\n    spot_size: float = 2,\n    alpha: float = 0.9,\n    spatial_key: str = 'X_spatial',\n    log_transform: bool = False,\n    clip_percentiles: tuple = (0, 99.5),\n    priority_metric: str = 'sum',\n    show_xcoords: bool = False,\n    show_ycoords: bool = False,\n    show_bbox: bool = False,\n    show_legend: bool = True,\n    width_ratios: Tuple[float, float] = (10, 1)\n) -&gt; None:\n    \"\"\"Plot two\u2010gene spatial expression with a bivariate colormap.\n\n    Args:\n        adata: AnnData with spatial coords in `adata.obsm[spatial_key]`.\n        gene1: First gene name (must be in `adata.var_names`).\n        gene2: Second gene name.\n        cmap: Bivariate colormap from `make_bivariate_cmap` (n\u00d7n LUT).\n        spot_size: Scatter point size.\n        alpha: Point alpha transparency.\n        spatial_key: Key in `adata.obsm` for an (n_obs, 2) coords array.\n        log_transform: If True, apply `np.log1p` to raw expression.\n        clip_percentiles: Tuple `(low_pct, high_pct)` to clip each gene.\n        priority_metric: Which metric to sort drawing order by:\n            - 'sum': u + v (default)\n            - 'gene1': u only\n            - 'gene2': v only\n        show_xcoords: Whether to display x-axis ticks and labels.\n        show_ycoords: Whether to display y-axis ticks and labels.\n        show_bbox: Whether to display the bounding box (spines).\n        show_legend: Whether to display the legend/colorbar.\n        width_ratios: 2\u2010tuple giving the relative widths of\n                  (scatter_panel, legend_panel). Defaults to (3,1).\n\n    Raises:\n        ValueError: If spatial coords are missing/malformed or\n                    if `priority_metric` is invalid.\n    \"\"\"\n    # 1) extract raw arrays\n    def _get_array(x):\n        return x.toarray().flatten() if hasattr(x, 'toarray') else x.flatten()\n    X1 = _get_array(adata[:, gene1].X)\n    X2 = _get_array(adata[:, gene2].X)\n\n    # 2) optional log1p\n    if log_transform:\n        X1 = np.log1p(X1)\n        X2 = np.log1p(X2)\n\n    # 3) percentile\u2010clip\n    lo1, hi1 = np.percentile(X1, clip_percentiles)\n    lo2, hi2 = np.percentile(X2, clip_percentiles)\n    X1 = np.clip(X1, lo1, hi1)\n    X2 = np.clip(X2, lo2, hi2)\n\n    # 4) normalize to [0,1]\n    u = (X1 - lo1) / (hi1 - lo1) if hi1 &gt; lo1 else np.zeros_like(X1)\n    v = (X2 - lo2) / (hi2 - lo2) if hi2 &gt; lo2 else np.zeros_like(X2)\n\n    # 5) prepare LUT\n    m = len(cmap.colors)\n    n = int(np.sqrt(m))\n    C = np.array(cmap.colors).reshape(n, n, 3)\n\n    # 6) bilinear interpolate per\u2010cell\n    gu = u * (n - 1); gv = v * (n - 1)\n    i0 = np.floor(gu).astype(int); j0 = np.floor(gv).astype(int)\n    i1 = np.minimum(i0 + 1, n - 1); j1 = np.minimum(j0 + 1, n - 1)\n    du = gu - i0; dv = gv - j0\n\n    wa = (1 - du) * (1 - dv)\n    wb = du * (1 - dv)\n    wc = (1 - du) * dv\n    wd = du * dv\n\n    c00 = C[j0, i0]; c10 = C[j0, i1]\n    c01 = C[j1, i0]; c11 = C[j1, i1]\n\n    cols_rgb = (\n        c00 * wa[:, None] +\n        c10 * wb[:, None] +\n        c01 * wc[:, None] +\n        c11 * wd[:, None]\n    )\n    hex_colors = [to_hex(c) for c in cols_rgb]\n\n    # 7) determine draw order\n    if priority_metric == 'sum':\n        priority = u + v\n    elif priority_metric == 'gene1':\n        priority = u\n    elif priority_metric == 'gene2':\n        priority = v\n    else:\n        raise ValueError(\"priority_metric must be 'sum', 'gene1', or 'gene2'\")\n    order = np.argsort(priority)\n\n    # 8) fetch and sort coords/colors\n    coords = adata.obsm.get(spatial_key)\n    if coords is None or coords.shape[1] &lt; 2:\n        raise ValueError(f\"adata.obsm['{spatial_key}'] must be an (n_obs, 2) array\")\n    coords_sorted = coords[order]\n    colors_sorted = [hex_colors[i] for i in order]\n\n    # 9) plot scatter + optional legend\n    fig, (ax_sc, ax_cb) = plt.subplots(\n        1, 2,\n        figsize=(8, 4),\n        gridspec_kw={'width_ratios': width_ratios, 'wspace': 0.3}\n    )\n    ax_sc.scatter(\n        coords_sorted[:, 0],\n        coords_sorted[:, 1],\n        c=colors_sorted,\n        s=spot_size,\n        alpha=alpha\n    )\n    ax_sc.set_aspect('equal')\n    ax_sc.set_title(f\"{gene1} :: {gene2}\")\n\n    # axis display options\n    if not show_xcoords:\n        ax_sc.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n    if not show_ycoords:\n        ax_sc.tick_params(axis='y', which='both', left=False, right=False, labelleft=False)\n    if not show_bbox:\n        for spine in ax_sc.spines.values():\n            spine.set_visible(False)\n\n    # legend/colorbar\n    if show_legend:\n        lut_img = C  # shape (n,n,3)\n        ax_cb.imshow(lut_img, origin='lower', extent=[0, 1, 0, 1])\n        # ax_cb.set_xlabel(f\"{gene1}\\nlow \u2192 high\")\n        # ax_cb.set_ylabel(f\"{gene2}\\nlow \u2192 high\")\n        ax_cb.set_xlabel(f\"{gene1}\")\n        ax_cb.set_ylabel(f\"{gene2}\")\n        ax_cb.set_xticks([0, 1]); ax_cb.set_yticks([0, 1])\n        ax_cb.set_aspect('equal')\n    else:\n        ax_cb.axis('off')\n\n    plt.show()\n</code></pre>"},{"location":"plotting.html#pySingleCellNet.plotting.stackedbar_composition","title":"stackedbar_composition","text":"<pre><code>stackedbar_composition(adata, groupby, obs_column='SCN_class', labels=None, bar_width=0.75, color_dict=None, ax=None, order_by_similarity=False, similarity_metric='correlation', include_legend=True, legend_rows=10)\n</code></pre> <p>Plots a stacked bar chart of cell type proportions for a single AnnData object grouped by a specified column.</p> <p>Parameters:</p> <ul> <li> <code>adata</code>               (<code>AnnData</code>)           \u2013            <p>An AnnData object.</p> </li> <li> <code>groupby</code>               (<code>str</code>)           \u2013            <p>The column in <code>.obs</code> to group by.</p> </li> <li> <code>obs_column</code>               (<code>str</code>, default:                   <code>'SCN_class'</code> )           \u2013            <p>The name of the <code>.obs</code> column to use for categories. Defaults to 'SCN_class'.</p> </li> <li> <code>labels</code>               (<code>List[str]</code>, default:                   <code>None</code> )           \u2013            <p>Custom labels for each group to be displayed on the x-axis. If not provided, the unique values of the groupby column will be used. The length of <code>labels</code> must match the number of unique groups.</p> </li> <li> <code>bar_width</code>               (<code>float</code>, default:                   <code>0.75</code> )           \u2013            <p>The width of the bars in the plot. Defaults to 0.75.</p> </li> <li> <code>color_dict</code>               (<code>Dict[str, str]</code>, default:                   <code>None</code> )           \u2013            <p>A dictionary mapping categories to specific colors. If not provided, default colors will be used.</p> </li> <li> <code>ax</code>               (<code>Axes</code>, default:                   <code>None</code> )           \u2013            <p>The axis to plot on. If not provided, a new figure and axis will be created.</p> </li> <li> <code>order_by_similarity</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to order the bars by similarity in composition. Defaults to False.</p> </li> <li> <code>similarity_metric</code>               (<code>str</code>, default:                   <code>'correlation'</code> )           \u2013            <p>The metric to use for similarity ordering. Defaults to 'correlation'.</p> </li> <li> <code>include_legend</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to include a legend in the plot. Defaults to True.</p> </li> <li> <code>legend_rows</code>               (<code>int</code>, default:                   <code>10</code> )           \u2013            <p>The number of rows in the legend. Defaults to 10.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the length of <code>labels</code> does not match the number of unique groups.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; stackedbar_composition(adata, groupby='sample', obs_column='your_column_name')\n&gt;&gt;&gt; fig, ax = plt.subplots()\n&gt;&gt;&gt; stackedbar_composition(adata, groupby='sample', obs_column='your_column_name', ax=ax, include_legend=False, legend_rows=5)\n</code></pre> Source code in <code>src/pySingleCellNet/plotting/bar.py</code> <pre><code>def stackedbar_composition(\n    adata: AnnData, \n    groupby: str, \n    obs_column='SCN_class', \n    labels=None, \n    bar_width: float = 0.75, \n    color_dict=None, \n    ax=None,\n    order_by_similarity: bool = False,\n    similarity_metric: str = 'correlation',\n    include_legend: bool = True,\n    legend_rows: int = 10\n):\n    \"\"\"\n    Plots a stacked bar chart of cell type proportions for a single AnnData object grouped by a specified column.\n\n    Args:\n        adata (anndata.AnnData): An AnnData object.\n        groupby (str): The column in `.obs` to group by.\n        obs_column (str, optional): The name of the `.obs` column to use for categories. Defaults to 'SCN_class'.\n        labels (List[str], optional): Custom labels for each group to be displayed on the x-axis.\n            If not provided, the unique values of the groupby column will be used. The length of `labels` must match\n            the number of unique groups.\n        bar_width (float, optional): The width of the bars in the plot. Defaults to 0.75.\n        color_dict (Dict[str, str], optional): A dictionary mapping categories to specific colors. If not provided,\n            default colors will be used.\n        ax (matplotlib.axes.Axes, optional): The axis to plot on. If not provided, a new figure and axis will be created.\n        order_by_similarity (bool, optional): Whether to order the bars by similarity in composition. Defaults to False.\n        similarity_metric (str, optional): The metric to use for similarity ordering. Defaults to 'correlation'.\n        include_legend (bool, optional): Whether to include a legend in the plot. Defaults to True.\n        legend_rows (int, optional): The number of rows in the legend. Defaults to 10.\n\n    Raises:\n        ValueError: If the length of `labels` does not match the number of unique groups.\n\n    Examples:\n        &gt;&gt;&gt; stackedbar_composition(adata, groupby='sample', obs_column='your_column_name')\n        &gt;&gt;&gt; fig, ax = plt.subplots()\n        &gt;&gt;&gt; stackedbar_composition(adata, groupby='sample', obs_column='your_column_name', ax=ax, include_legend=False, legend_rows=5)\n    \"\"\"\n    # Ensure the groupby column exists in .obs\n    if groupby not in adata.obs.columns:\n        raise ValueError(f\"The groupby column '{groupby}' does not exist in the .obs attribute.\")\n\n    # Check if groupby column is categorical or not\n    if pd.api.types.is_categorical_dtype(adata.obs[groupby]):\n        unique_groups = adata.obs[groupby].cat.categories.to_list()\n    else:\n        unique_groups = adata.obs[groupby].unique().tolist()\n\n    # Extract unique groups and ensure labels are provided or create default ones\n    if labels is None:\n        labels = unique_groups\n    elif len(labels) != len(unique_groups):\n        raise ValueError(\"Length of 'labels' must match the number of unique groups.\")\n\n    if color_dict is None:\n        color_dict = adata.uns.get('SCN_class_colors', {})\n\n    # Extracting category proportions per group\n    category_counts = []\n    categories = set()\n    for group in unique_groups:\n        subset = adata[adata.obs[groupby] == group]\n        counts = subset.obs[obs_column].value_counts(normalize=True)\n        category_counts.append(counts)\n        categories.update(counts.index)\n\n    categories = sorted(categories)\n\n    # Preparing the data for plotting\n    proportions = np.zeros((len(categories), len(unique_groups)))\n    for i, counts in enumerate(category_counts):\n        for category in counts.index:\n            j = categories.index(category)\n            proportions[j, i] = counts[category]\n\n    # Ordering groups by similarity if requested\n    if order_by_similarity:\n        dist_matrix = pdist(proportions.T, metric=similarity_metric)\n        linkage_matrix = linkage(dist_matrix, method='average')\n        order = leaves_list(linkage_matrix)\n        proportions = proportions[:, order]\n        unique_groups = [unique_groups[i] for i in order]\n        labels = [labels[i] for i in order]\n\n    # Plotting\n    if ax is None:\n        fig, ax = plt.subplots()\n    else:\n        fig = ax.figure\n\n    bottom = np.zeros(len(unique_groups))\n    for i, category in enumerate(categories):\n        color = color_dict.get(category, None)\n        ax.bar(\n            range(len(unique_groups)), \n            proportions[i], \n            bottom=bottom, \n            label=category, \n            width=bar_width, \n            edgecolor='white', \n            linewidth=.5,\n            color=color\n        )\n        bottom += proportions[i]\n\n    ax.set_xticks(range(len(unique_groups)))\n    ax.set_xticklabels(labels, rotation=45, ha=\"right\")\n    ax.set_ylabel('Proportion')\n    ax.set_title(f'{obs_column} proportions by {groupby}')\n\n    if include_legend:\n        num_columns = int(np.ceil(len(categories) / legend_rows))\n        ax.legend(title='Classes', bbox_to_anchor=(1.05, 1), loc='upper left', ncol=num_columns)\n\n    if ax is None:\n        plt.tight_layout()\n        plt.show()\n    else:\n        return ax\n</code></pre>"},{"location":"plotting.html#pySingleCellNet.plotting.stackedbar_composition_list","title":"stackedbar_composition_list","text":"<pre><code>stackedbar_composition_list(adata_list, obs_column='SCN_class', labels=None, bar_width=0.75, color_dict=None, legend_loc='outside center right')\n</code></pre> <p>Plots a stacked bar chart of category proportions for a list of AnnData objects.</p> <p>This function takes a list of AnnData objects, and for a specified column in the <code>.obs</code> attribute, it plots a stacked bar chart. Each bar represents an AnnData object with segments showing the proportion of each category within that object.</p> <p>Parameters:</p> <ul> <li> <code>adata_list</code>               (<code>List[AnnData]</code>)           \u2013            <p>A list of AnnData objects.</p> </li> <li> <code>obs_column</code>               (<code>str</code>, default:                   <code>'SCN_class'</code> )           \u2013            <p>The name of the <code>.obs</code> column to use for categories. Defaults to 'SCN_class'.</p> </li> <li> <code>labels</code>               (<code>List[str]</code>, default:                   <code>None</code> )           \u2013            <p>Custom labels for each AnnData object to be displayed on the x-axis. If not provided, defaults to 'AnnData {i+1}' for each object. The length of <code>labels</code> must match the number of AnnData objects provided.</p> </li> <li> <code>bar_width</code>               (<code>float</code>, default:                   <code>0.75</code> )           \u2013            <p>The width of the bars in the plot. Defaults to 0.75.</p> </li> <li> <code>color_dict</code>               (<code>Dict[str, str]</code>, default:                   <code>None</code> )           \u2013            <p>A dictionary mapping categories to specific colors. If not provided, default colors will be used.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the length of <code>labels</code> does not match the number of AnnData objects.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; plot_cell_type_proportions([adata1, adata2], obs_column='your_column_name', labels=['Sample 1', 'Sample 2'])\n</code></pre> Source code in <code>src/pySingleCellNet/plotting/bar.py</code> <pre><code>def stackedbar_composition_list(\n    adata_list, \n    obs_column = 'SCN_class', \n    labels = None, \n    bar_width: float = 0.75, \n    color_dict = None,\n    legend_loc = \"outside center right\"\n):\n    \"\"\"\n    Plots a stacked bar chart of category proportions for a list of AnnData objects.\n\n    This function takes a list of AnnData objects, and for a specified column in the `.obs` attribute,\n    it plots a stacked bar chart. Each bar represents an AnnData object with segments showing the proportion\n    of each category within that object.\n\n    Args:\n        adata_list (List[anndata.AnnData]): A list of AnnData objects.\n        obs_column (str, optional): The name of the `.obs` column to use for categories. Defaults to 'SCN_class'.\n        labels (List[str], optional): Custom labels for each AnnData object to be displayed on the x-axis.\n            If not provided, defaults to 'AnnData {i+1}' for each object. The length of `labels` must match\n            the number of AnnData objects provided.\n        bar_width (float, optional): The width of the bars in the plot. Defaults to 0.75.\n        color_dict (Dict[str, str], optional): A dictionary mapping categories to specific colors. If not provided,\n            default colors will be used.\n\n    Raises:\n        ValueError: If the length of `labels` does not match the number of AnnData objects.\n\n    Examples:\n        &gt;&gt;&gt; plot_cell_type_proportions([adata1, adata2], obs_column='your_column_name', labels=['Sample 1', 'Sample 2'])\n    \"\"\"\n\n    # Ensure labels are provided, or create default ones\n    if labels is None:\n        labels = [f'AnnData {i+1}' for i in range(len(adata_list))]\n    elif len(labels) != len(adata_list):\n        raise ValueError(\"Length of 'labels' must match the number of AnnData objects provided.\")\n\n    # Extracting category proportions\n    category_counts = []\n    categories = set()\n    for adata in adata_list:\n        counts = adata.obs[obs_column].value_counts(normalize=True)\n        category_counts.append(counts)\n        categories.update(counts.index)\n\n    categories = sorted(categories)\n\n    # Preparing the data for plotting\n    proportions = np.zeros((len(categories), len(adata_list)))\n    for i, counts in enumerate(category_counts):\n        for category in counts.index:\n            j = categories.index(category)\n            proportions[j, i] = counts[category]\n\n    if color_dict is None:\n        color_dict = adata_list[0].uns['SCN_class_colors'] # should parameterize this\n\n    # Plotting\n    #### fig, ax = plt.subplots()\n    fig, ax = plt.subplots(constrained_layout=True)\n    bottom = np.zeros(len(adata_list))\n    for i, category in enumerate(categories):\n        color = color_dict[category] if color_dict and category in color_dict else None\n        ax.bar(\n            range(len(adata_list)), \n            proportions[i], \n            bottom=bottom, \n            label=category, \n            width=bar_width, \n            edgecolor='white', \n            linewidth=.5,\n            color=color\n        )\n        bottom += proportions[i]\n\n    ax.set_xticks(range(len(adata_list)))\n    ax.set_xticklabels(labels, rotation=45, ha=\"right\")\n    ax.set_ylabel('Proportion')\n    ax.set_title(f'{obs_column} proportions')\n    # ax.legend(title='Classes', bbox_to_anchor=(1.05, 1), loc='upper left')\n    ## legend = fig.legend(title='Classes', loc=\"outside right upper\", frameon=False)#, bbox_to_anchor=(1.05, 1), loc='upper left')\n    ## legend_height = legend.get_window_extent().height / fig.dpi  # in inches\n\n    # Add legend\n    legend_handles = [mpatches.Patch(color=color, label=label) for label, color in color_dict.items()]\n    # legend = ax.legend(handles=legend_handles, bbox_to_anchor=(1.05, 1), loc='upper left', frameon=False)\n    ##### legend = fig.legend(title='Classes', loc=\"outside right upper\", frameon=False)\n    fig.legend(handles=legend_handles, loc=legend_loc, frameon=False)\n    ##### legend_height = legend.get_window_extent().height / fig.dpi  # in inches\n\n    # fig_height = fig.get_size_inches()[1]  # current height in inches\n    #### fig.set_size_inches(fig.get_size_inches()[0], legend_height )\n    # plt.tight_layout()\n    # plt.show()\n    return fig\n</code></pre>"},{"location":"plotting.html#pySingleCellNet.plotting.umap_scores","title":"umap_scores","text":"<pre><code>umap_scores(adata, scn_classes, obsm_name='SCN_score', alpha=0.75, s=10, display=True)\n</code></pre> <p>Plots UMAP projections of scRNA-seq data with specified scores.</p> <p>Parameters:</p> <ul> <li> <code>adata</code>               (<code>AnnData</code>)           \u2013            <p>The AnnData object containing the scRNA-seq data.</p> </li> <li> <code>scn_classes</code>               (<code>list</code>)           \u2013            <p>A list of SCN classes to visualize on the UMAP.</p> </li> <li> <code>obsm_name</code>               (<code>str</code>, default:                   <code>'SCN_score'</code> )           \u2013            <p>The name of the obsm key containing the SCN scores. Defaults to 'SCN_score'.</p> </li> <li> <code>alpha</code>               (<code>float</code>, default:                   <code>0.75</code> )           \u2013            <p>The transparency level of the points on the UMAP plot. Defaults to 0.75.</p> </li> <li> <code>s</code>               (<code>int</code>, default:                   <code>10</code> )           \u2013            <p>The size of the points on the UMAP plot. Defaults to 10.</p> </li> <li> <code>display</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If True, the plot is displayed immediately. If False, the axis object is returned. Defaults to True.</p> </li> </ul> <p>Returns:</p> <ul> <li>           \u2013            <p>matplotlib.axes.Axes or None:  If <code>display</code> is False, returns the matplotlib axes object. Otherwise, returns None.</p> </li> </ul> Source code in <code>src/pySingleCellNet/plotting/dot.py</code> <pre><code>def umap_scores(\n    adata: AnnData,\n    scn_classes: list,\n    obsm_name='SCN_score',\n    alpha=0.75,\n    s=10,\n    display=True\n):\n    \"\"\"\n    Plots UMAP projections of scRNA-seq data with specified scores.\n\n    Args:\n        adata (AnnData): \n            The AnnData object containing the scRNA-seq data.\n        scn_classes (list): \n            A list of SCN classes to visualize on the UMAP.\n        obsm_name (str, optional): \n            The name of the obsm key containing the SCN scores. Defaults to 'SCN_score'.\n        alpha (float, optional): \n            The transparency level of the points on the UMAP plot. Defaults to 0.75.\n        s (int, optional): \n            The size of the points on the UMAP plot. Defaults to 10.\n        display (bool, optional): \n            If True, the plot is displayed immediately. If False, the axis object is returned. Defaults to True.\n\n    Returns:\n        matplotlib.axes.Axes or None: \n            If `display` is False, returns the matplotlib axes object. Otherwise, returns None.\n    \"\"\"\n    # Create a temporary AnnData object with the desired obsm\n    adTemp = AnnData(adata.obsm[obsm_name], obs=adata.obs)\n    adTemp.obsm['X_umap'] = adata.obsm['X_umap'].copy()\n\n    # Create the UMAP plot\n    ax = sc.pl.umap(adTemp, color=scn_classes, alpha=alpha, s=s, vmin=0, vmax=1, show=False)\n\n    # Display or return the axis\n    if display:\n        plt.show()\n    else:\n        return ax\n</code></pre>"},{"location":"plotting.html#pySingleCellNet.plotting.umi_counts_ranked","title":"umi_counts_ranked","text":"<pre><code>umi_counts_ranked(adata, total_counts_column='total_counts')\n</code></pre> <p>Identifies and plors the knee point of the UMI count distribution in an AnnData object.</p> <p>Parameters:</p> <ul> <li> <code>adata</code>               (<code>AnnData</code>)           \u2013            <p>The input AnnData object.</p> </li> <li> <code>total_counts_column</code>               (<code>str</code>, default:                   <code>'total_counts'</code> )           \u2013            <p>Column in <code>adata.obs</code> containing total UMI counts. Default is \"total_counts\".</p> </li> <li> <code>show</code>               (<code>bool</code>)           \u2013            <p>If True, displays a log-log plot with the knee point. Default is True.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>float</code>          \u2013            <p>The UMI count value at the knee point.</p> </li> </ul> Source code in <code>src/pySingleCellNet/plotting/dot.py</code> <pre><code>def umi_counts_ranked(adata, total_counts_column=\"total_counts\"):\n    \"\"\"\n    Identifies and plors the knee point of the UMI count distribution in an AnnData object.\n\n    Parameters:\n        adata (AnnData): The input AnnData object.\n        total_counts_column (str): Column in `adata.obs` containing total UMI counts. Default is \"total_counts\".\n        show (bool): If True, displays a log-log plot with the knee point. Default is True.\n\n    Returns:\n        float: The UMI count value at the knee point.\n    \"\"\"\n    # Extract total UMI counts\n    umi_counts = adata.obs[total_counts_column]\n\n    # Sort UMI counts in descending order\n    sorted_umi_counts = np.sort(umi_counts)[::-1]\n\n    # Compute cumulative UMI counts (normalized to a fraction)\n    cumulative_counts = np.cumsum(sorted_umi_counts)\n    cumulative_fraction = cumulative_counts / cumulative_counts[-1]\n\n    # Compute derivatives to identify the knee point\n    first_derivative = np.gradient(cumulative_fraction)\n    second_derivative = np.gradient(first_derivative)\n\n    # Find the index of the maximum curvature (knee point)\n    knee_idx = np.argmax(second_derivative)\n    knee_point_value = sorted_umi_counts[knee_idx]\n\n    # Generate log-log plot\n    cell_ranks = np.arange(1, len(sorted_umi_counts) + 1)\n    plt.figure(figsize=(10, 6))\n    plt.plot(cell_ranks, sorted_umi_counts, marker='o', markersize=2, linestyle='-', linewidth=0.5, label=\"UMI Counts\")\n    plt.axvline(cell_ranks[knee_idx], color=\"red\", linestyle=\"--\", label=f\"Knee Point: {knee_point_value}\")\n    plt.title('UMI Counts Per Cell (Log-Log Scale)', fontsize=14)\n    plt.xlabel('Cell Rank (Descending)', fontsize=12)\n    plt.ylabel('Total UMI Counts', fontsize=12)\n    plt.xscale('log')\n    plt.yscale('log')\n    plt.grid(True, linestyle='--', linewidth=0.5)\n    plt.legend()\n    plt.tight_layout()\n    plt.show()\n</code></pre>"},{"location":"refs.html","title":"References","text":"<ul> <li> <p>Kumar P, Tan Y, Cahan P. Understanding development and stem cells using single cell-based analyses of gene expression. Development. 2017 Jan 1;144(1):17-32. doi: 10.1242/dev.133058. PMID: 28049689; PMCID: PMC5278625.</p> </li> <li> <p>Wolf FA, Angerer P, Theis FJ. SCANPY: large-scale single-cell gene expression data analysis. Genome Biol. 2018 Feb 6;19(1):15. doi: 10.1186/s13059-017-1382-0. PMID: 29409532; PMCID: PMC5802054.</p> </li> <li> <p>Tabula Muris Consortium; Overall coordination; Logistical coordination; Organ collection and processing; Library preparation and sequencing; Computational data analysis; Cell type annotation; Writing group; Supplemental text writing group; Principal investigators. Single-cell transcriptomics of 20 mouse organs creates a Tabula Muris. Nature. 2018 Oct;562(7727):367-372. doi: 10.1038/s41586-018-0590-4. Epub 2018 Oct 3. PMID: 30283141; PMCID: PMC6642641.</p> </li> <li> <p>Tan Y, Cahan P. SingleCellNet: A Computational Tool to Classify Single Cell RNA-Seq Data Across Platforms and Across Species. Cell Syst. 2019 Aug 28;9(2):207-213.e2. doi: 10.1016/j.cels.2019.06.004. Epub 2019 Jul 31. PMID: 31377170; PMCID: PMC6715530.</p> </li> </ul>"},{"location":"training_data.html","title":"Training data","text":""},{"location":"training_data.html#mouse-embryo-data","title":"Mouse embryo data","text":"<ol> <li> <p>Mouse gastrulation</p> <ul> <li>This is a subset of the mouse gastrulation atlas described in Pijuan-Sala et al Nature 2019. We have reduced the size of this dataset and we have re-annotated the cell lineages based on recent spatial transcriptomics studies of mouse gastrulation (see Lohoff et al 2021 and Kumar et al 2023).</li> <li>There are 18,023 cells</li> <li>27,636 genes</li> <li>25 cell types or lineages</li> <li>E7.0 to E8.5</li> </ul> </li> <li> <p>Mouse gastrulation v2</p> <ul> <li>This is also subset of the mouse gastrulation atlas described in Pijuan-Sala et al Nature 2019. We have included earlier time points and reduced the number of cells per cell type to 75.</li> </ul> </li> </ol>"},{"location":"training_data.html#mouse-training-data-from-tabula-senis-10x","title":"Mouse training data from Tabula senis 10X.","text":"<ol> <li>Bladder</li> <li>Fat</li> <li>Heart</li> <li>Kidney</li> <li>Large Intestine</li> <li>Lung</li> <li>Mammary Gland</li> <li>Marrow</li> <li>Pancreas</li> <li>Skeletal Muscle</li> <li>Skin</li> <li>Trachea</li> </ol>"},{"location":"utils.html","title":"Utilities","text":"<p>Miscellaneous functions</p>"},{"location":"utils.html#pySingleCellNet.utils.assign_optimal_cluster","title":"assign_optimal_cluster","text":"<pre><code>assign_optimal_cluster(adata, cluster_reports, new_col='optimal_cluster')\n</code></pre> <p>Determine the optimal cluster label per cell across multiple cluster assignments by comparing F1-scores, then prepend the chosen label with the name of the .obs column that provided it.</p>"},{"location":"utils.html#pySingleCellNet.utils.assign_optimal_cluster--parameters","title":"Parameters","text":"<p>adata : anndata.AnnData     The annotated single-cell dataset. cluster_reports : dict[str, pd.DataFrame]     A dictionary where keys are column names in <code>adata.obs</code> (each key      corresponds to one clustering scheme), and values are DataFrames      with classification metrics including 'Label' and 'F1-Score'. new_col : str, optional     The name of the new <code>.obs</code> column in which the optimal cluster labels      will be stored. Default is \"optimal_cluster\".</p>"},{"location":"utils.html#pySingleCellNet.utils.assign_optimal_cluster--returns","title":"Returns","text":"<p>None     The function adds a new column to <code>adata.obs</code> but does not return anything.</p> Source code in <code>src/pySingleCellNet/utils/cell.py</code> <pre><code>def assign_optimal_cluster(adata, cluster_reports, new_col=\"optimal_cluster\"):\n    \"\"\"\n    Determine the optimal cluster label per cell across multiple cluster assignments\n    by comparing F1-scores, then prepend the chosen label with the name of the .obs\n    column that provided it.\n\n    Parameters\n    ----------\n    adata : anndata.AnnData\n        The annotated single-cell dataset.\n    cluster_reports : dict[str, pd.DataFrame]\n        A dictionary where keys are column names in `adata.obs` (each key \n        corresponds to one clustering scheme), and values are DataFrames \n        with classification metrics including 'Label' and 'F1-Score'.\n    new_col : str, optional\n        The name of the new `.obs` column in which the optimal cluster labels \n        will be stored. Default is \"optimal_cluster\".\n\n    Returns\n    -------\n    None\n        The function adds a new column to `adata.obs` but does not return anything.\n    \"\"\"\n    # Prepare a list to hold the chosen cluster label (prepended with obs_col name) per cell\n    optimal_labels = np.empty(adata.n_obs, dtype=object)\n\n    # Convert each cluster report into a dictionary for faster F1 lookups:\n    # For each clustering key, map cluster_label -&gt; F1_score\n    f1_lookup_dict = {}\n    for obs_col, df in cluster_reports.items():\n        # Convert the \"Label\" -&gt; \"F1-Score\" DataFrame to a dictionary for quick lookups\n        f1_lookup_dict[obs_col] = dict(zip(df[\"Label\"], df[\"F1-Score\"]))\n\n    # Iterate over each cell in adata\n    for i in range(adata.n_obs):\n        best_f1 = -1\n        best_label_full = None  # Will store \"&lt;obs_col&gt;_&lt;cluster_label&gt;\"\n\n        # Check each cluster assignment\n        for obs_col, label_to_f1 in f1_lookup_dict.items():\n            # Current cell's cluster label in this assignment\n            cell_label = adata.obs[obs_col].iloc[i]\n            # Lookup F1 score (if label doesn't exist in the classification report, default to -1)\n            f1 = label_to_f1.get(cell_label, -1)\n            # Update if this is a higher F1\n            if f1 &gt; best_f1:\n                best_f1 = f1\n                # Prepend the obs_col to ensure uniqueness across different clustering schemes\n                best_label_full = f\"{obs_col}_{cell_label}\"\n\n        optimal_labels[i] = best_label_full\n\n    # Store the new labels in an adata.obs column\n    adata.obs[new_col] = optimal_labels\n    # convert to categorical\n    adata.obs[new_col] = adata.obs[new_col].astype('category')\n</code></pre>"},{"location":"utils.html#pySingleCellNet.utils.build_knn_graph","title":"build_knn_graph","text":"<pre><code>build_knn_graph(correlation_matrix, labels, k=5)\n</code></pre> <p>Build a k-nearest neighbors (kNN) graph from a correlation matrix.</p> <p>Parameters:</p> <ul> <li> <code>correlation_matrix</code>               (<code>ndarray</code>)           \u2013            <p>Square correlation matrix.</p> </li> <li> <code>labels</code>               (<code>list</code>)           \u2013            <p>Node labels corresponding to the rows/columns of the correlation matrix.</p> </li> <li> <code>k</code>               (<code>int</code>, default:                   <code>5</code> )           \u2013            <p>Number of nearest neighbors to connect each node to.</p> </li> </ul> <p>Returns:</p> <ul> <li>           \u2013            <p>igraph.Graph: kNN graph.</p> </li> </ul> Source code in <code>src/pySingleCellNet/utils/adataTools.py</code> <pre><code>def build_knn_graph(correlation_matrix, labels, k=5):\n    \"\"\"\n    Build a k-nearest neighbors (kNN) graph from a correlation matrix.\n\n    Parameters:\n        correlation_matrix (ndarray): Square correlation matrix.\n        labels (list): Node labels corresponding to the rows/columns of the correlation matrix.\n        k (int): Number of nearest neighbors to connect each node to.\n\n    Returns:\n        igraph.Graph: kNN graph.\n    \"\"\"\n\n    # import igraph as ig\n\n    # Ensure the correlation matrix is square\n    assert correlation_matrix.shape[0] == correlation_matrix.shape[1], \"Matrix must be square.\"\n\n    # Initialize the graph\n    n = len(labels)\n    g = ig.Graph()\n    g.add_vertices(n)\n    g.vs[\"name\"] = labels  # Add node labels\n\n    # Build kNN edges\n    for i in range(n):\n        # Get k largest correlations (excluding self-correlation)\n        neighbors = np.argsort(correlation_matrix[i, :])[-(k + 1):-1]  # Exclude the node itself\n        for j in neighbors:\n            g.add_edge(i, j, weight=correlation_matrix[i, j])\n\n    return g\n</code></pre>"},{"location":"utils.html#pySingleCellNet.utils.cluster_subclusters","title":"cluster_subclusters","text":"<pre><code>cluster_subclusters(adata, cluster_column='leiden', cluster_name=None, layer='counts', n_hvg=2000, n_pcs=40, n_neighbors=10, leiden_resolution=0.25, subcluster_col_name='subcluster')\n</code></pre> <p>Subcluster a specified cluster (or all clusters) within an AnnData object by recomputing HVGs, PCA, kNN graph, and Leiden clustering. Updates the AnnData object in-place, adding or updating the <code>subcluster_col_name</code> column in <code>.obs</code> with new labels prefixed by the original cluster.</p> <p>Parameters:</p> <ul> <li> <code>adata</code>               (<code>AnnData</code>)           \u2013            <p>AnnData The AnnData object containing precomputed clusters in <code>.obs[cluster_column]</code>.</p> </li> <li> <code>cluster_column</code>               (<code>str</code>, default:                   <code>'leiden'</code> )           \u2013            <p>str, optional Name of the <code>.obs</code> column holding the original cluster assignments. Default is 'leiden'.</p> </li> <li> <code>cluster_name</code>               (<code>str</code>, default:                   <code>None</code> )           \u2013            <p>str or None, optional Specific cluster label to subcluster. If <code>None</code>, applies to all clusters. Default is None.</p> </li> <li> <code>layer</code>               (<code>str</code>, default:                   <code>'counts'</code> )           \u2013            <p>str, optional Layer name in <code>adata.layers</code> to use for HVG detection. Default is 'counts'.</p> </li> <li> <code>n_hvg</code>               (<code>int</code>, default:                   <code>2000</code> )           \u2013            <p>int, optional Number of highly variable genes to select per cluster. Default is 2000.</p> </li> <li> <code>n_pcs</code>               (<code>int</code>, default:                   <code>40</code> )           \u2013            <p>int, optional Number of principal components to compute. Default is 40.</p> </li> <li> <code>n_neighbors</code>               (<code>int</code>, default:                   <code>10</code> )           \u2013            <p>int, optional Number of neighbors for the kNN graph. Default is 10.</p> </li> <li> <code>leiden_resolution</code>               (<code>float</code>, default:                   <code>0.25</code> )           \u2013            <p>float, optional Resolution parameter for Leiden clustering. Default is 0.25.</p> </li> <li> <code>subcluster_col_name</code>               (<code>str</code>, default:                   <code>'subcluster'</code> )           \u2013            <p>str, optional Name of the <code>.obs</code> column to store subcluster labels. Default is 'subcluster'.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If <code>cluster_column</code> not in <code>adata.obs</code>.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If <code>layer</code> not in <code>adata.layers</code>.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If <code>cluster_name</code> is specified but not found in <code>adata.obs[cluster_column]</code>.</p> </li> </ul> Source code in <code>src/pySingleCellNet/utils/cell.py</code> <pre><code>def cluster_subclusters(\n    adata: ad.AnnData,\n    cluster_column: str = 'leiden',\n    cluster_name: str = None,\n    layer: str = 'counts',\n    n_hvg: int = 2000,\n    n_pcs: int = 40,\n    n_neighbors: int = 10,\n    leiden_resolution: float = 0.25,\n    subcluster_col_name: str = 'subcluster'\n) -&gt; None:\n    \"\"\"\n    Subcluster a specified cluster (or all clusters) within an AnnData object by recomputing HVGs, PCA,\n    kNN graph, and Leiden clustering. Updates the AnnData object in-place, adding or updating\n    the `subcluster_col_name` column in `.obs` with new labels prefixed by the original cluster.\n\n    Args:\n        adata: AnnData\n            The AnnData object containing precomputed clusters in `.obs[cluster_column]`.\n        cluster_column: str, optional\n            Name of the `.obs` column holding the original cluster assignments. Default is 'leiden'.\n        cluster_name: str or None, optional\n            Specific cluster label to subcluster. If `None`, applies to all clusters. Default is None.\n        layer: str, optional\n            Layer name in `adata.layers` to use for HVG detection. Default is 'counts'.\n        n_hvg: int, optional\n            Number of highly variable genes to select per cluster. Default is 2000.\n        n_pcs: int, optional\n            Number of principal components to compute. Default is 40.\n        n_neighbors: int, optional\n            Number of neighbors for the kNN graph. Default is 10.\n        leiden_resolution: float, optional\n            Resolution parameter for Leiden clustering. Default is 0.25.\n        subcluster_col_name: str, optional\n            Name of the `.obs` column to store subcluster labels. Default is 'subcluster'.\n\n    Raises:\n        ValueError: If `cluster_column` not in `adata.obs`.\n        ValueError: If `layer` not in `adata.layers`.\n        ValueError: If `cluster_name` is specified but not found in `adata.obs[cluster_column]`.\n    \"\"\"\n    # Error checking\n    if cluster_column not in adata.obs:\n        raise ValueError(f\"Cluster column '{cluster_column}' not found in adata.obs\")\n    if layer not in adata.layers:\n        raise ValueError(f\"Layer '{layer}' not found in adata.layers\")\n\n    # Convert original clusters to string\n    adata.obs['original_cluster'] = adata.obs[cluster_column].astype(str)\n\n    # Ensure subcluster column exists\n    adata.obs[subcluster_col_name] = \"\"\n\n    # Validate cluster_name\n    unique_clusters = adata.obs['original_cluster'].unique()\n    if cluster_name is not None:\n        if str(cluster_name) not in unique_clusters:\n            raise ValueError(\n                f\"Cluster '{cluster_name}' not found in adata.obs['{cluster_column}']\"\n            )\n        clusters_to_process = [str(cluster_name)]\n    else:\n        clusters_to_process = unique_clusters\n\n    # Iterate and subcluster\n    for orig in clusters_to_process:\n        mask = adata.obs['original_cluster'] == orig\n        sub = adata[mask].copy()\n\n        # 1) Compute HVGs\n        sc.pp.highly_variable_genes(\n            sub,\n            flavor='seurat_v3',\n            n_top_genes=n_hvg,\n            layer=layer\n        )\n\n        # 2) PCA\n        sc.pp.pca(sub, n_comps=n_pcs, use_highly_variable=True)\n\n        # 3) kNN\n        sc.pp.neighbors(sub, n_neighbors=n_neighbors, use_rep='X_pca')\n\n        # 4) Leiden\n        sc.tl.leiden(\n            sub,\n            resolution=leiden_resolution,\n            flavor='igraph',\n            n_iterations=2,\n            key_added='leiden_sub'\n        )\n\n        # Prefix and assign back\n        labels = (orig + \"_\" + sub.obs['leiden_sub'].astype(str)).values\n        adata.obs.loc[mask, subcluster_col_name] = labels\n</code></pre>"},{"location":"utils.html#pySingleCellNet.utils.combine_pca_scores","title":"combine_pca_scores","text":"<pre><code>combine_pca_scores(adata, n_pcs=50, score_key='SCN_score')\n</code></pre> <p>Combine principal components and gene set scores into a single matrix.</p> <p>This function merges the top principal components (PCs) and gene set scores  into a combined matrix stored in <code>.obsm</code>.</p> <p>Parameters:</p> <ul> <li> <code>adata</code>               (<code>AnnData</code>)           \u2013            <p>AnnData object containing PCA results and gene set scores in <code>.obsm</code>.</p> </li> <li> <code>n_pcs</code>               (<code>int</code>, default:                   <code>50</code> )           \u2013            <p>Number of top PCs to include. Default is 50.</p> </li> <li> <code>score_key</code>               (<code>str</code>, default:                   <code>'SCN_score'</code> )           \u2013            <p>Key in <code>.obsm</code> where gene set scores are stored. Default is <code>'SCN_score'</code>.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If <code>'X_pca'</code> is not found in <code>.obsm</code>.  </p> </li> <li> <code>ValueError</code>             \u2013            <p>If <code>score_key</code> is missing in <code>.obsm</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>None</code>          \u2013            <p>Updates <code>adata</code> by adding the combined matrix to <code>.obsm['X_pca_scores_combined']</code>.</p> </li> </ul> Example <p>combine_pca_scores(adata, n_pcs=30, score_key='GeneSet_Score')</p> Source code in <code>src/pySingleCellNet/utils/adataTools.py</code> <pre><code>def combine_pca_scores(adata, n_pcs=50, score_key='SCN_score'):\n    \"\"\"Combine principal components and gene set scores into a single matrix.\n\n    This function merges the top principal components (PCs) and gene set scores \n    into a combined matrix stored in `.obsm`.\n\n    Args:\n        adata (AnnData): \n            AnnData object containing PCA results and gene set scores in `.obsm`.\n        n_pcs (int, optional): \n            Number of top PCs to include. Default is 50.\n        score_key (str, optional): \n            Key in `.obsm` where gene set scores are stored. Default is `'SCN_score'`.\n\n    Raises:\n        ValueError: If `'X_pca'` is not found in `.obsm`.  \n        ValueError: If `score_key` is missing in `.obsm`.\n\n    Returns:\n        None: Updates `adata` by adding the combined matrix to `.obsm['X_pca_scores_combined']`.\n\n    Example:\n        &gt;&gt;&gt; combine_pca_scores(adata, n_pcs=30, score_key='GeneSet_Score')\n    \"\"\"\n\n    # Ensure that the required data exists in .obsm\n    if 'X_pca' not in adata.obsm:\n        raise ValueError(\"X_pca not found in .obsm. Perform PCA before combining.\")\n\n    if score_key not in adata.obsm:\n        raise ValueError(f\"{score_key} not found in .obsm. Please provide valid gene set scores.\")\n\n    # Extract the top n_pcs from .obsm['X_pca']\n    pca_matrix = adata.obsm['X_pca'][:, :n_pcs]\n\n    # Extract the gene set scores from .obsm\n    score_matrix = adata.obsm[score_key]\n\n    # Combine PCA matrix and score matrix horizontally (along columns)\n    combined_matrix = np.hstack([pca_matrix, score_matrix])\n\n    # Add the combined matrix back into .obsm with a new key\n    adata.obsm['X_pca_scores_combined'] = combined_matrix\n\n    print(f\"Combined matrix with {n_pcs} PCs and {score_matrix.shape[1]} gene set scores added to .obsm['X_pca_scores_combined'].\")\n</code></pre>"},{"location":"utils.html#pySingleCellNet.utils.create_gene_structure_dict_by_stage","title":"create_gene_structure_dict_by_stage","text":"<pre><code>create_gene_structure_dict_by_stage(file_path, stage)\n</code></pre> <p>Create a dictionary mapping structures to lists of genes expressed at a specific stage. Designed for parsing output from Jax Labs MGI data</p> <p>Parameters:</p> <ul> <li> <code>file_path</code>               (<code>str</code>)           \u2013            <p>Path to the gene expression file.</p> </li> <li> <code>stage</code>               (<code>str or int</code>)           \u2013            <p>The Theiler Stage to filter the data.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>dict</code>          \u2013            <p>A dictionary where keys are structures and values are lists of genes expressed in those structures.</p> </li> </ul> Source code in <code>src/pySingleCellNet/utils/annotation.py</code> <pre><code>def create_gene_structure_dict_by_stage(file_path, stage):\n    \"\"\"\n    Create a dictionary mapping structures to lists of genes expressed at a specific stage. Designed for parsing output from Jax Labs MGI data\n\n    Parameters:\n        file_path (str): Path to the gene expression file.\n        stage (str or int): The Theiler Stage to filter the data.\n\n    Returns:\n        dict: A dictionary where keys are structures and values are lists of genes expressed in those structures.\n    \"\"\"\n    structure_dict = defaultdict(set)  # Using a set to avoid duplicate gene symbols\n\n    with open(file_path, 'r') as file:\n        reader = csv.DictReader(file, delimiter='\\t')  # Use tab-delimiter based on previous example\n        for row in reader:\n            if row['Theiler Stage'] == str(stage):  # Subset by stage\n                structure = row['Structure']\n                gene_symbol = row['Gene Symbol']\n                if structure and gene_symbol:  # Ensure both fields are not empty\n                    structure_dict[structure].add(gene_symbol)\n\n    # Convert sets to lists for final output\n    structure_dict = {structure: list(genes) for structure, genes in structure_dict.items()}\n    return structure_dict\n</code></pre>"},{"location":"utils.html#pySingleCellNet.utils.extract_top_bottom_genes","title":"extract_top_bottom_genes","text":"<pre><code>extract_top_bottom_genes(deg_res, ngenes, sort_by='scores', extraction_map=None)\n</code></pre> <p>Extracts top and bottom ngenes from each gene table in deg_res and organizes them into a dictionary with combined keys of group and sample names.</p>"},{"location":"utils.html#pySingleCellNet.utils.extract_top_bottom_genes--parameters","title":"Parameters:","text":"<p>deg_res : dict     A dictionary containing differential expression results with keys:         - 'sample_names': List of sample names (e.g., ['Singular', 'None'])         - 'geneTab_dict': Dictionary where each key is a group name and each value is                           a Pandas DataFrame with gene information. ngenes : int     The number of top or bottom genes to extract from each gene table. sort_by : str, optional (default='scores')     The column name in the gene tables to sort by. extraction_map : dict, optional     A dictionary mapping sample names to extraction behavior ('top' or 'bottom').     If not provided, defaults to:         - First sample name: 'top'         - Second sample name: 'bottom'         - Additional sample names: 'top'</p>"},{"location":"utils.html#pySingleCellNet.utils.extract_top_bottom_genes--returns","title":"Returns:","text":"<p>result_dict : dict     A dictionary where each key is a combination of group and sample name     (e.g., 'Meso.Nascent_Singular') and each value is a list of gene names.     - For 'top', the list contains the top ngenes based on sort_by.     - For 'bottom', the list contains the bottom ngenes based on sort_by.</p>"},{"location":"utils.html#pySingleCellNet.utils.extract_top_bottom_genes--raises","title":"Raises:","text":"<p>KeyError:     If 'sample_names' or 'geneTab_dict' keys are missing in deg_res,     or if 'sort_by' is not a column in the gene tables. ValueError:     If ngenes is not a positive integer or if 'sample_names' does not contain at least one entry. TypeError:     If the input types are incorrect.</p> Source code in <code>src/pySingleCellNet/utils/gene.py</code> <pre><code>def extract_top_bottom_genes(\n    deg_res: dict,\n    ngenes: int,\n    sort_by: str = 'scores',\n    extraction_map: Dict[str, str] = None\n) -&gt; Dict[str, List[str]]:\n    \"\"\"\n    Extracts top and bottom ngenes from each gene table in deg_res and organizes them\n    into a dictionary with combined keys of group and sample names.\n\n    Parameters:\n    -----------\n    deg_res : dict\n        A dictionary containing differential expression results with keys:\n            - 'sample_names': List of sample names (e.g., ['Singular', 'None'])\n            - 'geneTab_dict': Dictionary where each key is a group name and each value is\n                              a Pandas DataFrame with gene information.\n    ngenes : int\n        The number of top or bottom genes to extract from each gene table.\n    sort_by : str, optional (default='scores')\n        The column name in the gene tables to sort by.\n    extraction_map : dict, optional\n        A dictionary mapping sample names to extraction behavior ('top' or 'bottom').\n        If not provided, defaults to:\n            - First sample name: 'top'\n            - Second sample name: 'bottom'\n            - Additional sample names: 'top'\n\n    Returns:\n    --------\n    result_dict : dict\n        A dictionary where each key is a combination of group and sample name\n        (e.g., 'Meso.Nascent_Singular') and each value is a list of gene names.\n        - For 'top', the list contains the top ngenes based on sort_by.\n        - For 'bottom', the list contains the bottom ngenes based on sort_by.\n\n    Raises:\n    -------\n    KeyError:\n        If 'sample_names' or 'geneTab_dict' keys are missing in deg_res,\n        or if 'sort_by' is not a column in the gene tables.\n    ValueError:\n        If ngenes is not a positive integer or if 'sample_names' does not contain at least one entry.\n    TypeError:\n        If the input types are incorrect.\n    \"\"\"\n    # Input Validation\n    required_keys = ['sample_names', 'geneTab_dict']\n    for key in required_keys:\n        if key not in deg_res:\n            raise KeyError(f\"Key '{key}' not found in deg_res.\")\n\n    sample_names = deg_res['sample_names']\n    geneTab_dict = deg_res['geneTab_dict']\n\n    if not isinstance(sample_names, list):\n        raise TypeError(f\"'sample_names' should be a list, got {type(sample_names)}.\")\n\n    if not isinstance(geneTab_dict, dict):\n        raise TypeError(f\"'geneTab_dict' should be a dict, got {type(geneTab_dict)}.\")\n\n    if not isinstance(ngenes, int) or ngenes &lt;= 0:\n        raise ValueError(f\"'ngenes' must be a positive integer, got {ngenes}.\")\n\n    if len(sample_names) &lt; 1:\n        raise ValueError(f\"'sample_names' should contain at least one entry, got {len(sample_names)}.\")\n\n    result_dict = {}\n\n    # Define default extraction behavior if extraction_map is not provided\n    if extraction_map is None:\n        extraction_map = {}\n        for idx, sample in enumerate(sample_names):\n            if idx == 0:\n                extraction_map[sample] = 'top'\n            elif idx == 1:\n                extraction_map[sample] = 'bottom'\n            else:\n                extraction_map[sample] = 'top'  # Default behavior for additional samples\n\n    else:\n        # Validate extraction_map\n        if not isinstance(extraction_map, dict):\n            raise TypeError(f\"'extraction_map' should be a dict, got {type(extraction_map)}.\")\n        for sample, behavior in extraction_map.items():\n            if behavior not in ['top', 'bottom']:\n                raise ValueError(f\"Invalid extraction behavior '{behavior}' for sample '{sample}'. Must be 'top' or 'bottom'.\")\n\n    # Iterate over each group in geneTab_dict\n    for group, df in geneTab_dict.items():\n        if not isinstance(df, pd.DataFrame):\n            raise TypeError(f\"Expected DataFrame for group '{group}', got {type(df)}.\")\n\n        # Ensure required columns exist\n        required_columns = ['names', sort_by]\n        for col in required_columns:\n            if col not in df.columns:\n                raise KeyError(f\"Column '{col}' not found in gene table for group '{group}'.\")\n\n        # Sort the DataFrame by 'sort_by' column\n        sorted_df = df.sort_values(by=sort_by, ascending=False).reset_index(drop=True)\n\n        # Iterate over sample names to determine extraction behavior\n        for sample in sample_names:\n            combined_key = f\"{group}_{sample}\"\n            behavior = extraction_map.get(sample, 'top')  # Default to 'top' if not specified\n\n            if behavior == 'top':\n                # Extract top ngenes\n                top_genes = sorted_df['names'].head(ngenes).tolist()\n                result_dict[combined_key] = top_genes\n            elif behavior == 'bottom':\n                # Extract bottom ngenes\n                bottom_genes = sorted_df['names'].tail(ngenes).tolist()\n                result_dict[combined_key] = bottom_genes\n\n    return result_dict\n</code></pre>"},{"location":"utils.html#pySingleCellNet.utils.filter_adata_by_group_size","title":"filter_adata_by_group_size","text":"<pre><code>filter_adata_by_group_size(adata, groupby, ncells=20)\n</code></pre> <p>Filters an AnnData object to retain only cells from groups with at least 'ncells' cells.</p>"},{"location":"utils.html#pySingleCellNet.utils.filter_adata_by_group_size--parameters","title":"Parameters:","text":"<p>adata : AnnData     The input AnnData object containing single-cell data. groupby : str     The column name in <code>adata.obs</code> used to define groups (e.g., cluster labels). ncells : int, optional (default=20)     The minimum number of cells a group must have to be retained.</p>"},{"location":"utils.html#pySingleCellNet.utils.filter_adata_by_group_size--returns","title":"Returns:","text":"<p>filtered_adata : AnnData     A new AnnData object containing only cells from groups with at least 'ncells' cells.</p>"},{"location":"utils.html#pySingleCellNet.utils.filter_adata_by_group_size--raises","title":"Raises:","text":"<p>ValueError:     - If <code>groupby</code> is not a column in <code>adata.obs</code>.     - If <code>ncells</code> is not a positive integer.</p> Source code in <code>src/pySingleCellNet/utils/cell.py</code> <pre><code>def filter_adata_by_group_size(adata: ad.AnnData, groupby: str, ncells: int = 20) -&gt; ad.AnnData:\n    \"\"\"\n    Filters an AnnData object to retain only cells from groups with at least 'ncells' cells.\n\n    Parameters:\n    -----------\n    adata : AnnData\n        The input AnnData object containing single-cell data.\n    groupby : str\n        The column name in `adata.obs` used to define groups (e.g., cluster labels).\n    ncells : int, optional (default=20)\n        The minimum number of cells a group must have to be retained.\n\n    Returns:\n    --------\n    filtered_adata : AnnData\n        A new AnnData object containing only cells from groups with at least 'ncells' cells.\n\n    Raises:\n    -------\n    ValueError:\n        - If `groupby` is not a column in `adata.obs`.\n        - If `ncells` is not a positive integer.\n    \"\"\"\n    # Input Validation\n    if not isinstance(adata, ad.AnnData):\n        raise TypeError(f\"'adata' must be an AnnData object, but got {type(adata)}.\")\n\n    if not isinstance(groupby, str):\n        raise TypeError(f\"'groupby' must be a string, but got {type(groupby)}.\")\n\n    if groupby not in adata.obs.columns:\n        raise ValueError(f\"'{groupby}' is not a column in adata.obs. Available columns are: {adata.obs.columns.tolist()}\")\n\n    if not isinstance(ncells, int) or ncells &lt;= 0:\n        raise ValueError(f\"'ncells' must be a positive integer, but got {ncells}.\")\n\n    # Compute the size of each group\n    group_sizes = adata.obs[groupby].value_counts()\n\n    # Identify groups that meet or exceed the minimum cell threshold\n    valid_groups = group_sizes[group_sizes &gt;= ncells].index.tolist()\n\n    if not valid_groups:\n        raise ValueError(f\"No groups found in '{groupby}' with at least {ncells} cells.\")\n\n    # Optionally, inform the user about the filtering\n    total_groups = adata.obs[groupby].nunique()\n    retained_groups = len(valid_groups)\n    excluded_groups = total_groups - retained_groups\n    print(f\"Filtering AnnData object based on group sizes in '{groupby}':\")\n    print(f\" - Total groups: {total_groups}\")\n    print(f\" - Groups retained (\u2265 {ncells} cells): {retained_groups}\")\n    print(f\" - Groups excluded (&lt; {ncells} cells): {excluded_groups}\")\n\n    # Create a boolean mask for cells belonging to valid groups\n    mask = adata.obs[groupby].isin(valid_groups)\n\n    # Apply the mask to filter the AnnData object\n    filtered_adata = adata[mask].copy()\n\n    # Optionally, reset indices if necessary\n    # filtered_adata.obs_names = range(filtered_adata.n_obs)\n\n    print(f\"Filtered AnnData object contains {filtered_adata.n_obs} cells from {filtered_adata.obs[groupby].nunique()} groups.\")\n\n    return filtered_adata\n</code></pre>"},{"location":"utils.html#pySingleCellNet.utils.filter_anndata_slots","title":"filter_anndata_slots","text":"<pre><code>filter_anndata_slots(adata, slots_to_keep)\n</code></pre> <p>Creates a copy of an AnnData object and filters it to retain only the specified  slots and elements within those slots. Unspecified slots or elements are removed from the copy.</p> <p>The function operates on a copy of the provided AnnData object, ensuring that the original data remains unchanged. This approach allows users to maintain data integrity while exploring different subsets or representations of their dataset.</p> <p>Parameters:</p> <ul> <li> <code>adata</code>               (<code>AnnData</code>)           \u2013            <p>The AnnData object to be copied and filtered. This object represents a single-cell dataset with various annotations and embeddings.</p> </li> <li> <code>slots_to_keep</code>               (<code>dict</code>)           \u2013            <p>A dictionary specifying which slots and elements within  those slots to keep. The keys should be the slot names ('obs', 'var', 'obsm', 'obsp', 'varm', 'varp'), and the values should be lists of the names within  those slots to preserve. If a slot is not mentioned or its value is None,  all its contents are removed in the copy. Example format:</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>AnnData</code>          \u2013            <p>A copy of the original AnnData object filtered according to the specified</p> </li> <li>           \u2013            <p>slots to keep. This copy contains only the data and annotations specified by the</p> </li> <li>           \u2013            <p><code>slots_to_keep</code> dictionary, with all other data and annotations removed.</p> </li> </ul> Example <p>adata = sc.datasets.pbmc68k_reduced() slots_to_keep = {     'obs': ['n_genes', 'percent_mito'],     'var': ['n_cells'],     # Assuming we want to clear these unless specified to keep     'obsm': None,     'obsp': None,     'varm': None,     'varp': None, } filtered_adata = filter_anndata_slots(adata, slots_to_keep)</p> Source code in <code>src/pySingleCellNet/utils/adataTools.py</code> <pre><code>def filter_anndata_slots(adata, slots_to_keep):\n    \"\"\"\n    Creates a copy of an AnnData object and filters it to retain only the specified \n    slots and elements within those slots. Unspecified slots or elements are removed from the copy.\n\n    The function operates on a copy of the provided AnnData object, ensuring that the original\n    data remains unchanged. This approach allows users to maintain data integrity while\n    exploring different subsets or representations of their dataset.\n\n    Args:\n        adata (AnnData): The AnnData object to be copied and filtered. This object\n            represents a single-cell dataset with various annotations and embeddings.\n        slots_to_keep (dict): A dictionary specifying which slots and elements within \n            those slots to keep. The keys should be the slot names ('obs', 'var', 'obsm',\n            'obsp', 'varm', 'varp'), and the values should be lists of the names within \n            those slots to preserve. If a slot is not mentioned or its value is None, \n            all its contents are removed in the copy. Example format:\n            {'obs': ['cluster'], 'var': ['gene_id'], 'obsm': ['X_pca']}\n\n    Returns:\n        AnnData: A copy of the original AnnData object filtered according to the specified\n        slots to keep. This copy contains only the data and annotations specified by the\n        `slots_to_keep` dictionary, with all other data and annotations removed.\n\n    Example:\n        adata = sc.datasets.pbmc68k_reduced()\n        slots_to_keep = {\n            'obs': ['n_genes', 'percent_mito'],\n            'var': ['n_cells'],\n            # Assuming we want to clear these unless specified to keep\n            'obsm': None,\n            'obsp': None,\n            'varm': None,\n            'varp': None,\n        }\n        filtered_adata = filter_anndata_slots(adata, slots_to_keep)\n        # `filtered_adata` is the modified copy, `adata` remains unchanged.\n    \"\"\"\n\n    # Create a copy of the AnnData object to work on\n    adata_copy = adata.copy()\n\n    # Define all possible slots\n    all_slots = ['obs', 'var', 'obsm', 'obsp', 'varm', 'varp']\n\n    for slot in all_slots:\n        if slot not in slots_to_keep or slots_to_keep[slot] is None:\n            # If slot is not mentioned or is None, remove all its contents\n            if slot in ['obs', 'var']:\n                setattr(adata_copy, slot, pd.DataFrame(index=getattr(adata_copy, slot).index))\n            else:\n                setattr(adata_copy, slot, {})\n        else:\n            # Specific elements within the slot are specified to be kept\n            elements_to_keep = slots_to_keep[slot]\n\n            if slot in ['obs', 'var']:\n                # Filter columns for 'obs' and 'var'\n                df = getattr(adata_copy, slot)\n                columns_to_drop = [col for col in df.columns if col not in elements_to_keep]\n                df.drop(columns=columns_to_drop, inplace=True)\n\n            elif slot in ['obsm', 'obsp', 'varm', 'varp']:\n                # Filter keys for 'obsm', 'obsp', 'varm', 'varp'\n                mapping = getattr(adata_copy, slot)\n                keys_to_drop = [key for key in mapping.keys() if key not in elements_to_keep]\n                for key in keys_to_drop:\n                    del mapping[key]\n\n    return adata_copy\n</code></pre>"},{"location":"utils.html#pySingleCellNet.utils.filter_anndata_slots--filtered_adata-is-the-modified-copy-adata-remains-unchanged","title":"<code>filtered_adata</code> is the modified copy, <code>adata</code> remains unchanged.","text":""},{"location":"utils.html#pySingleCellNet.utils.filter_gene_list","title":"filter_gene_list","text":"<pre><code>filter_gene_list(genelist, min_genes, max_genes=1000000.0)\n</code></pre> <p>Filter the gene lists in the provided dictionary based on their lengths.</p> <ul> <li>genelist : dict     Dictionary with keys as identifiers and values as lists of genes.</li> <li>min_genes : int     Minimum number of genes a list should have.</li> <li>max_genes : int     Maximum number of genes a list should have.</li> </ul> <ul> <li>dict     Filtered dictionary with lists that have a length between min_genes and max_genes (inclusive of min_genes and max_genes).</li> </ul> Source code in <code>src/pySingleCellNet/utils/annotation.py</code> <pre><code>def filter_gene_list(genelist, min_genes, max_genes=1e6):\n    \"\"\"\n    Filter the gene lists in the provided dictionary based on their lengths.\n\n    Parameters:\n    - genelist : dict\n        Dictionary with keys as identifiers and values as lists of genes.\n    - min_genes : int\n        Minimum number of genes a list should have.\n    - max_genes : int\n        Maximum number of genes a list should have.\n\n    Returns:\n    - dict\n        Filtered dictionary with lists that have a length between min_genes and max_genes (inclusive of min_genes and max_genes).\n    \"\"\"\n    filtered_dict = {key: value for key, value in genelist.items() if min_genes &lt;= len(value) &lt;= max_genes}\n    return filtered_dict\n</code></pre>"},{"location":"utils.html#pySingleCellNet.utils.find_elbow","title":"find_elbow","text":"<pre><code>find_elbow(adata)\n</code></pre> <p>Find the \"elbow\" index in the variance explained by principal components.</p> <ul> <li>variance_explained : list or array     Variance explained by each principal component, typically in decreasing order.</li> </ul> <ul> <li>int     The index corresponding to the \"elbow\" in the variance explained plot.</li> </ul> Source code in <code>src/pySingleCellNet/utils/adataTools.py</code> <pre><code>def find_elbow(\n    adata\n):\n    \"\"\"\n    Find the \"elbow\" index in the variance explained by principal components.\n\n    Parameters:\n    - variance_explained : list or array\n        Variance explained by each principal component, typically in decreasing order.\n\n    Returns:\n    - int\n        The index corresponding to the \"elbow\" in the variance explained plot.\n    \"\"\"\n    variance_explained = adata.uns['pca']['variance_ratio']\n    # Coordinates of all points\n    n_points = len(variance_explained)\n    all_coords = np.vstack((range(n_points), variance_explained)).T\n    # Line vector from first to last point\n    line_vec = all_coords[-1] - all_coords[0]\n    line_vec_norm = line_vec / np.sqrt(np.sum(line_vec**2))\n    # Vector being orthogonal to the line\n    vec_from_first = all_coords - all_coords[0]\n    scalar_prod = np.sum(vec_from_first * np.tile(line_vec_norm, (n_points, 1)), axis=1)\n    vec_from_first_parallel = np.outer(scalar_prod, line_vec_norm)\n    vec_to_line = vec_from_first - vec_from_first_parallel\n    # Distance to the line\n    dist_to_line = np.sqrt(np.sum(vec_to_line ** 2, axis=1))\n    # Index of the point with max distance to the line\n    elbow_idx = np.argmax(dist_to_line)\n    return elbow_idx\n</code></pre>"},{"location":"utils.html#pySingleCellNet.utils.find_knee_point","title":"find_knee_point","text":"<pre><code>find_knee_point(adata, total_counts_column='total_counts')\n</code></pre> <p>Identifies the knee point of the UMI count distribution in an AnnData object.</p> <p>Parameters:</p> <ul> <li> <code>adata</code>               (<code>AnnData</code>)           \u2013            <p>The input AnnData object.</p> </li> <li> <code>total_counts_column</code>               (<code>str</code>, default:                   <code>'total_counts'</code> )           \u2013            <p>Column in <code>adata.obs</code> containing total UMI counts. Default is \"total_counts\".</p> </li> <li> <code>show</code>               (<code>bool</code>)           \u2013            <p>If True, displays a log-log plot with the knee point. Default is True.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>float</code>          \u2013            <p>The UMI count value at the knee point.</p> </li> </ul> Source code in <code>src/pySingleCellNet/utils/qc.py</code> <pre><code>def find_knee_point(adata, total_counts_column=\"total_counts\"):\n    \"\"\"\n    Identifies the knee point of the UMI count distribution in an AnnData object.\n\n    Parameters:\n        adata (AnnData): The input AnnData object.\n        total_counts_column (str): Column in `adata.obs` containing total UMI counts. Default is \"total_counts\".\n        show (bool): If True, displays a log-log plot with the knee point. Default is True.\n\n    Returns:\n        float: The UMI count value at the knee point.\n    \"\"\"\n    # Extract total UMI counts\n    umi_counts = adata.obs[total_counts_column]\n\n    # Sort UMI counts in descending order\n    sorted_umi_counts = np.sort(umi_counts)[::-1]\n\n    # Compute cumulative UMI counts (normalized to a fraction)\n    cumulative_counts = np.cumsum(sorted_umi_counts)\n    cumulative_fraction = cumulative_counts / cumulative_counts[-1]\n\n    # Compute derivatives to identify the knee point\n    first_derivative = np.gradient(cumulative_fraction)\n    second_derivative = np.gradient(first_derivative)\n\n    # Find the index of the maximum curvature (knee point)\n    knee_idx = np.argmax(second_derivative)\n    knee_point_value = sorted_umi_counts[knee_idx]\n\n    return knee_point_value\n</code></pre>"},{"location":"utils.html#pySingleCellNet.utils.generate_joint_graph","title":"generate_joint_graph","text":"<pre><code>generate_joint_graph(adata, connectivity_keys, weights, output_key='jointNeighbors')\n</code></pre> <p>Create a joint graph by combining multiple connectivity graphs with specified weights.</p> <p>This function computes the weighted sum of selected connectivity and distance matrices  in an AnnData object and stores the result in <code>.obsp</code>.</p> <p>Parameters:</p> <ul> <li> <code>adata</code>               (<code>AnnData</code>)           \u2013            <p>The AnnData object containing connectivity matrices in <code>.obsp</code>.</p> </li> <li> <code>connectivity_keys</code>               (<code>list of str</code>)           \u2013            <p>A list of keys in <code>adata.obsp</code> corresponding to connectivity matrices to combine.</p> </li> <li> <code>weights</code>               (<code>list of float</code>)           \u2013            <p>A list of weights for each connectivity matrix. Must match the length of <code>connectivity_keys</code>.</p> </li> <li> <code>output_key</code>               (<code>str</code>, default:                   <code>'jointNeighbors'</code> )           \u2013            <p>The base key under which to store the combined graph in <code>.obsp</code>.  The default is <code>'jointNeighbors'</code>.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the number of <code>connectivity_keys</code> does not match the number of <code>weights</code>.</p> </li> <li> <code>KeyError</code>             \u2013            <p>If any key in <code>connectivity_keys</code> or its corresponding distances key is not found in <code>adata.obsp</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>None</code>          \u2013            <p>Updates the AnnData object in place by adding the combined connectivity and distance matrices to <code>.obsp</code> and metadata to <code>.uns</code>.</p> </li> </ul> Example <p>generate_joint_graph(adata, ['neighbors_connectivities', 'umap_connectivities'], [0.7, 0.3]) adata.obsp['jointNeighbors_connectivities'] adata.uns['jointNeighbors']</p> Source code in <code>src/pySingleCellNet/utils/adataTools.py</code> <pre><code>def generate_joint_graph(adata, connectivity_keys, weights, output_key='jointNeighbors'):\n    \"\"\"Create a joint graph by combining multiple connectivity graphs with specified weights.\n\n    This function computes the weighted sum of selected connectivity and distance matrices \n    in an AnnData object and stores the result in `.obsp`.\n\n    Args:\n        adata (AnnData): \n            The AnnData object containing connectivity matrices in `.obsp`.\n        connectivity_keys (list of str): \n            A list of keys in `adata.obsp` corresponding to connectivity matrices to combine.\n        weights (list of float): \n            A list of weights for each connectivity matrix. Must match the length of `connectivity_keys`.\n        output_key (str, optional): \n            The base key under which to store the combined graph in `.obsp`. \n            The default is `'jointNeighbors'`.\n\n    Raises:\n        ValueError: If the number of `connectivity_keys` does not match the number of `weights`.\n        KeyError: If any key in `connectivity_keys` or its corresponding distances key is not found in `adata.obsp`.\n\n    Returns:\n        None: \n            Updates the AnnData object in place by adding the combined connectivity and distance matrices\n            to `.obsp` and metadata to `.uns`.\n\n    Example:\n        &gt;&gt;&gt; generate_joint_graph(adata, ['neighbors_connectivities', 'umap_connectivities'], [0.7, 0.3])\n        &gt;&gt;&gt; adata.obsp['jointNeighbors_connectivities']\n        &gt;&gt;&gt; adata.uns['jointNeighbors']\n    \"\"\"\n\n    if len(connectivity_keys) != len(weights):\n        raise ValueError(\"The number of connectivity keys must match the number of weights.\")\n\n    # Initialize the joint graph and distances matrix with zeros\n    joint_graph = None\n    joint_distances = None\n    # Loop through each connectivity key and weight\n    for key, weight in zip(connectivity_keys, weights):\n        if key not in adata.obsp:\n            raise KeyError(f\"'{key}' not found in adata.obsp.\")\n\n        # Retrieve the connectivity matrix\n        connectivity_matrix = adata.obsp[key]\n        # Assume corresponding distances key exists\n        distances_key = key.replace('connectivities', 'distances')\n        if distances_key not in adata.obsp:\n            raise KeyError(f\"'{distances_key}' not found in adata.obsp.\")\n        distances_matrix = adata.obsp[distances_key]\n        # Initialize or accumulate the weighted connectivity and distances matrices\n        if joint_graph is None:\n            joint_graph = weight * connectivity_matrix\n            joint_distances = weight * distances_matrix\n        else:\n            joint_graph += weight * connectivity_matrix\n            joint_distances += weight * distances_matrix\n\n    # Save the resulting joint graph and distances matrix in the specified keys of .obsp\n\n    adata.obsp[output_key + '_connectivities'] = joint_graph\n    adata.obsp[output_key + '_distances'] = joint_distances\n\n    # Save metadata about the joint graph in .uns\n    adata.uns[output_key] = {\n        'connectivities_key': output_key + '_connectivities',\n        'distances_key': output_key + '_distances',\n        'params': {\n            'connectivity_keys': connectivity_keys,\n            'weights': weights,\n            'method': \"umap\"\n        }\n    }\n</code></pre>"},{"location":"utils.html#pySingleCellNet.utils.get_unique_colors","title":"get_unique_colors","text":"<pre><code>get_unique_colors(n_colors)\n</code></pre> <p>Generate a list of unique colors from the Tab20, Tab20b, and Tab20c colormaps.</p> <p>Parameters: - n_colors: The number of unique colors needed.</p> <p>Returns: - A list of unique colors.</p> Source code in <code>src/pySingleCellNet/utils/colors.py</code> <pre><code>def get_unique_colors(n_colors):\n    \"\"\"\n    Generate a list of unique colors from the Tab20, Tab20b, and Tab20c colormaps.\n\n    Parameters:\n    - n_colors: The number of unique colors needed.\n\n    Returns:\n    - A list of unique colors.\n    \"\"\"\n    # Get the colormaps\n    tab20 = plt.get_cmap('tab20').colors\n    tab20b = plt.get_cmap('tab20b').colors\n    tab20c = plt.get_cmap('tab20c').colors\n\n    # Combine the colors from the colormaps\n    combined_colors = np.vstack([tab20, tab20b, tab20c])\n\n    # Check if the requested number of colors exceeds the available unique colors\n    if n_colors &gt; len(combined_colors):\n        raise ValueError(f\"Requested number of colors ({n_colors}) exceeds the available unique colors ({len(combined_colors)}).\")\n\n    # Select the required number of unique colors\n    selected_colors = combined_colors[:n_colors]\n    return selected_colors\n</code></pre>"},{"location":"utils.html#pySingleCellNet.utils.mito_rib","title":"mito_rib","text":"<pre><code>mito_rib(adQ, species='MM', log1p=True, clean=True)\n</code></pre> <p>Calculate mitochondrial and ribosomal QC metrics and add them to the <code>.var</code> attribute of the AnnData object.</p>"},{"location":"utils.html#pySingleCellNet.utils.mito_rib--parameters","title":"Parameters","text":"<p>adQ : AnnData     Annotated data matrix with observations (cells) and variables (features). species : str, optional (default: \"MM\")     The species of the input data. Can be \"MM\" (Mus musculus) or \"HS\" (Homo sapiens). clean : bool, optional (default: True)     Whether to remove mitochondrial and ribosomal genes from the data.</p>"},{"location":"utils.html#pySingleCellNet.utils.mito_rib--returns","title":"Returns","text":"<p>AnnData     Annotated data matrix with QC metrics added to the <code>.var</code> attribute.</p> Source code in <code>src/pySingleCellNet/utils/qc.py</code> <pre><code>def mito_rib(adQ: AnnData, species: str = \"MM\", log1p = True, clean: bool = True) -&gt; AnnData:\n    \"\"\"\n    Calculate mitochondrial and ribosomal QC metrics and add them to the `.var` attribute of the AnnData object.\n\n    Parameters\n    ----------\n    adQ : AnnData\n        Annotated data matrix with observations (cells) and variables (features).\n    species : str, optional (default: \"MM\")\n        The species of the input data. Can be \"MM\" (Mus musculus) or \"HS\" (Homo sapiens).\n    clean : bool, optional (default: True)\n        Whether to remove mitochondrial and ribosomal genes from the data.\n\n    Returns\n    -------\n    AnnData\n        Annotated data matrix with QC metrics added to the `.var` attribute.\n    \"\"\"\n    # Create a copy of the input data\n    adata = adQ.copy()\n\n    # Define mitochondrial and ribosomal gene prefixes based on the species\n    if species == 'MM':\n        mt_prefix = \"mt-\"\n        ribo_prefix = (\"Rps\",\"Rpl\")\n    else:\n        mt_prefix = \"MT-\"\n        ribo_prefix = (\"RPS\",\"RPL\")\n\n    # Add mitochondrial and ribosomal gene flags to the `.var` attribute\n    adata.var['mt'] = adata.var_names.str.startswith((mt_prefix))\n    adata.var['ribo'] = adata.var_names.str.startswith(ribo_prefix)\n\n    # Calculate QC metrics using Scanpy's `calculate_qc_metrics` function\n    sc.pp.calculate_qc_metrics(\n        adata,\n        qc_vars=['ribo', 'mt'],\n        percent_top=None,\n        log1p=log1p,\n        inplace=True\n    )\n\n    # Optionally remove mitochondrial and ribosomal genes from the data\n    if clean:\n        mito_genes = adata.var_names.str.startswith(mt_prefix)\n        ribo_genes = adata.var_names.str.startswith(ribo_prefix)\n        remove = np.add(mito_genes, ribo_genes)\n        keep = np.invert(remove)\n        adata = adata[:,keep].copy()\n        # sc.pp.calculate_qc_metrics(adata,percent_top=None,log1p=False,inplace=True)\n\n    return adata\n</code></pre>"},{"location":"utils.html#pySingleCellNet.utils.mito_rib_heme","title":"mito_rib_heme","text":"<pre><code>mito_rib_heme(adQ, species='MM', clean=None)\n</code></pre> <p>Calculate mitochondrial, ribosomal, and hemoglobin QC metrics  and add them to the <code>.var</code> attribute of the AnnData object.</p>"},{"location":"utils.html#pySingleCellNet.utils.mito_rib_heme--parameters","title":"Parameters","text":"<p>adQ : AnnData     Annotated data matrix with observations (cells) and variables (features). species : str, optional (default: \"MM\")     The species of the input data. Can be \"MM\" (Mus musculus) or \"HS\" (Homo sapiens). clean : dict, optional (default: {'ribo': True, 'mt': True, 'heme': True})     Dictionary controlling whether to remove:       - 'ribo': ribosomal genes       - 'mt': mitochondrial genes       - 'heme': hemoglobin genes</p>"},{"location":"utils.html#pySingleCellNet.utils.mito_rib_heme--returns","title":"Returns","text":"<p>AnnData     Annotated data matrix with QC metrics added to the <code>.var</code> attribute,     and optionally with certain gene classes removed.</p> Source code in <code>src/pySingleCellNet/utils/qc.py</code> <pre><code>def mito_rib_heme(adQ: AnnData,\n                  species: str = \"MM\",\n                  clean: dict = None) -&gt; AnnData:\n    \"\"\"\n    Calculate mitochondrial, ribosomal, and hemoglobin QC metrics \n    and add them to the `.var` attribute of the AnnData object.\n\n    Parameters\n    ----------\n    adQ : AnnData\n        Annotated data matrix with observations (cells) and variables (features).\n    species : str, optional (default: \"MM\")\n        The species of the input data. Can be \"MM\" (Mus musculus) or \"HS\" (Homo sapiens).\n    clean : dict, optional (default: {'ribo': True, 'mt': True, 'heme': True})\n        Dictionary controlling whether to remove:\n          - 'ribo': ribosomal genes\n          - 'mt': mitochondrial genes\n          - 'heme': hemoglobin genes\n\n    Returns\n    -------\n    AnnData\n        Annotated data matrix with QC metrics added to the `.var` attribute,\n        and optionally with certain gene classes removed.\n    \"\"\"\n    # -------------------------\n    # 1. Set default if clean is None\n    # -------------------------\n    if clean is None:\n        clean = {'ribo': True, 'mt': True, 'heme': True}\n    else:\n        # Ensure all three keys exist; if not, set them to default True\n        for k in ['ribo', 'mt', 'heme']:\n            if k not in clean:\n                clean[k] = True\n\n    # -------------------------\n    # 2. Copy the input data\n    # -------------------------\n    adata = adQ.copy()\n\n    # -------------------------\n    # 3. Define gene prefixes based on species\n    # -------------------------\n    if species == 'MM':\n        # MOUSE\n        mt_prefix = \"mt-\"\n        ribo_prefix = (\"Rps\", \"Rpl\")\n        # Common mouse hemoglobin genes often start with 'Hba-' or 'Hbb-'\n        heme_prefix = (\"Hba-\", \"Hbb-\")\n\n    else:\n        # HUMAN\n        mt_prefix = \"MT-\"\n        ribo_prefix = (\"RPS\", \"RPL\")\n        # Human hemoglobin genes typically start with 'HB...' \n        # (HBA, HBB, HBD, HBE, HBG, HBZ, HBM, HBQ, etc.)\n        # Using just \"HB\" can be too broad in some annotations, \n        # so here's a more explicit tuple:\n        heme_prefix = (\"HBA\", \"HBB\", \"HBD\", \"HBE\", \"HBG\", \"HBZ\", \"HBM\", \"HBQ\")\n\n    # -------------------------\n    # 4. Flag MT, Ribo, and Heme genes in .var\n    # -------------------------\n    adata.var['mt'] = adata.var_names.str.startswith(mt_prefix)\n    adata.var['ribo'] = adata.var_names.str.startswith(ribo_prefix)\n    adata.var['heme'] = adata.var_names.str.startswith(heme_prefix)\n\n    # -------------------------\n    # 5. Calculate QC metrics \n    #    (Scanpy automatically calculates .var['total_counts'] etc.)\n    # -------------------------\n    sc.pp.calculate_qc_metrics(\n        adata,\n        qc_vars=['ribo', 'mt', 'heme'],\n        percent_top=None,\n        log1p=True,\n        inplace=True\n    )\n\n    # -------------------------\n    # 6. Optionally remove genes\n    # -------------------------\n    remove_mask = np.zeros(adata.shape[1], dtype=bool)\n\n    if clean['mt']:\n        remove_mask |= adata.var['mt'].values\n    if clean['ribo']:\n        remove_mask |= adata.var['ribo'].values\n    if clean['heme']:\n        remove_mask |= adata.var['heme'].values\n\n    keep_mask = ~remove_mask\n\n    adata = adata[:, keep_mask].copy()\n\n    # -------------------------\n    # 7. Return the modified AnnData\n    # -------------------------\n    return adata\n</code></pre>"},{"location":"utils.html#pySingleCellNet.utils.rank_genes_subsets","title":"rank_genes_subsets","text":"<pre><code>rank_genes_subsets(adata, groupby, grpA, grpB, pval=0.01, layer=None)\n</code></pre> <p>Subset an AnnData object to specified groups, create a new .obs column labeling cells as group A or B, and run rank_genes_groups for differential expression analysis. Necessary because the scanpy reference does not seem to work</p> <p>Parameters:</p> <ul> <li> <code>adata</code>               (<code>AnnData</code>)           \u2013            <p>The AnnData object.</p> </li> <li> <code>groupby</code>               (<code>str</code>)           \u2013            <p>The .obs column to group cells by.</p> </li> <li> <code>grpA</code>               (<code>list</code>)           \u2013            <p>Values used to subset cells into group A.</p> </li> <li> <code>grpB</code>               (<code>list</code>)           \u2013            <p>Values used to subset cells into group B.</p> </li> <li> <code>layer</code>               (<code>str</code>, default:                   <code>None</code> )           \u2013            <p>Layer to use for expression values.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>AnnData</code>          \u2013            <p>Subsetted and labeled AnnData object after running rank_genes_groups.</p> </li> </ul> Source code in <code>src/pySingleCellNet/utils/gene.py</code> <pre><code>def rank_genes_subsets(\n    adata,\n    groupby,\n    grpA,\n    grpB,\n    pval = 0.01,\n    layer=None\n):\n    \"\"\"\n    Subset an AnnData object to specified groups, create a new .obs column labeling cells\n    as group A or B, and run rank_genes_groups for differential expression analysis. Necessary because the scanpy reference does not seem to work\n\n    Parameters:\n        adata (AnnData): The AnnData object.\n        groupby (str): The .obs column to group cells by.\n        grpA (list): Values used to subset cells into group A.\n        grpB (list): Values used to subset cells into group B.\n        layer (str, optional): Layer to use for expression values.\n\n    Returns:\n        AnnData: Subsetted and labeled AnnData object after running rank_genes_groups.\n    \"\"\"\n    # Subset the data to cells in either grpA or grpB\n    subset = adata[adata.obs[groupby].isin(grpA + grpB)].copy()\n    # Create a new .obs column labeling cells as 'grpA' or 'grpB'\n    subset.obs[\"comparison_group\"] = subset.obs[groupby].apply(\n        lambda x: \"grpA\" if x in grpA else \"grpB\"\n    )\n    # Run rank_genes_groups\n    sc.tl.rank_genes_groups(\n        subset,\n        groupby=\"comparison_group\",\n        layer=layer,\n        pts = True,\n        use_raw=False\n    )\n    # return subset\n    ans = sc.get.rank_genes_groups_df(subset, group='grpA', pval_cutoff=pval)\n    return ans\n</code></pre>"},{"location":"utils.html#pySingleCellNet.utils.read_gmt","title":"read_gmt","text":"<pre><code>read_gmt(file_path)\n</code></pre> <p>Read a Gene Matrix Transposed (GMT) file and return a dictionary of gene sets.</p> <p>Parameters:</p> <ul> <li> <code>file_path</code>               (<code>str</code>)           \u2013            <p>Path to the GMT file.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>dict</code> (              <code>dict</code> )          \u2013            <p>A dictionary where keys are gene set names and values are lists of associated genes.</p> </li> </ul> Source code in <code>src/pySingleCellNet/utils/annotation.py</code> <pre><code>def read_gmt(file_path: str) -&gt; dict:\n    \"\"\"\n    Read a Gene Matrix Transposed (GMT) file and return a dictionary of gene sets.\n\n    Args:\n        file_path (str): Path to the GMT file.\n\n    Returns:\n        dict: A dictionary where keys are gene set names and values are lists of associated genes.\n    \"\"\"\n    gene_sets = {}\n\n    with open(file_path, 'r') as gmt_file:\n        for line in gmt_file:\n            columns = line.strip().split('\\t')\n            gene_set_name = columns[0]\n            description = columns[1]  # This can be ignored if not needed\n            genes = columns[2:]\n\n            gene_sets[gene_set_name] = genes\n\n    return gene_sets\n</code></pre>"},{"location":"utils.html#pySingleCellNet.utils.reassign_selected_clusters","title":"reassign_selected_clusters","text":"<pre><code>reassign_selected_clusters(adata, dendro_key, current_label, new_label, clusters_to_clean=None)\n</code></pre> <p>Reassign cells whose cluster is in <code>clusters_to_clean</code> by picking the  highest-correlation cluster from the dendrogram correlation matrix.</p> <p>We fix Scanpy's default behavior where:   - 'categories_ordered' (leaf order) != the row order in 'correlation_matrix'.   - Instead, 'categories_idx_ordered' is the permutation that maps leaf positions      to row indices in the original correlation matrix.</p>"},{"location":"utils.html#pySingleCellNet.utils.reassign_selected_clusters--parameters","title":"Parameters","text":"<p>adata : anndata.AnnData     Must contain:       - adata.obs[current_label]: the current cluster assignments (strings).       - adata.uns[dendro_key]: a dict with:          * \"categories_ordered\": list of cluster labels in dendrogram (leaf) order          * \"categories_idx_ordered\": list of row indices corresponding to the above          * \"correlation_matrix\": the NxN matrix of correlations in the original order dendro_key : str     Key in adata.uns that has the dendrogram data. current_label : str     Column in adata.obs containing the current cluster assignments. new_label : str     Column name in adata.obs where we store the reassigned clusters. clusters_to_clean : list or set of str, optional     Labels that should be reassigned. If None, nothing will be cleaned.</p>"},{"location":"utils.html#pySingleCellNet.utils.reassign_selected_clusters--returns","title":"Returns","text":"<p>None     Adds a new column <code>adata.obs[new_label]</code> with updated assignments.</p> Source code in <code>src/pySingleCellNet/utils/cell.py</code> <pre><code>def reassign_selected_clusters(\n    adata,\n    dendro_key,\n    current_label,\n    new_label,\n    clusters_to_clean=None\n):\n    \"\"\"\n    Reassign cells whose cluster is in `clusters_to_clean` by picking the \n    highest-correlation cluster from the dendrogram correlation matrix.\n\n    We fix Scanpy's default behavior where:\n      - 'categories_ordered' (leaf order) != the row order in 'correlation_matrix'.\n      - Instead, 'categories_idx_ordered' is the permutation that maps leaf positions \n        to row indices in the original correlation matrix.\n\n    Parameters\n    ----------\n    adata : anndata.AnnData\n        Must contain:\n          - adata.obs[current_label]: the current cluster assignments (strings).\n          - adata.uns[dendro_key]: a dict with:\n             * \"categories_ordered\": list of cluster labels in dendrogram (leaf) order\n             * \"categories_idx_ordered\": list of row indices corresponding to the above\n             * \"correlation_matrix\": the NxN matrix of correlations in the original order\n    dendro_key : str\n        Key in adata.uns that has the dendrogram data.\n    current_label : str\n        Column in adata.obs containing the current cluster assignments.\n    new_label : str\n        Column name in adata.obs where we store the reassigned clusters.\n    clusters_to_clean : list or set of str, optional\n        Labels that should be reassigned. If None, nothing will be cleaned.\n\n    Returns\n    -------\n    None\n        Adds a new column `adata.obs[new_label]` with updated assignments.\n    \"\"\"\n\n    if clusters_to_clean is None:\n        clusters_to_clean = []\n    clusters_to_clean_set = set(clusters_to_clean)\n\n    # Ensure the column is string (not categorical) to avoid assignment issues\n    if pd.api.types.is_categorical_dtype(adata.obs[current_label]):\n        adata.obs[current_label] = adata.obs[current_label].astype(str)\n\n    # Pull out original assignments\n    original_assignments = adata.obs[current_label].values\n    new_assignments = original_assignments.copy()\n\n    # Retrieve dendrogram data\n    if dendro_key not in adata.uns:\n        raise KeyError(f\"{dendro_key} not found in adata.uns.\")\n    dendro_data = adata.uns[dendro_key]\n\n    categories_ordered = dendro_data.get(\"categories_ordered\", None)      # Leaf labels\n    leaves = dendro_data.get(\"categories_idx_ordered\", None)             # Leaf indices\n    corr_matrix = dendro_data.get(\"correlation_matrix\", None)\n\n    if (categories_ordered is None or leaves is None or corr_matrix is None):\n        raise ValueError(\n            f\"adata.uns['{dendro_key}'] must contain \"\n            \"'categories_ordered', 'categories_idx_ordered', and 'correlation_matrix'.\"\n        )\n\n    n_cats = len(categories_ordered)\n    if n_cats != len(leaves):\n        raise ValueError(\"Mismatch: categories_ordered and categories_idx_ordered differ in length.\")\n    if corr_matrix.shape != (n_cats, n_cats):\n        raise ValueError(\"Mismatch: correlation_matrix shape does not match number of categories.\")\n\n    # --------------------------------------------------------\n    # 1) Reconstruct the \"original\" category order used in corr_matrix\n    #    Because Scanpy does not reorder corr_matrix to the dendrogram's leaf order;\n    #    instead it stores the \"dendrogram order\" in leaves + categories_ordered.\n    #\n    #    categories_ordered[i] = label at leaf i\n    #    leaves[i] = index in the original order for that leaf\n    #\n    #    So if leaves = [2, 0, 1], it means:\n    #      - leaf 0 is originally row 2,\n    #      - leaf 1 is originally row 0,\n    #      - leaf 2 is originally row 1.\n    #\n    #    We'll invert that so original_categories[row_idx] = label for that row.\n    # --------------------------------------------------------\n    original_categories = [None]*n_cats\n    for leaf_pos, row_idx in enumerate(leaves):\n        # categories_ordered[leaf_pos] is the label at leaf_pos\n        label = categories_ordered[leaf_pos]\n        original_categories[row_idx] = label\n\n    # Build a lookup from label -&gt; row index in corr_matrix\n    label_to_idx = {lbl: i for i, lbl in enumerate(original_categories)}\n\n    def find_closest_cluster(label):\n        \"\"\"\n        Return the label whose correlation is highest with `label`, \n        skipping the label itself and any in clusters_to_clean_set.\n\n        'corr_matrix' is in the \"original\" order, \n        so we find its row via 'label_to_idx[label]'.\n        \"\"\"\n        if label not in label_to_idx:\n            return None  # no data for this label\n        row_idx = label_to_idx[label]\n        row = corr_matrix[row_idx]\n\n        # Sort indices by descending correlation\n        sorted_idx = np.argsort(row)[::-1]  # highest corr first\n\n        for idx_ in sorted_idx:\n            # skip itself\n            if idx_ == row_idx:\n                continue\n            candidate_label = original_categories[idx_]\n            if candidate_label in clusters_to_clean_set:\n                continue  # skip \"clean\" labels\n            return candidate_label\n        return None\n\n    # Reassign if needed\n    for i in range(len(new_assignments)):\n        c_label = new_assignments[i]\n        if c_label in clusters_to_clean_set:\n            fallback = find_closest_cluster(c_label)\n            if fallback is not None:\n                new_assignments[i] = fallback\n            # else remain in the same cluster\n\n    adata.obs[new_label] = new_assignments\n    # make sure type is category, seems to be needed for sc.tl.dendrogram\n    adata.obs[new_label] = adata.obs[new_label].astype('category')\n</code></pre>"},{"location":"utils.html#pySingleCellNet.utils.rename_cluster_labels","title":"rename_cluster_labels","text":"<pre><code>rename_cluster_labels(adata, old_col='cluster', new_col='short_cluster')\n</code></pre> <p>Renames cluster labels in the specified .obs column with multi-letter codes.</p> <ul> <li>All unique labels (including NaN) are mapped in order of appearance to    a base-26 style ID: 'A', 'B', ..., 'Z', 'AA', 'AB', etc.</li> <li>The new labels are stored as a categorical column in <code>adata.obs[new_col]</code>.</li> </ul> <p>Parameters:</p> <ul> <li> <code>adata</code>               (<code>AnnData</code>)           \u2013            <p>The AnnData object containing the cluster labels.</p> </li> <li> <code>old_col</code>               (<code>str</code>, default:                   <code>'cluster'</code> )           \u2013            <p>The name of the .obs column that has the original cluster labels. Defaults to \"cluster\".</p> </li> <li> <code>new_col</code>               (<code>str</code>, default:                   <code>'short_cluster'</code> )           \u2013            <p>The name of the new .obs column that will store the shortened labels. Defaults to \"short_cluster\".</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>None</code> (              <code>None</code> )          \u2013            <p>The function adds a new column to <code>adata.obs</code> in place.</p> </li> </ul> Source code in <code>src/pySingleCellNet/utils/cell.py</code> <pre><code>def rename_cluster_labels(\n    adata: ad.AnnData,\n    old_col: str = \"cluster\",\n    new_col: str = \"short_cluster\"\n) -&gt; None:\n    \"\"\"\n    Renames cluster labels in the specified .obs column with multi-letter codes.\n\n    - All unique labels (including NaN) are mapped in order of appearance to \n      a base-26 style ID: 'A', 'B', ..., 'Z', 'AA', 'AB', etc.\n    - The new labels are stored as a categorical column in `adata.obs[new_col]`.\n\n    Args:\n        adata (AnnData):\n            The AnnData object containing the cluster labels.\n        old_col (str, optional):\n            The name of the .obs column that has the original cluster labels.\n            Defaults to \"cluster\".\n        new_col (str, optional):\n            The name of the new .obs column that will store the shortened labels.\n            Defaults to \"short_cluster\".\n\n    Returns:\n        None: The function adds a new column to `adata.obs` in place.\n    \"\"\"\n\n    # 1. Extract unique labels (including NaN), in the order they appear\n    unique_labels = adata.obs[old_col].unique()\n\n    # 2. Helper function for base-26 labeling\n    def index_to_label(idx: int) -&gt; str:\n        \"\"\"\n        Convert a zero-based index to a base-26 letter code:\n        0 -&gt; A\n        1 -&gt; B\n        ...\n        25 -&gt; Z\n        26 -&gt; AA\n        27 -&gt; AB\n        ...\n        \"\"\"\n        letters = []\n        while True:\n            remainder = idx % 26\n            letter = chr(ord('A') + remainder)\n            letters.append(letter)\n            idx = idx // 26 - 1\n            if idx &lt; 0:\n                break\n        return ''.join(letters[::-1])\n\n    # 3. Build the mapping (including NaN -&gt; next code)\n    label_map = {}\n    for i, lbl in enumerate(unique_labels):\n        label_map[lbl] = index_to_label(i)\n\n    # 4. Apply the mapping to create the new column\n    adata.obs[new_col] = adata.obs[old_col].map(label_map)\n    adata.obs[new_col] = adata.obs[new_col].astype(\"category\")\n</code></pre>"},{"location":"utils.html#pySingleCellNet.utils.score_sex","title":"score_sex","text":"<pre><code>score_sex(adata, y_genes=['Eif2s3y', 'Ddx3y', 'Uty'], x_inactivation_genes=['Xist', 'Tsix'])\n</code></pre> <p>Adds sex chromosome expression scores to an AnnData object.</p> This function calculates two scores for each cell in a scRNA-seq AnnData object <ul> <li>Y_score: the sum of expression values for a set of Y-chromosome specific genes.</li> <li>X_inact_score: the sum of expression values for genes involved in X-chromosome inactivation.</li> </ul> <p>The scores are added to the AnnData object's <code>.obs</code> DataFrame with the keys 'Y_score' and 'X_inact_score'.</p>"},{"location":"utils.html#pySingleCellNet.utils.score_sex--parameters","title":"Parameters","text":"<p>adata : AnnData     An AnnData object containing scRNA-seq data, with gene names in <code>adata.var_names</code>. y_genes : list of str, optional     List of Y-chromosome specific marker genes (default is ['Eif2s3y', 'Ddx3y', 'Uty']). x_inactivation_genes : list of str, optional     List of genes involved in X-chromosome inactivation (default is ['Xist', 'Tsix']).</p>"},{"location":"utils.html#pySingleCellNet.utils.score_sex--raises","title":"Raises","text":"<p>ValueError     If none of the Y-specific or X inactivation genes are found in <code>adata.var_names</code>.</p>"},{"location":"utils.html#pySingleCellNet.utils.score_sex--returns","title":"Returns","text":"<p>None     The function modifies the AnnData object in place by adding the score columns to <code>adata.obs</code>.</p> Source code in <code>src/pySingleCellNet/utils/gene.py</code> <pre><code>def score_sex(\n    adata, \n    y_genes=['Eif2s3y', 'Ddx3y', 'Uty'], \n    x_inactivation_genes=['Xist', 'Tsix']\n):\n    \"\"\"\n    Adds sex chromosome expression scores to an AnnData object.\n\n    This function calculates two scores for each cell in a scRNA-seq AnnData object:\n      - Y_score: the sum of expression values for a set of Y-chromosome specific genes.\n      - X_inact_score: the sum of expression values for genes involved in X-chromosome inactivation.\n\n    The scores are added to the AnnData object's `.obs` DataFrame with the keys 'Y_score' and 'X_inact_score'.\n\n    Parameters\n    ----------\n    adata : AnnData\n        An AnnData object containing scRNA-seq data, with gene names in `adata.var_names`.\n    y_genes : list of str, optional\n        List of Y-chromosome specific marker genes (default is ['Eif2s3y', 'Ddx3y', 'Uty']).\n    x_inactivation_genes : list of str, optional\n        List of genes involved in X-chromosome inactivation (default is ['Xist', 'Tsix']).\n\n    Raises\n    ------\n    ValueError\n        If none of the Y-specific or X inactivation genes are found in `adata.var_names`.\n\n    Returns\n    -------\n    None\n        The function modifies the AnnData object in place by adding the score columns to `adata.obs`.\n    \"\"\"\n    # Filter for genes that are available in the dataset.\n    available_y_genes = [gene for gene in y_genes if gene in adata.var_names]\n    available_x_genes = [gene for gene in x_inactivation_genes if gene in adata.var_names]\n\n    if not available_y_genes:\n        raise ValueError(\"None of the Y-specific genes were found in the dataset.\")\n    if not available_x_genes:\n        raise ValueError(\"None of the X inactivation genes were found in the dataset.\")\n\n    # Compute the sum of expression for the Y-specific genes.\n    y_expression = adata[:, available_y_genes].X\n    if hasattr(y_expression, \"toarray\"):\n        y_expression = y_expression.toarray()\n    adata.obs['Y_score'] = np.sum(y_expression, axis=1)\n\n    # Compute the sum of expression for the X inactivation genes.\n    x_expression = adata[:, available_x_genes].X\n    if hasattr(x_expression, \"toarray\"):\n        x_expression = x_expression.toarray()\n    adata.obs['X_inact_score'] = np.sum(x_expression, axis=1)\n\n    # Optionally, you could log some output:\n    print(\"Added 'Y_score' and 'X_inact_score' to adata.obs for {} cells.\".format(adata.n_obs))\n</code></pre>"},{"location":"utils.html#pySingleCellNet.utils.sort_obs_table","title":"sort_obs_table","text":"<pre><code>sort_obs_table(adata)\n</code></pre> <p>Sorts the observation table of an AnnData object by 'celltype' and the numeric part of 'stage'.</p> <p>This function takes an AnnData object as input, extracts the 'celltype' and 'stage' columns  from its observation (obs) DataFrame, counts the occurrences of each unique pair, and sorts  these counts first by 'celltype' and then by the numeric value extracted from 'stage'.</p> <p>Parameters:</p> <ul> <li> <code>adata</code>               (<code>AnnData</code>)           \u2013            <p>An AnnData object containing the single-cell dataset.</p> </li> </ul> <p>Returns:</p> <ul> <li>           \u2013            <p>pandas.DataFrame: A DataFrame with sorted counts of cell types and stages.</p> </li> </ul> Notes <p>The 'stage' column is expected to contain string values with a numeric part that can be  extracted and sorted numerically. The function does not modify the original AnnData object.</p> Source code in <code>src/pySingleCellNet/utils/cell.py</code> <pre><code>def sort_obs_table(adata):\n    \"\"\"\n    Sorts the observation table of an AnnData object by 'celltype' and the numeric part of 'stage'.\n\n    This function takes an AnnData object as input, extracts the 'celltype' and 'stage' columns \n    from its observation (obs) DataFrame, counts the occurrences of each unique pair, and sorts \n    these counts first by 'celltype' and then by the numeric value extracted from 'stage'.\n\n    Args:\n        adata (AnnData): An AnnData object containing the single-cell dataset.\n\n    Returns:\n        pandas.DataFrame: A DataFrame with sorted counts of cell types and stages.\n\n    Notes:\n        The 'stage' column is expected to contain string values with a numeric part that can be \n        extracted and sorted numerically. The function does not modify the original AnnData object.\n    \"\"\"\n    # Count occurrences of each unique 'celltype' and 'stage' pair\n    counts = adata.obs[['celltype', 'stage']].value_counts()\n    counts_df = counts.reset_index()\n    counts_df.columns = ['celltype', 'stage', 'count']\n\n    # Add a temporary column 'stage_num' for numeric sorting of 'stage'\n    # Then sort by 'celltype' and the numeric part of 'stage'\n    # Finally, drop the temporary 'stage_num' column\n    counts_df = (\n        counts_df\n        .assign(stage_num=lambda df: df['stage'].str.extract(r'(\\d+\\.\\d+|\\d+)')[0].astype(float))\n        .sort_values(by=['celltype', 'stage_num'])\n        .drop(columns='stage_num')\n    )\n\n    return counts_df\n</code></pre>"},{"location":"utils.html#pySingleCellNet.utils.split_adata_indices","title":"split_adata_indices","text":"<pre><code>split_adata_indices(adata, n_cells=100, groupby='cell_ontology_class', cellid=None, strata_col=None)\n</code></pre> <p>Splits an AnnData object into training and validation indices based on stratification by cell type and optionally by another categorical variable.</p> <p>Parameters:</p> <ul> <li> <code>adata</code>               (<code>AnnData</code>)           \u2013            <p>The annotated data matrix to split.</p> </li> <li> <code>n_cells</code>               (<code>int</code>, default:                   <code>100</code> )           \u2013            <p>The number of cells to sample per cell type.</p> </li> <li> <code>groupby</code>               (<code>str</code>, default:                   <code>'cell_ontology_class'</code> )           \u2013            <p>The column name in adata.obs that specifies the cell type.                      Defaults to \"cell_ontology_class\".</p> </li> <li> <code>cellid</code>               (<code>str</code>, default:                   <code>None</code> )           \u2013            <p>The column in adata.obs to use as a unique identifier for cells.                     If None, it defaults to using the index.</p> </li> <li> <code>strata_col</code>               (<code>str</code>, default:                   <code>None</code> )           \u2013            <p>The column name in adata.obs used for secondary stratification,                         such as developmental stage, gender, or disease status.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple</code> (              <code>tuple</code> )          \u2013            <p>A tuple containing two lists: - training_indices (list): List of indices for the training set. - validation_indices (list): List of indices for the validation set.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If any specified column names do not exist in the DataFrame.</p> </li> </ul> Source code in <code>src/pySingleCellNet/utils/cell.py</code> <pre><code>def split_adata_indices(\n    adata: ad.AnnData,\n    n_cells: int = 100,\n    groupby: str = \"cell_ontology_class\",\n    cellid: str = None,\n    strata_col: str  = None\n) -&gt; tuple:\n    \"\"\"\n    Splits an AnnData object into training and validation indices based on stratification by cell type\n    and optionally by another categorical variable.\n\n    Args:\n        adata (AnnData): The annotated data matrix to split.\n        n_cells (int): The number of cells to sample per cell type.\n        groupby (str, optional): The column name in adata.obs that specifies the cell type.\n                                 Defaults to \"cell_ontology_class\".\n        cellid (str, optional): The column in adata.obs to use as a unique identifier for cells.\n                                If None, it defaults to using the index.\n        strata_col (str, optional): The column name in adata.obs used for secondary stratification,\n                                    such as developmental stage, gender, or disease status.\n\n    Returns:\n        tuple: A tuple containing two lists:\n            - training_indices (list): List of indices for the training set.\n            - validation_indices (list): List of indices for the validation set.\n\n    Raises:\n        ValueError: If any specified column names do not exist in the DataFrame.\n    \"\"\"\n    if cellid is None:\n        adata.obs[\"cellid\"] = adata.obs.index\n        cellid = \"cellid\"\n    if groupby not in adata.obs.columns or (strata_col and strata_col not in adata.obs.columns):\n        raise ValueError(\"Specified column names do not exist in the DataFrame.\")\n\n    cts = set(adata.obs[groupby])\n    trainingids = []\n\n    for ct in cts:\n        subset = adata[adata.obs[groupby] == ct]\n\n        if strata_col:\n            stratified_ids = []\n            strata_groups = subset.obs[strata_col].unique()\n            n_strata = len(strata_groups)\n\n            # Initialize desired count and structure to store samples per strata\n            desired_per_group = n_cells // n_strata\n            samples_per_group = {}\n            remaining = 0\n\n            # First pass: allocate base quota or maximum available if less than base\n            for group in strata_groups:\n                group_subset = subset[subset.obs[strata_col] == group]\n                available = group_subset.n_obs\n                if available &lt; desired_per_group:\n                    samples_per_group[group] = available\n                    remaining += desired_per_group - available\n                else:\n                    samples_per_group[group] = desired_per_group\n\n            # Second pass: redistribute remaining quota among groups that can supply more\n            # Continue redistributing until either there's no remaining quota or no group can supply more.\n            groups_can_supply = True\n            while remaining &gt; 0 and groups_can_supply:\n                groups_can_supply = False\n                for group in strata_groups:\n                    group_subset = subset[subset.obs[strata_col] == group]\n                    available = group_subset.n_obs\n                    # Check if this group can supply an extra cell beyond what we've allocated so far\n                    if samples_per_group[group] &lt; available:\n                        samples_per_group[group] += 1\n                        remaining -= 1\n                        groups_can_supply = True\n                        if remaining == 0:\n                            break\n\n            # Sample cells for each strata group based on the determined counts\n            for group in strata_groups:\n                group_subset = subset[subset.obs[strata_col] == group]\n                count_to_sample = samples_per_group.get(group, 0)\n                if count_to_sample &gt; 0:\n                    sampled_ids = np.random.choice(\n                        group_subset.obs[cellid].values, \n                        count_to_sample, \n                        replace=False\n                    )\n                    stratified_ids.extend(sampled_ids)\n\n            trainingids.extend(stratified_ids)\n        else:\n            ccount = min(subset.n_obs, n_cells)\n            sampled_ids = np.random.choice(subset.obs[cellid].values, ccount, replace=False)\n            trainingids.extend(sampled_ids)\n\n    # Get all unique IDs\n    all_ids = adata.obs[cellid].values\n    # Determine validation IDs\n    assume_unique = adata.obs_names.is_unique\n    val_ids = np.setdiff1d(all_ids, trainingids, assume_unique=assume_unique)\n\n    return trainingids, val_ids\n</code></pre>"},{"location":"utils.html#pySingleCellNet.utils.write_gmt","title":"write_gmt","text":"<pre><code>write_gmt(gene_list, filename, collection_name, prefix='')\n</code></pre> <p>Write a .gmt file from a gene list.</p> <p>gene_list: dict     Dictionary of gene sets (keys are gene set names, values are lists of genes). filename: str     The name of the file to write to. collection_name: str     The name of the gene set collection. prefix: str, optional     A prefix to add to each gene set name.</p> Source code in <code>src/pySingleCellNet/utils/annotation.py</code> <pre><code>def write_gmt(gene_list, filename, collection_name, prefix=\"\"):\n    \"\"\"\n    Write a .gmt file from a gene list.\n\n    Parameters:\n    gene_list: dict\n        Dictionary of gene sets (keys are gene set names, values are lists of genes).\n    filename: str\n        The name of the file to write to.\n    collection_name: str\n        The name of the gene set collection.\n    prefix: str, optional\n        A prefix to add to each gene set name.\n    \"\"\"\n    with open(filename, mode='w') as fo:\n        for akey in gene_list:\n            # replace whitespace with a \"_\"\n            gl_name = re.sub(r'\\s+', '_', akey)\n            if prefix:\n                pfix = prefix + \"_\" + gl_name\n            else:\n                pfix = gl_name\n            preface = pfix + \"\\t\" + collection_name + \"\\t\"\n            output = preface + \"\\t\".join(gene_list[akey])\n            print(output, file=fo)\n</code></pre>"},{"location":"notebooks/Basics.html","title":"Basics","text":"<p>In this brief tutorial, we show you how to train a pySCN classifier, assess its performance, and use it to predict the cell type of independent data.</p> In\u00a0[2]: Copied! <pre>import warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\nimport os, sys\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport scanpy as sc\nimport pySingleCellNet as cn\n</pre> import warnings warnings.filterwarnings(\"ignore\", category=FutureWarning) import os, sys import numpy as np import pandas as pd import matplotlib.pyplot as plt import scanpy as sc import pySingleCellNet as cn <p>Load the data</p> In\u00a0[3]: Copied! <pre>adref = sc.read_h5ad(\"../../data/raw/pySCN_testdata/adPBMC_ref_040623.h5ad\")\nadref.shape\n</pre> adref = sc.read_h5ad(\"../../data/raw/pySCN_testdata/adPBMC_ref_040623.h5ad\") adref.shape Out[3]: <pre>(10309, 20104)</pre> In\u00a0[4]: Copied! <pre>adQuery = sc.read_h5ad(\"../../data/raw/pySCN_testdata/adPBMC_query_1_20k_HT_040723.h5ad\")\nadQuery.shape\n</pre> adQuery = sc.read_h5ad(\"../../data/raw/pySCN_testdata/adPBMC_query_1_20k_HT_040723.h5ad\") adQuery.shape Out[4]: <pre>(21677, 23836)</pre> <p>Limit data to same set of genes</p> In\u00a0[5]: Copied! <pre>cn.ut.limit_anndata_to_common_genes([adref, adQuery])\nadref.shape\n</pre> cn.ut.limit_anndata_to_common_genes([adref, adQuery]) adref.shape Out[5]: <pre>(10309, 19043)</pre> <p>The training step assumes that some basic processing has been performed on the training data.</p> In\u00a0[6]: Copied! <pre>sc.pp.highly_variable_genes(adref, n_top_genes=3000, flavor='seurat_v3')\nsc.pp.normalize_total(adref)\nsc.pp.log1p(adref)\nadref.layers['lognorm'] = adref.X\nsc.pp.pca(adref)\n</pre> sc.pp.highly_variable_genes(adref, n_top_genes=3000, flavor='seurat_v3') sc.pp.normalize_total(adref) sc.pp.log1p(adref) adref.layers['lognorm'] = adref.X sc.pp.pca(adref) <p>Split the training data into a training set and a held out validation set.</p> In\u00a0[7]: Copied! <pre>tids, vids = cn.ut.split_adata_indices(adref, groupby = \"cell_type\")\nadTrain = adref[tids].copy()\nadHO = adref[vids].copy()\n</pre> tids, vids = cn.ut.split_adata_indices(adref, groupby = \"cell_type\") adTrain = adref[tids].copy() adHO = adref[vids].copy() In\u00a0[8]: Copied! <pre>adTrain.obs['cell_type'].value_counts()\n</pre> adTrain.obs['cell_type'].value_counts() Out[8]: <pre>cell_type\nB cell             100\nCD14 monocyte      100\nCD4 T cell         100\nCD8 T cell         100\nDendritic          100\nFCGR3A monocyte    100\nNK cell            100\nMegakaryocyte       59\nName: count, dtype: int64</pre> <p>Train the classifier and apply it to the held out data. This process adds 'SCN_class_argmax' to adQuery.obs, and 'SCN_score' to adQuery.uns.</p> In\u00a0[9]: Copied! <pre>clf = cn.cl.train_classifier(adTrain, \"cell_type\", nRand = 100, n_comps = 10)\ncn.cl.classify_anndata(adHO, clf)\nadHO.obs['SCN_class_argmax'].value_counts()\n</pre> clf = cn.cl.train_classifier(adTrain, \"cell_type\", nRand = 100, n_comps = 10) cn.cl.classify_anndata(adHO, clf) adHO.obs['SCN_class_argmax'].value_counts() <pre>Training classifier |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [100%] in 4.1s (1.21/s) \n</pre> Out[9]: <pre>SCN_class_argmax\nCD4 T cell         3272\nCD14 monocyte      2874\nB cell             1348\nCD8 T cell         1088\nNK cell             513\nFCGR3A monocyte     339\nDendritic            95\nrand                 19\nMegakaryocyte         2\nName: count, dtype: int64</pre> <p>Assess the performance of the classifier in predicting labels of the held out data.</p> In\u00a0[10]: Copied! <pre>c_report = cn.cl.create_classifier_report(adHO, ground_truth='cell_type', prediction='SCN_class_argmax')\ncn.pl.heatmap_classifier_report(c_report)\nplt.show()\n</pre> c_report = cn.cl.create_classifier_report(adHO, ground_truth='cell_type', prediction='SCN_class_argmax') cn.pl.heatmap_classifier_report(c_report) plt.show() <p>Now, we can apply thte classifier to the independent data.</p> In\u00a0[11]: Copied! <pre>cn.cl.classify_anndata(adQuery, clf)\nadQuery.obs['SCN_class_argmax'].value_counts()\n</pre> cn.cl.classify_anndata(adQuery, clf) adQuery.obs['SCN_class_argmax'].value_counts() Out[11]: <pre>SCN_class_argmax\nCD4 T cell         8160\nCD14 monocyte      6548\nB cell             2024\nFCGR3A monocyte    1897\nCD8 T cell         1778\nNK cell             936\nDendritic           277\nrand                 52\nMegakaryocyte         5\nName: count, dtype: int64</pre> <p>Visualize the classification results as a heatmap</p> In\u00a0[12]: Copied! <pre>cn.pl.heatmap_scores(adQuery, groupby='SCN_class_argmax')\n</pre> cn.pl.heatmap_scores(adQuery, groupby='SCN_class_argmax') <p>Compare the celltype proportions of the held out sample and the query sample. Only show those cell types that differ by more than 1% composition.</p> In\u00a0[13]: Copied! <pre>cn.pl.bar_compare_celltype_composition(adHO, adQuery, \"SCN_class_argmax\", min_delta = 1, colors = clf['ctColors'], metric='difference')\n</pre> cn.pl.bar_compare_celltype_composition(adHO, adQuery, \"SCN_class_argmax\", min_delta = 1, colors = clf['ctColors'], metric='difference') <p>Visualize cell type composition with a stacked barplot.</p> In\u00a0[15]: Copied! <pre>adlist = [adHO, adQuery]\nadlabels = [\"HO\", \"Query\"]\nafig = cn.pl.stackedbar_composition_list(adlist, labels=adlabels, color_dict=clf['ctColors'], obs_column = 'SCN_class_argmax')\n</pre> adlist = [adHO, adQuery] adlabels = [\"HO\", \"Query\"] afig = cn.pl.stackedbar_composition_list(adlist, labels=adlabels, color_dict=clf['ctColors'], obs_column = 'SCN_class_argmax')  In\u00a0[16]: Copied! <pre>sc.pp.highly_variable_genes(adQuery, n_top_genes=3000, flavor='seurat_v3')\nsc.pp.normalize_total(adQuery)\nsc.pp.log1p(adQuery)\nadQuery.layers['lognorm'] = adQuery.X\nsc.tl.pca(adQuery, mask_var='highly_variable')\n</pre> sc.pp.highly_variable_genes(adQuery, n_top_genes=3000, flavor='seurat_v3') sc.pp.normalize_total(adQuery) sc.pp.log1p(adQuery) adQuery.layers['lognorm'] = adQuery.X sc.tl.pca(adQuery, mask_var='highly_variable') In\u00a0[17]: Copied! <pre>def_npcs = 15\ndef_nneigh = 10\nsc.pp.neighbors(adQuery, n_neighbors = def_nneigh,  n_pcs = def_npcs)\nsc.pp.neighbors(adQuery, n_neighbors = def_nneigh,  use_rep = 'SCN_score', key_added='SCN_score_NN')\ncn.ut.generate_joint_graph(adQuery, connectivity_keys = [\"connectivities\", \"SCN_score_NN_connectivities\"], weights=[0.5, 0.5], output_key='jointNN')\nsc.tl.umap(adQuery, neighbors_key='jointNN')\n</pre> def_npcs = 15 def_nneigh = 10 sc.pp.neighbors(adQuery, n_neighbors = def_nneigh,  n_pcs = def_npcs) sc.pp.neighbors(adQuery, n_neighbors = def_nneigh,  use_rep = 'SCN_score', key_added='SCN_score_NN') cn.ut.generate_joint_graph(adQuery, connectivity_keys = [\"connectivities\", \"SCN_score_NN_connectivities\"], weights=[0.5, 0.5], output_key='jointNN') sc.tl.umap(adQuery, neighbors_key='jointNN') <p>We can compare the embeddings and clustering results using the joint embedding versus PC alone. First, cluster based on the joint kNN graph, and plot the embedding.</p> In\u00a0[18]: Copied! <pre>sc.tl.leiden(adQuery, adjacency=adQuery.obsp['jointNN_connectivities'], resolution=0.5, flavor=\"igraph\", n_iterations=2, key_added=\"joint_clusters\")\nsc.pl.umap(adQuery, color=['SCN_class_argmax','joint_clusters'], size=10, alpha=.25, legend_loc='on data')\n</pre> sc.tl.leiden(adQuery, adjacency=adQuery.obsp['jointNN_connectivities'], resolution=0.5, flavor=\"igraph\", n_iterations=2, key_added=\"joint_clusters\") sc.pl.umap(adQuery, color=['SCN_class_argmax','joint_clusters'], size=10, alpha=.25, legend_loc='on data') <p>Now, cluster and run UMAP on the PC-only kNN.</p> In\u00a0[22]: Copied! <pre>sc.tl.leiden(adQuery, adjacency=adQuery.obsp['connectivities'], resolution=0.5, flavor=\"igraph\", n_iterations=2, key_added=\"reg_clusters\")\nsc.tl.umap(adQuery, neighbors_key='neighbors')\nsc.pl.umap(adQuery, color=['SCN_class_argmax','reg_clusters'], size=10, alpha=.25, legend_loc='on data')\n</pre> sc.tl.leiden(adQuery, adjacency=adQuery.obsp['connectivities'], resolution=0.5, flavor=\"igraph\", n_iterations=2, key_added=\"reg_clusters\") sc.tl.umap(adQuery, neighbors_key='neighbors') sc.pl.umap(adQuery, color=['SCN_class_argmax','reg_clusters'], size=10, alpha=.25, legend_loc='on data')"},{"location":"notebooks/Basics.html#data","title":"Data\u00b6","text":""},{"location":"notebooks/Basics.html#training-data","title":"Training data\u00b6","text":"<p>We will use \u201c10k PBMCs from a Healthy Donor (v3 chemistry) Single Cell Gene Expression Dataset by Cell Ranger 3.0.0\u201d data set from 10X Genomics. You can see how that data was analyzed and annotated. link to processed training data</p>"},{"location":"notebooks/Basics.html#query-data","title":"Query data\u00b6","text":"<p>We will use another, unannotated Peripheral blood mononuclear cell (PBMC) data set here as the query data.</p> <ul> <li>h5ad file of the query data</li> <li>20k Human PBMCs, 3\u2019 HT v3.1, Chromium X</li> <li>Sourced from a healthy female donor</li> <li>23,837 cells</li> <li>35,000 reads per cell</li> </ul>"},{"location":"notebooks/Basics.html#create-embedding-of-query-data","title":"Create embedding of query data\u00b6","text":"<p>Sometimes it is informative to incorporate the SCN_scores into the embedding process as it emphasizes the cell type assignments. We achieve this by computing two kNN graphs. One is based on distances from PCs, the second is based on distances from the SCN_score matrix. Then, we run UMAP on the combination of these graphs.</p>"},{"location":"notebooks/categorize.html","title":"Explore","text":"<p>In this tutorial, we walk you through an application of PySCN to analyze mouse embryonic stem cells (mESCs) undergoing differentiation as embryoid bodies. We first train and assess a classifier with scRNAseq of gastrula-stage embryos. Then, we use this classifier to predict the cell type of the embryoid body cells. In the Categorization section below, we describe an approach to categorizing the predictions based on confidence in their accuracy and based on the relatedness of the predicted cell types predicted. We end this tutorial by showing how this categorization can help to identify signatures that distinguish in vitro cells from their in vivo counterparts.</p> In\u00a0[1]: Copied! <pre>import warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\nimport os, sys\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport scanpy as sc\nimport pySingleCellNet as cn\n</pre> import warnings warnings.filterwarnings(\"ignore\", category=FutureWarning) import os, sys import numpy as np import pandas as pd import matplotlib.pyplot as plt import scanpy as sc import pySingleCellNet as cn In\u00a0[2]: Copied! <pre>adRef = sc.read_h5ad(\"data/adPijuan_small.h5ad\")\nadQuery = sc.read_h5ad(\"../../data/raw/Spangler_2017/adata_Spangler_EB_day4_clean_raw_010225.h5ad\")\n</pre> adRef = sc.read_h5ad(\"data/adPijuan_small.h5ad\") adQuery = sc.read_h5ad(\"../../data/raw/Spangler_2017/adata_Spangler_EB_day4_clean_raw_010225.h5ad\") <p>Limit to shared genes</p> In\u00a0[3]: Copied! <pre>cn.ut.limit_anndata_to_common_genes([adRef, adQuery])\n</pre> cn.ut.limit_anndata_to_common_genes([adRef, adQuery]) <p>Split the reference data into training and held out data.</p> In\u00a0[4]: Copied! <pre>n_cells = 500\ngroupby = 'ct1'\nstratify_by = 'stage'\ntids, vids = cn.ut.split_adata_indices(adRef, n_cells, groupby=groupby, cellid=None, strata_col=stratify_by)\nadTrain = adRef[tids].copy()\nadHO = adRef[vids].copy()\n</pre> n_cells = 500 groupby = 'ct1' stratify_by = 'stage' tids, vids = cn.ut.split_adata_indices(adRef, n_cells, groupby=groupby, cellid=None, strata_col=stratify_by) adTrain = adRef[tids].copy() adHO = adRef[vids].copy() <p>Prepare the training data.</p> In\u00a0[5]: Copied! <pre>adTrain.layers['counts'] = adTrain.X.copy()\nsc.pp.normalize_total(adTrain)\nsc.pp.log1p(adTrain)\nsc.pp.highly_variable_genes(adTrain, n_top_genes=2000, flavor='seurat_v3', layer='counts')\nsc.tl.pca(adTrain, mask_var='highly_variable')\n</pre> adTrain.layers['counts'] = adTrain.X.copy() sc.pp.normalize_total(adTrain) sc.pp.log1p(adTrain) sc.pp.highly_variable_genes(adTrain, n_top_genes=2000, flavor='seurat_v3', layer='counts') sc.tl.pca(adTrain, mask_var='highly_variable') <p>Train the classifier.</p> In\u00a0[6]: Copied! <pre>n_rand = n_cells\nnTopGenes = 30\nnTopGenePairs = 40\nn_comps = 30\n\nclf = cn.cl.train_classifier(adTrain, groupby, nRand = n_rand, nTopGenes = nTopGenes, nTopGenePairs = nTopGenePairs, n_comps = n_comps)\n</pre> n_rand = n_cells nTopGenes = 30 nTopGenePairs = 40 n_comps = 30  clf = cn.cl.train_classifier(adTrain, groupby, nRand = n_rand, nTopGenes = nTopGenes, nTopGenePairs = nTopGenePairs, n_comps = n_comps) <pre>Training classifier |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [100%] in 34.1s (0.15/s) \n</pre> <p>Apply classifier to held out data</p> In\u00a0[7]: Copied! <pre>obs_pred=\"SCN_class_argmax\"\ncn.cl.classify_anndata(adHO, clf, nrand = 0)\n\ncn.pl.heatmap_scores(adHO, groupby='SCN_class_argmax')\n</pre> obs_pred=\"SCN_class_argmax\" cn.cl.classify_anndata(adHO, clf, nrand = 0)  cn.pl.heatmap_scores(adHO, groupby='SCN_class_argmax') <p>Assess performance</p> In\u00a0[8]: Copied! <pre>c_report = cn.cl.create_classifier_report(adHO, ground_truth=groupby, prediction=obs_pred)\ncn.pl.heatmap_classifier_report(c_report)\nplt.show()\n</pre> c_report = cn.cl.create_classifier_report(adHO, ground_truth=groupby, prediction=obs_pred) cn.pl.heatmap_classifier_report(c_report) plt.show() <p>Classify the embryoid body cells.</p> In\u00a0[9]: Copied! <pre>cn.cl.classify_anndata(adQuery, clf)\ncn.pl.heatmap_scores(adQuery, groupby='SCN_class_argmax')\n</pre> cn.cl.classify_anndata(adQuery, clf) cn.pl.heatmap_scores(adQuery, groupby='SCN_class_argmax') <p>Compute the cell-type specific thresholds</p> In\u00a0[10]: Copied! <pre>tThrs_val_05_HO = cn.cl.comp_ct_thresh(adHO, 0.05)\n</pre> tThrs_val_05_HO = cn.cl.comp_ct_thresh(adHO, 0.05) <p>Distingiushing hybrids from intermediates requires the user to provided cell typ relationship information in the form of a graph. This can come from prior knowledge of ontogeny, or it can be  inferred from transcriptional similarity in the reference data. In the next function call, we infer a relatenedness graph from the reference data.</p> In\u00a0[11]: Copied! <pre>rela_graph = cn.cl.paga_connectivities_to_igraph(adTrain, threshold = 0.3, n_comps = n_comps, group_key = groupby)\n</pre> rela_graph = cn.cl.paga_connectivities_to_igraph(adTrain, threshold = 0.3, n_comps = n_comps, group_key = groupby) <p>Finally, we will categorize the classification results. Note that a manually created graph can be used in place of that returned by <code>cn.cl.paga_connectivities_to_igraph</code></p> In\u00a0[12]: Copied! <pre>cn.cl.categorize_classification(adQuery, tThrs_val_05_HO, rela_graph)\n</pre> cn.cl.categorize_classification(adQuery, tThrs_val_05_HO, rela_graph) In\u00a0[13]: Copied! <pre>cn.pl.stackedbar_categories(adQuery, class_col_name='SCN_class_argmax', show_pct_total=True)\nplt.show()\n</pre> cn.pl.stackedbar_categories(adQuery, class_col_name='SCN_class_argmax', show_pct_total=True) plt.show() <p>The x-axis is the proporition of query cells with a given SCN_class_argmax fall into each category. The numbers indicate the total (and percent of total) of that SCN_class_argmax in the anQuery.</p> In\u00a0[14]: Copied! <pre>adComp = adQuery.copy()\nsc.pp.filter_genes(adComp, min_cells = 10)\nadComp.layers[\"counts\"] = adComp.X.copy()\nsc.pp.normalize_total(adComp)\nsc.pp.log1p(adComp)\n</pre> adComp = adQuery.copy() sc.pp.filter_genes(adComp, min_cells = 10) adComp.layers[\"counts\"] = adComp.X.copy() sc.pp.normalize_total(adComp) sc.pp.log1p(adComp) <p>Now create a new .obs column that combines the argmax label prediction with the categorization. Then, remove groups of size &lt; 100 cells.</p> In\u00a0[15]: Copied! <pre>new_col = \"SCN_combined_max\"\nadComp.obs[new_col] = adComp.obs[\"SCN_class_argmax\"].astype(str) + \"_\" + adComp.obs[\"SCN_class_type\"].astype(str)\nadComp.obs[new_col] = adComp.obs[new_col].astype(str).astype(\"category\")\nadx = cn.ut.filter_adata_by_group_size(adComp, new_col, 100)\ncn.pl.heatmap_scores(adx, groupby=new_col)\n</pre> new_col = \"SCN_combined_max\" adComp.obs[new_col] = adComp.obs[\"SCN_class_argmax\"].astype(str) + \"_\" + adComp.obs[\"SCN_class_type\"].astype(str) adComp.obs[new_col] = adComp.obs[new_col].astype(str).astype(\"category\") adx = cn.ut.filter_adata_by_group_size(adComp, new_col, 100) cn.pl.heatmap_scores(adx, groupby=new_col) <pre>Filtering AnnData object based on group sizes in 'SCN_combined_max':\n - Total groups: 41\n - Groups retained (\u2265 100 cells): 7\n - Groups excluded (&lt; 100 cells): 34\nFiltered AnnData object contains 5048 cells from 7 groups.\n</pre> <p>We can see that Ecto.Neural, Epiblast, and Meso.Axial are the only cell types in which we have at least 100 cells in both the None and Singular categories. Let's compare those directly to each other.</p> In\u00a0[16]: Copied! <pre>cellgrps = [\"Ecto.Neural\", \"Epiblast\", \"Meso.Axial\"]\ncats_to_comp = [\"Singular\", \"None\"]\ndeg_res = cn.cl.deg(adx, sample_obsvals=cats_to_comp, limitto_obsvals=cellgrps, cellgrp_obsname = 'SCN_class_argmax',groupby_obsname='SCN_class_type',ncells_per_sample = 10, test_name='t-test', mask_var=None)\n</pre> cellgrps = [\"Ecto.Neural\", \"Epiblast\", \"Meso.Axial\"] cats_to_comp = [\"Singular\", \"None\"] deg_res = cn.cl.deg(adx, sample_obsvals=cats_to_comp, limitto_obsvals=cellgrps, cellgrp_obsname = 'SCN_class_argmax',groupby_obsname='SCN_class_type',ncells_per_sample = 10, test_name='t-test', mask_var=None) <pre>cell group: Ecto.Neural\ncell group: Epiblast\ncell group: Meso.Axial\n</pre> <p>One plausible difference between the 'None' and 'Singular' is simply that the 'None' have not upregulated lineage specific genes sufficiently. To test this, we will perform GSEA using the lineage-enriched genes that are stored during the training process.</p> In\u00a0[35]: Copied! <pre>genesets = clf['diffExpGenes']\ngsname = \"lineage_specific\"\ngsea_res = cn.cl.gsea_on_deg(deg_res['geneTab_dict'], gsname, genesets = genesets, permutation_num = 1e3)\n</pre> genesets = clf['diffExpGenes'] gsname = \"lineage_specific\" gsea_res = cn.cl.gsea_on_deg(deg_res['geneTab_dict'], gsname, genesets = genesets, permutation_num = 1e3) <pre>2025-02-18 14:43:38,817 [WARNING] Duplicated values found in preranked stats: 1.29% of genes\nThe order of those genes will be arbitrary, which may produce unexpected results.\n2025-02-18 14:43:39,565 [WARNING] Duplicated values found in preranked stats: 3.30% of genes\nThe order of those genes will be arbitrary, which may produce unexpected results.\n</pre> In\u00a0[36]: Copied! <pre>gres_trim = cn.cl.collect_gsea_results_from_dict(gsea_res, .01)\ncn.pl.heatmap_gsea(gres_trim,clean_signatures = True, clean_cells=False, col_cluster=True, row_cluster=True)\n</pre> gres_trim = cn.cl.collect_gsea_results_from_dict(gsea_res, .01) cn.pl.heatmap_gsea(gres_trim,clean_signatures = True, clean_cells=False, col_cluster=True, row_cluster=True) <p>This heatmap shows the normalized enrichment score (NES) of comparing 'Singular' vs 'None' cells that share the same predicted label. Columns are the groups of cells. Rows are the gene signatures tested for enrichment. In this case, we have used the gene signatures of each cell type from the reference embryo data. In the case of cells labeled as 'Epiblast', the heatmap tells us that 'Singular' cells are enriched in the Epiblast, Ecto.Pan, and Ecto.Neural signatures. We can also see that Singular cells predicted to be 'Ecto.Neural' are enriched in Ecto.Neural, Ecto.Neural_crest, and Meso.Somitic signature. On the other hand, 'None' cells with maximum pySCN scores for 'Ecto.Neural' are enriched in Anterior.PS, Endo.DE.VE, Epiblast, and Ecto.Pan signatures (blue).</p> <p>We can also look at the enrichment of any other gene sets, for example, GOBP</p> In\u00a0[19]: Copied! <pre>genesets = cn.ut.read_gmt(\"../../../resources/genesets/msigdb_v2023.2.Mm_GMTs/m5.go.bp.v2023.2.Mm.symbols.gmt\")\ngsname = \"GOBP\"\ngsea_res = cn.cl.gsea_on_deg(deg_res['geneTab_dict'], gsname, genesets = genesets, permutation_num = 1e3)\n</pre> genesets = cn.ut.read_gmt(\"../../../resources/genesets/msigdb_v2023.2.Mm_GMTs/m5.go.bp.v2023.2.Mm.symbols.gmt\") gsname = \"GOBP\" gsea_res = cn.cl.gsea_on_deg(deg_res['geneTab_dict'], gsname, genesets = genesets, permutation_num = 1e3) <pre>2025-02-18 14:26:27,958 [WARNING] Duplicated values found in preranked stats: 1.29% of genes\nThe order of those genes will be arbitrary, which may produce unexpected results.\n2025-02-18 14:27:25,881 [WARNING] Duplicated values found in preranked stats: 3.30% of genes\nThe order of those genes will be arbitrary, which may produce unexpected results.\n</pre> In\u00a0[20]: Copied! <pre>gres_trim = cn.cl.collect_gsea_results_from_dict(gsea_res, .01)\ncn.pl.heatmap_gsea(gres_trim,clean_signatures = True, clean_cells=False, col_cluster=True, row_cluster=True)\n</pre> gres_trim = cn.cl.collect_gsea_results_from_dict(gsea_res, .01) cn.pl.heatmap_gsea(gres_trim,clean_signatures = True, clean_cells=False, col_cluster=True, row_cluster=True) <p>Let's end by embedding the query data based on a combination of the SCN_class_scores and PCs.</p> In\u00a0[34]: Copied! <pre>sc.pp.highly_variable_genes(adComp, n_top_genes=2000, flavor='seurat_v3', layer=\"counts\")\nsc.tl.pca(adComp, mask_var='highly_variable')\n\ndef_npcs = 30\ndef_nneigh = 10\n\nsc.pp.neighbors(adComp, n_neighbors = def_nneigh,  n_pcs = def_npcs)\nsc.pp.neighbors(adComp, n_neighbors = def_nneigh,  use_rep = 'SCN_score', key_added='SCN_score_NN')\n\ncn.ut.generate_joint_graph(adComp, connectivity_keys = [\"connectivities\", \"SCN_score_NN_connectivities\"], weights=[0.25, 0.75], output_key='jointNN')\nsc.tl.umap(adComp,  neighbors_key='jointNN')\nsc.pl.umap(adComp, color=['SCN_combined_max'], size=35, alpha=.75,frameon=False)\n</pre> sc.pp.highly_variable_genes(adComp, n_top_genes=2000, flavor='seurat_v3', layer=\"counts\") sc.tl.pca(adComp, mask_var='highly_variable')  def_npcs = 30 def_nneigh = 10  sc.pp.neighbors(adComp, n_neighbors = def_nneigh,  n_pcs = def_npcs) sc.pp.neighbors(adComp, n_neighbors = def_nneigh,  use_rep = 'SCN_score', key_added='SCN_score_NN')  cn.ut.generate_joint_graph(adComp, connectivity_keys = [\"connectivities\", \"SCN_score_NN_connectivities\"], weights=[0.25, 0.75], output_key='jointNN') sc.tl.umap(adComp,  neighbors_key='jointNN') sc.pl.umap(adComp, color=['SCN_combined_max'], size=35, alpha=.75,frameon=False)"},{"location":"notebooks/categorize.html#data","title":"Data\u00b6","text":""},{"location":"notebooks/categorize.html#training-data","title":"Training data\u00b6","text":"<p>The training data is a subset of the mouse gastrulation atlas described in Pijuan-Sala et al Nature 2019. We have reduced the size of this dataset to make running this tutorial more accessible. We have also re-annotated the cell lineages based on recent spatial transcriptomics studies of mouse gastrulation (see Lohoff et al 2021 and Kumar et al 2023).</p> <p>You can download the training data from here</p> <ul> <li>17,480 cells</li> <li>29,329 genes</li> <li>cell type labels in <code>.obs['ct1']</code></li> </ul>"},{"location":"notebooks/categorize.html#query-data-set","title":"Query data set\u00b6","text":"<p>The query data comes from one of our the lab's first papers Spangler et al 2018.</p> Protocol for making mouse embryoid bodies. Data here is only from day 4. <p>Embryoid body day 4</p> <ul> <li>download h5ad here</li> </ul>"},{"location":"notebooks/categorize.html#start-up","title":"Start up\u00b6","text":"<p>Import requisite packages and load the data.</p>"},{"location":"notebooks/categorize.html#categorization","title":"Categorization\u00b6","text":"<p>By looking at the heatmap above, you can see that there are some cases where even a maximum SCN_score for a cell is relatively low. There are several reasons that this might occur. For example, a cell might receive high scores for more than one cell type because it is in a developmental intermediate state. Other possible classification results are depicted below.</p> How PySCN assigns categories. <p>To apply these category labels, we need to select SCN_score thresholds. Below, we will determine cell-type specific SCN_score thresholds to empirically categorize classification predictions. The thresholds are determined as the 5th percentile of SCN_score of known true positives for each cell type. Then we will assign categorization labels as indicated in the figure above and as listed below:</p> <ul> <li>If SCN_score of exactly one cell type exceeds threshold: \"Singular\"</li> <li>If SCN_score of no cell types (including 'rand') exceed threshold: \"None\"</li> <li>If  SCN_score of more than one cell type exceeds threshold:<ul> <li>If all pairs of high-scoring cell types are within <code>k</code> edges in the provided graph: \"Intermediate\"</li> <li>Otherwise: \"Hybrid\"</li> </ul> </li> <li>If predicted cell type is 'rand': \"Rand\"</li> </ul> <p>This approach ensures that when applied to the reference data, the categorization process should result in 95% of cells receiving a category of 'Singular', 'Intermediate', 'Hybrid' (or 'rand' for rand cells).</p>"},{"location":"notebooks/categorize.html#compare-singular-vs-none","title":"Compare Singular vs None\u00b6","text":"<p>What distinguishes cells that have high classification score from those that have low scores? Pre-process the query data.</p>"},{"location":"notebooks/enrichment.html","title":"GSEA &amp; annData","text":"In\u00a0[1]: Copied! <pre>import scanpy as sc\nfrom joblib import dump, load\nimport numpy as np\nimport pandas as pd\nimport pySingleCellNet as pySCN\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport anndata\n\nimport warnings\nwarnings.filterwarnings('ignore')\nsc.settings.verbosity = 0\n</pre> import scanpy as sc from joblib import dump, load import numpy as np import pandas as pd import pySingleCellNet as pySCN import matplotlib.pyplot as plt import seaborn as sns import anndata  import warnings warnings.filterwarnings('ignore') sc.settings.verbosity = 0 In\u00a0[11]: Copied! <pre>hallmarks = pySCN.read_gmt(\"mh.all.v2023.2.Mm.symbols.gmt\")\n</pre> hallmarks = pySCN.read_gmt(\"mh.all.v2023.2.Mm.symbols.gmt\") In\u00a0[2]: Copied! <pre>adata = sc.read_h5ad(\"mouseGastrulation_n75_032124.h5ad\")\nadata = pySCN.mito_rib(adata, species='MM', clean=True)\nmin_num_cells = 37\nsc.pp.filter_genes(adata, min_cells=min_num_cells)\n</pre> adata = sc.read_h5ad(\"mouseGastrulation_n75_032124.h5ad\") adata = pySCN.mito_rib(adata, species='MM', clean=True) min_num_cells = 37 sc.pp.filter_genes(adata, min_cells=min_num_cells) In\u00a0[3]: Copied! <pre>adNorm = pySCN.norm_hvg_scale_pca(adata)\nsc.pl.pca_variance_ratio(adNorm, 50)\n</pre> adNorm = pySCN.norm_hvg_scale_pca(adata) sc.pl.pca_variance_ratio(adNorm, 50) In\u00a0[4]: Copied! <pre>n_pcs = 30\nn_neighbors = 30\n\nsc.pp.neighbors(adNorm, n_neighbors=n_neighbors, n_pcs=n_pcs)\n\nsc.tl.leiden(adNorm,.1)\nsc.tl.paga(adNorm)\nsc.pl.paga(adNorm, plot=False)\nsc.tl.umap(adNorm, init_pos='paga')\nsc.pl.umap(adNorm,color=['celltype'], alpha=.75, s=15)\n</pre> n_pcs = 30 n_neighbors = 30  sc.pp.neighbors(adNorm, n_neighbors=n_neighbors, n_pcs=n_pcs)  sc.tl.leiden(adNorm,.1) sc.tl.paga(adNorm) sc.pl.paga(adNorm, plot=False) sc.tl.umap(adNorm, init_pos='paga') sc.pl.umap(adNorm,color=['celltype'], alpha=.75, s=15) In\u00a0[5]: Copied! <pre>sc.pl.umap(adNorm,color=['leiden'], alpha=.75, s=15, legend_loc='on data')\n</pre> sc.pl.umap(adNorm,color=['leiden'], alpha=.75, s=15, legend_loc='on data') <p>cell_dict = {'Erythrocyte': ['7'], 'HE, endothelial': ['4'], 'Mesoderm': ['0'], 'Ectoderm, Epiblast, PGC': ['1'], 'APS, Node, Notochord': ['2'], 'Endoderm ': ['3'], 'ExE Ectoderm': ['5'], 'Parietal Endoderm': ['6'] }</p> <p>new_obs_name = 'coarse_cluster' adNorm.obs[new_obs_name] = np.nan</p> <p>for i in cell_dict.keys(): ind = pd.Series(adNorm.obs.leiden).isin(cell_dict[i]) adNorm.obs.loc[ind,new_obs_name] = i</p> <p>adNorm.obs[new_obs_name] = adNorm.obs[new_obs_name].astype(\"category\")</p> In\u00a0[7]: Copied! <pre>sc.pl.umap(adNorm,color=[new_obs_name], alpha=.75, s=15, legend_loc='on data', legend_fontsize=8)\n</pre> sc.pl.umap(adNorm,color=[new_obs_name], alpha=.75, s=15, legend_loc='on data', legend_fontsize=8) In\u00a0[8]: Copied! <pre>sc.tl.rank_genes_groups(adNorm, use_raw=False, groupby=\"coarse_cluster\")\n</pre> sc.tl.rank_genes_groups(adNorm, use_raw=False, groupby=\"coarse_cluster\") In\u00a0[10]: Copied! <pre>sc.tl.filter_rank_genes_groups(adNorm, min_fold_change=.5, min_in_group_fraction=.3, max_out_group_fraction=.1)\n\nfig, ax = plt.subplots(figsize=(5, 5))\nsc.pl.rank_genes_groups_dotplot(adNorm, n_genes=3, groupby=\"coarse_cluster\", dendrogram=True, key='rank_genes_groups_filtered', swap_axes=True, ax=ax)\n</pre> sc.tl.filter_rank_genes_groups(adNorm, min_fold_change=.5, min_in_group_fraction=.3, max_out_group_fraction=.1)  fig, ax = plt.subplots(figsize=(5, 5)) sc.pl.rank_genes_groups_dotplot(adNorm, n_genes=3, groupby=\"coarse_cluster\", dendrogram=True, key='rank_genes_groups_filtered', swap_axes=True, ax=ax) <p>Note to self: re-work the figure above so that cell group labels on x-axis are rotated 45, and remove the gene-group labes on the y-axis. Probably can do so by extracting vars, then passing to sc.pl.DotPot.</p> In\u00a0[12]: Copied! <pre>deg_res = pySCN.convert_diffExp_to_dict(adNorm)\ngsea_res = pySCN.gsea_on_deg(deg_res, \"hallmarks\",genesets = hallmarks, permutation_num = 1e3)\n</pre> deg_res = pySCN.convert_diffExp_to_dict(adNorm) gsea_res = pySCN.gsea_on_deg(deg_res, \"hallmarks\",genesets = hallmarks, permutation_num = 1e3) <pre>2024-03-21 17:44:34,340 [WARNING] Duplicated values found in preranked stats: 0.02% of genes\nThe order of those genes will be arbitrary, which may produce unexpected results.\n2024-03-21 17:44:37,130 [WARNING] Duplicated values found in preranked stats: 0.02% of genes\nThe order of those genes will be arbitrary, which may produce unexpected results.\n</pre> In\u00a0[13]: Copied! <pre>gsea_matrix_coarse = pySCN.collect_gsea_results_from_dict(gsea_res, .05)\npySCN.heatmap_gsea(gsea_matrix_coarse, figsize=(7,12),clean_signatures = True, clean_cells=True)\n</pre> gsea_matrix_coarse = pySCN.collect_gsea_results_from_dict(gsea_res, .05) pySCN.heatmap_gsea(gsea_matrix_coarse, figsize=(7,12),clean_signatures = True, clean_cells=True) In\u00a0[14]: Copied! <pre>sc.tl.rank_genes_groups(adNorm, use_raw=False, groupby=\"celltype\")\nsc.tl.filter_rank_genes_groups(adNorm, min_fold_change=.5, min_in_group_fraction=.5, max_out_group_fraction=.15)\nsc.tl.dendrogram(adNorm, \"celltype\")\nsc.pl.rank_genes_groups_dotplot(adNorm, n_genes=1, groupby=\"celltype\", dendrogram=True, key='rank_genes_groups_filtered', swap_axes=True)\n</pre> sc.tl.rank_genes_groups(adNorm, use_raw=False, groupby=\"celltype\") sc.tl.filter_rank_genes_groups(adNorm, min_fold_change=.5, min_in_group_fraction=.5, max_out_group_fraction=.15) sc.tl.dendrogram(adNorm, \"celltype\") sc.pl.rank_genes_groups_dotplot(adNorm, n_genes=1, groupby=\"celltype\", dendrogram=True, key='rank_genes_groups_filtered', swap_axes=True) In\u00a0[15]: Copied! <pre>deg_res_ct = pySCN.convert_diffExp_to_dict(adNorm)\ngsea_res_ct = pySCN.gsea_on_deg(deg_res_ct, \"hallmarks\",genesets = hallmarks, permutation_num = 1e3)\n</pre> deg_res_ct = pySCN.convert_diffExp_to_dict(adNorm) gsea_res_ct = pySCN.gsea_on_deg(deg_res_ct, \"hallmarks\",genesets = hallmarks, permutation_num = 1e3) <pre>2024-03-21 17:44:51,532 [WARNING] Duplicated values found in preranked stats: 0.01% of genes\nThe order of those genes will be arbitrary, which may produce unexpected results.\n2024-03-21 17:44:52,418 [WARNING] Duplicated values found in preranked stats: 0.01% of genes\nThe order of those genes will be arbitrary, which may produce unexpected results.\n2024-03-21 17:44:53,323 [WARNING] Duplicated values found in preranked stats: 0.01% of genes\nThe order of those genes will be arbitrary, which may produce unexpected results.\n2024-03-21 17:44:54,224 [WARNING] Duplicated values found in preranked stats: 0.02% of genes\nThe order of those genes will be arbitrary, which may produce unexpected results.\n2024-03-21 17:44:56,031 [WARNING] Duplicated values found in preranked stats: 0.01% of genes\nThe order of those genes will be arbitrary, which may produce unexpected results.\n2024-03-21 17:44:57,850 [WARNING] Duplicated values found in preranked stats: 0.01% of genes\nThe order of those genes will be arbitrary, which may produce unexpected results.\n2024-03-21 17:45:00,560 [WARNING] Duplicated values found in preranked stats: 0.01% of genes\nThe order of those genes will be arbitrary, which may produce unexpected results.\n2024-03-21 17:45:01,466 [WARNING] Duplicated values found in preranked stats: 0.01% of genes\nThe order of those genes will be arbitrary, which may produce unexpected results.\n2024-03-21 17:45:03,230 [WARNING] Duplicated values found in preranked stats: 0.02% of genes\nThe order of those genes will be arbitrary, which may produce unexpected results.\n2024-03-21 17:45:04,139 [WARNING] Duplicated values found in preranked stats: 0.02% of genes\nThe order of those genes will be arbitrary, which may produce unexpected results.\n2024-03-21 17:45:05,034 [WARNING] Duplicated values found in preranked stats: 0.01% of genes\nThe order of those genes will be arbitrary, which may produce unexpected results.\n2024-03-21 17:45:05,946 [WARNING] Duplicated values found in preranked stats: 0.01% of genes\nThe order of those genes will be arbitrary, which may produce unexpected results.\n2024-03-21 17:45:06,814 [WARNING] Duplicated values found in preranked stats: 0.01% of genes\nThe order of those genes will be arbitrary, which may produce unexpected results.\n2024-03-21 17:45:07,690 [WARNING] Duplicated values found in preranked stats: 0.01% of genes\nThe order of those genes will be arbitrary, which may produce unexpected results.\n2024-03-21 17:45:08,560 [WARNING] Duplicated values found in preranked stats: 0.04% of genes\nThe order of those genes will be arbitrary, which may produce unexpected results.\n2024-03-21 17:45:09,438 [WARNING] Duplicated values found in preranked stats: 0.01% of genes\nThe order of those genes will be arbitrary, which may produce unexpected results.\n</pre> In\u00a0[16]: Copied! <pre>gsea_matrix_ct = pySCN.collect_gsea_results_from_dict(gsea_res_ct, .05)\npySCN.heatmap_gsea(gsea_matrix_ct, figsize=(10,12),clean_signatures = True, clean_cells=True)\n</pre> gsea_matrix_ct = pySCN.collect_gsea_results_from_dict(gsea_res_ct, .05) pySCN.heatmap_gsea(gsea_matrix_ct, figsize=(10,12),clean_signatures = True, clean_cells=True) In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"notebooks/enrichment.html#gsea-anndata","title":"GSEA &amp; annData\u00b6","text":"<p>Often it is really informative and useful to be able to run gene enrichment analysis on an annData object to see what pathways or signatures are enriched in certain clusters compared to others. There are packages that can be coerced to do this but they are not always straightforward to use. The purpose of this notebook is to show you how to run GSEA on your scRNAseq data and visualize the enichment results. We have made these tasks extremely easy through the use of our helper functions that seamlessly interface to GSEAPY for the analysis, and through the use of our visualization functions.</p>"},{"location":"notebooks/enrichment.html#data","title":"Data\u00b6","text":"<p>The training data is a subset of the mouse gastrulation atlas described in Pijuan-Sala et al Nature 2019. We have reduced the size of this dataset to make running this tutorial more accessible. We have also re-annotated the cell lineages based on recent spatial transcriptomics studies of mouse gastrulation (see Lohoff et al 2021 and Kumar et al 2023).</p> <ul> <li>You can download the h5ad file from here</li> <li>There are 1,875 cells</li> <li>29,452 genes</li> <li>25 cell types or lineages</li> <li>Sampled from embryonic stages E6.5 to E8.5</li> </ul>"},{"location":"notebooks/enrichment.html#gene-signatures","title":"Gene signatures\u00b6","text":"<p>In this notebook, we will onyl use the mouse MSigDB Hallmarks as described here but any appropriate .gmt file can be used. Below are some additional gene signature sets that we have cobbled together from various sources and that are useful in developmental and stem cell systems:</p> <ul> <li>Signaling pathway effector targets that we previously curated from Chip-Atlas</li> <li>Signaling pathways in development</li> <li>GOBP development subset</li> </ul>"},{"location":"notebooks/enrichment.html#steps-to-gsea","title":"Steps to GSEA\u00b6","text":""},{"location":"notebooks/enrichment.html#load-packages","title":"Load packages\u00b6","text":""},{"location":"notebooks/enrichment.html#load-gene-signatures","title":"Load gene signatures\u00b6","text":""},{"location":"notebooks/enrichment.html#load-data","title":"Load data\u00b6","text":"<p>Then subject it to the usual processing pipeline. Low quality cell barcodes have alread been removed.</p>"},{"location":"notebooks/enrichment.html#normhvgpca","title":"Norm/HVG/PCA\u00b6","text":""},{"location":"notebooks/enrichment.html#knnclusterumap","title":"kNN/Cluster/UMAP\u00b6","text":""},{"location":"notebooks/enrichment.html#annotate-these-coarse-clusters","title":"Annotate these 'coarse' clusters\u00b6","text":"<p>The low Leiden resolution resulted in coarse clustering roughly corresponding:</p> <ul> <li>Erythrocyte (7)</li> <li>Endothelial, hemogenic endothelium (4)</li> <li>Mesoderm (0)</li> <li>Ectoderm, Epiblast, Primordial germ cell (1)</li> <li>APS, Node and Notochord (2)</li> <li>Endoderm (3)</li> <li>Extra-embryonic ectoderm (5)</li> <li>Parietal endoderm (6).</li> </ul>"},{"location":"notebooks/enrichment.html#analysis-of-coarse-clusters","title":"Analysis of coarse clusters\u00b6","text":"<p>In the next few steps, we will run differentiation gene expression analysis and then GSEA to identify genes and pathways enriched in these broadly annotated cell groups.</p>"},{"location":"notebooks/enrichment.html#differential-gene-expression-deg-analysis-coarse","title":"Differential gene expression (DEG) analysis - coarse\u00b6","text":""},{"location":"notebooks/enrichment.html#gsea","title":"GSEA\u00b6","text":""},{"location":"notebooks/enrichment.html#heatmap-gsea-results","title":"Heatmap GSEA results\u00b6","text":""},{"location":"notebooks/enrichment.html#analysis-of-cell-types","title":"Analysis of cell types\u00b6","text":"<p>Here, we will run DEG and GSEA based on the more finely resolved cell annotations that were provided with the data.</p>"},{"location":"notebooks/enrichment.html#deg","title":"DEG\u00b6","text":""},{"location":"notebooks/enrichment.html#gsea","title":"GSEA\u00b6","text":""},{"location":"notebooks/enrichment.html#heatmap-gsea-results","title":"Heatmap GSEA results\u00b6","text":""},{"location":"notebooks/explore.html","title":"Explore in vitro development with PySCN","text":"In\u00a0[1]: Copied! <pre>import scanpy as sc\nfrom joblib import dump, load\nimport numpy as np\nimport pandas as pd\nimport pySingleCellNet as pySCN\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport anndata\n</pre> import scanpy as sc from joblib import dump, load import numpy as np import pandas as pd import pySingleCellNet as pySCN import matplotlib.pyplot as plt import seaborn as sns import anndata  <pre>/opt/homebrew/Caskroom/miniforge/base/envs/pyscn_v3/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n</pre> In\u00a0[2]: Copied! <pre>adAtlas = sc.read_h5ad(\"adMouseAtlas_demo_121823.h5ad\")\nadGastruloid = sc.read_h5ad(\"ad_Standard_1_GSM4205743.h5ad\")\nadXEG = sc.read_h5ad(\"ad_XEG_1_GSM4205746.h5ad\")\n</pre> adAtlas = sc.read_h5ad(\"adMouseAtlas_demo_121823.h5ad\") adGastruloid = sc.read_h5ad(\"ad_Standard_1_GSM4205743.h5ad\") adXEG = sc.read_h5ad(\"ad_XEG_1_GSM4205746.h5ad\") In\u00a0[3]: Copied! <pre>pySCN.limit_anndata_to_common_genes([adAtlas, adGastruloid, adXEG])\n</pre> pySCN.limit_anndata_to_common_genes([adAtlas, adGastruloid, adXEG]) In\u00a0[4]: Copied! <pre>adTrain, adHeldOut = pySCN.splitCommonAnnData(adAtlas, ncells=200,dLevel=\"celltype\")\nclf = pySCN.scn_train(adTrain, dLevel = 'celltype', nTopGenes = 25, nTopGenePairs = 25, nRand = 200, nTrees = 1000, stratify=False, propOther=0.50)\n</pre> adTrain, adHeldOut = pySCN.splitCommonAnnData(adAtlas, ncells=200,dLevel=\"celltype\") clf = pySCN.scn_train(adTrain, dLevel = 'celltype', nTopGenes = 25, nTopGenePairs = 25, nRand = 200, nTrees = 1000, stratify=False, propOther=0.50)  <pre>Meso.Mesenchyme : \n420\nMeso.Nascent : \n1157\nMeso.Somite : \n977\nEndo.Gut : \n433\nEcto.N.Crest : \n518\nMeso.HE.Progenitor : \n663\nMeso.Presomitic : \n671\nMeso.Allantois : \n699\nNode_Notochord : \n589\nEndo.Visceral : \n527\nAnterior.PS : \n800\nMeso.LPM : \n566\nNMP : \n1248\nEndo.Parietal : \n263\nEcto.Surface : \n557\nMeso.Angioblast : \n828\nEcto.Nascent.CN : \n1202\nEcto.Neural : \n1063\nEpiblast_Ectoderm : \n932\nMeso.Blood.Progenitor : \n829\nPrimordial.GC : \n445\nEcto.Extra : \n500\nMeso.Cardio : \n548\nMeso.Erythroid : \n1115\nEndo.Extra : \n473\nHVG\nMatrix normalized\nThere are  398  classification genes\n\nAnterior.PS\nEcto.Extra\nEcto.N.Crest\nEcto.Nascent.CN\nEcto.Neural\nEcto.Surface\nEndo.Extra\nEndo.Gut\nEndo.Parietal\nEndo.Visceral\nEpiblast_Ectoderm\nMeso.Allantois\nMeso.Angioblast\nMeso.Blood.Progenitor\nMeso.Cardio\nMeso.Erythroid\nMeso.HE.Progenitor\nMeso.LPM\nMeso.Mesenchyme\nMeso.Nascent\nMeso.Presomitic\nMeso.Somite\nNMP\nNode_Notochord\nPrimordial.GC\nThere are 8137 top gene pairs\n\nFinished pair transforming the data\n\n</pre> <p>Classify heldout data and visualize.</p> In\u00a0[5]: Copied! <pre>pySCN.scn_classify(adHeldOut, clf, nrand = 0)\npySCN.heatmap_scores(adHeldOut, groupby='SCN_class')\n</pre> pySCN.scn_classify(adHeldOut, clf, nrand = 0) pySCN.heatmap_scores(adHeldOut, groupby='SCN_class') <pre>... storing 'SCN_class' as categorical\n</pre> In\u00a0[6]: Copied! <pre>pySCN.barplot_classifier_f1(adHeldOut, ground_truth=\"celltype\", class_prediction=\"SCN_class\")\n</pre> pySCN.barplot_classifier_f1(adHeldOut, ground_truth=\"celltype\", class_prediction=\"SCN_class\") <pre>0.883248730964467\n0.8706199460916442\n0.8872497365648051\n0.9241527703066165\n0.9710540688148553\n0.828786999419617\n0.8932038834951457\n0.901010101010101\n0.9278752436647174\n0.9430676490288011\n0.9274900398406374\n0.9568\n0.9489291598023064\n0.9368836291913214\n0.8989247311827957\n0.9580052493438321\n0.9715099715099715\n0.9756097560975611\n0.9638932496075353\n0.9966777408637874\n0.9908925318761385\n0.8854961832061068\n0.8879492600422833\n0.9103247697527872\n0.9767441860465117\n</pre> In\u00a0[8]: Copied! <pre>pySCN.scn_classify(adGastruloid, clf, nrand = 0)\npySCN.heatmap_scores(adGastruloid, groupby='SCN_class')\n</pre> pySCN.scn_classify(adGastruloid, clf, nrand = 0) pySCN.heatmap_scores(adGastruloid, groupby='SCN_class') <pre>... storing 'SCN_class' as categorical\n</pre> <p>We can embed the query data and see how SCN classification and SCN scores are distributed across clusters</p> In\u00a0[9]: Copied! <pre>pySCN.scn_classify(adXEG, clf, nrand = 0)\npySCN.heatmap_scores(adXEG, groupby='SCN_class')\n</pre> pySCN.scn_classify(adXEG, clf, nrand = 0) pySCN.heatmap_scores(adXEG, groupby='SCN_class') <pre>... storing 'SCN_class' as categorical\n</pre> In\u00a0[11]: Copied! <pre>tThrs_val_05 = pySCN.comp_ct_thresh(adHeldOut, 0.05)\ntThrs_val_05\n</pre> tThrs_val_05 = pySCN.comp_ct_thresh(adHeldOut, 0.05) tThrs_val_05 <pre>Anterior.PS\nEcto.Extra\nEcto.N.Crest\nEcto.Nascent.CN\nEcto.Neural\nEcto.Surface\nEndo.Extra\nEndo.Gut\nEndo.Parietal\nEndo.Visceral\nEpiblast_Ectoderm\nMeso.Allantois\nMeso.Angioblast\nMeso.Blood.Progenitor\nMeso.Cardio\nMeso.Erythroid\nMeso.HE.Progenitor\nMeso.LPM\nMeso.Mesenchyme\nMeso.Nascent\nMeso.Presomitic\nMeso.Somite\nNMP\nNode_Notochord\nPrimordial.GC\n</pre> Out[11]: 0 Anterior.PS 0.41130 Ecto.Extra 0.70425 Ecto.N.Crest 0.43280 Ecto.Nascent.CN 0.33350 Ecto.Neural 0.29300 Ecto.Surface 0.28560 Endo.Extra 0.74425 Endo.Gut 0.31005 Endo.Parietal 0.52250 Endo.Visceral 0.47080 Epiblast_Ectoderm 0.38100 Meso.Allantois 0.26370 Meso.Angioblast 0.39020 Meso.Blood.Progenitor 0.49325 Meso.Cardio 0.42650 Meso.Erythroid 0.56400 Meso.HE.Progenitor 0.32920 Meso.LPM 0.27975 Meso.Mesenchyme 0.28080 Meso.Nascent 0.27305 Meso.Presomitic 0.29130 Meso.Somite 0.26310 NMP 0.34770 Node_Notochord 0.32180 Primordial.GC 0.27090 <p>We can pass them to pySCN.class_by_threshold, which will make new classification calls and add them to anndata.obs['SCN_class_emp']. It is possible that more than one class receives a score that exceeds its respective threshold. In these cases, class_by_threshold sets .obs['SCN_class_emp'] to the combinded class labels. .obs['SCN_class_emp']. `class_by_threshold` also adds .obs['SCN_class_type'], which is one of 'Singlular', 'Hybrid', or 'None' indicating the number of categories passing their respective thresholds.</p> In\u00a0[12]: Copied! <pre>pySCN.class_by_threshold(adHeldOut, tThrs_val_05)\npySCN.class_by_threshold(adGastruloid, tThrs_val_05)\npySCN.class_by_threshold(adXEG, tThrs_val_05)\naplot = pySCN.barplot_class_proportions_list([adHeldOut, adGastruloid, adXEG], titles=['Embryo', 'Gastruloid', 'XEG'], bar_height=0.8)\naplot.show()\n</pre> pySCN.class_by_threshold(adHeldOut, tThrs_val_05) pySCN.class_by_threshold(adGastruloid, tThrs_val_05) pySCN.class_by_threshold(adXEG, tThrs_val_05) aplot = pySCN.barplot_class_proportions_list([adHeldOut, adGastruloid, adXEG], titles=['Embryo', 'Gastruloid', 'XEG'], bar_height=0.8) aplot.show() <p>Let's focus on the cell types that are most abundant in the engineered populations.</p> In\u00a0[13]: Copied! <pre>cellgrps = [\"Epiblast_Ectoderm\", \"Ecto.Nascent.CN\", \"NMP\", \"Meso.Presomitic\", \"Meso.Somite\", \"Meso.LPM\", \"Endo.Visceral\"]\naplot = pySCN.barplot_class_proportions_list([adHeldOut, adGastruloid, adXEG], titles=['Embryo', 'Gastruloid', 'XEG'], scn_classes_to_display=cellgrps, bar_height=0.8)\naplot.show()\n</pre> cellgrps = [\"Epiblast_Ectoderm\", \"Ecto.Nascent.CN\", \"NMP\", \"Meso.Presomitic\", \"Meso.Somite\", \"Meso.LPM\", \"Endo.Visceral\"] aplot = pySCN.barplot_class_proportions_list([adHeldOut, adGastruloid, adXEG], titles=['Embryo', 'Gastruloid', 'XEG'], scn_classes_to_display=cellgrps, bar_height=0.8) aplot.show() In\u00a0[14]: Copied! <pre>signaling_targets = pySCN.read_gmt(\"Signaling_Targets_ChipAtlas_102222.gmt\")\nhallmarks = pySCN.read_gmt(\"mh.all.v2023.2.Mm.symbols.gmt\")\n</pre> signaling_targets = pySCN.read_gmt(\"Signaling_Targets_ChipAtlas_102222.gmt\") hallmarks = pySCN.read_gmt(\"mh.all.v2023.2.Mm.symbols.gmt\") <p>Set commond paramaters across subsequent GSEA analyses</p> In\u00a0[15]: Copied! <pre>p_num = 1e3\nfdr_thresh = 0.1\n</pre> p_num = 1e3 fdr_thresh = 0.1 <p>Define the groups of cells to compare.</p> In\u00a0[16]: Copied! <pre>cellgrps = [\"Epiblast_Ectoderm\", \"Ecto.Nascent.CN\", \"NMP\", \"Meso.Presomitic\", \"Meso.Somite\"]\n</pre> cellgrps = [\"Epiblast_Ectoderm\", \"Ecto.Nascent.CN\", \"NMP\", \"Meso.Presomitic\", \"Meso.Somite\"] <p>Compare standard gastruloids to XEG</p> In\u00a0[17]: Copied! <pre>comp_grps = [\"Gastruloid\",\"XEG\"]\n# combine the raw data from each annData\nadComb = pySCN.combine_adatas_for_deg(adatas = [adGastruloid, adXEG], sample_obsvals = comp_grps, cellgrp_obsnames=['SCN_class', 'SCN_class'])\n# remove any Mt- and ribosomal genes, and compute some basic QC metrics\nadComb = pySCN.mito_rib(adComb, species='MM', clean=True)\n# Basic read depth normalization and log transformation\nsc.pp.normalize_total(adComb, 1e4)\nsc.pp.log1p(adComb)\n# Differential gene expression. This calls the scanpy function tl.rank.genes.groups\ndeg_res = pySCN.deg(adComb, sample_obsvals=comp_grps, limitto_obsvals=cellgrps,ncells_per_sample = 10, test_name='t-test')\n</pre> comp_grps = [\"Gastruloid\",\"XEG\"] # combine the raw data from each annData adComb = pySCN.combine_adatas_for_deg(adatas = [adGastruloid, adXEG], sample_obsvals = comp_grps, cellgrp_obsnames=['SCN_class', 'SCN_class']) # remove any Mt- and ribosomal genes, and compute some basic QC metrics adComb = pySCN.mito_rib(adComb, species='MM', clean=True) # Basic read depth normalization and log transformation sc.pp.normalize_total(adComb, 1e4) sc.pp.log1p(adComb) # Differential gene expression. This calls the scanpy function tl.rank.genes.groups deg_res = pySCN.deg(adComb, sample_obsvals=comp_grps, limitto_obsvals=cellgrps,ncells_per_sample = 10, test_name='t-test') <pre>... storing 'SCN_class' as categorical\n... storing 'SCN_class_emp' as categorical\n... storing 'SCN_class_type' as categorical\n... storing 'comb_sampname' as categorical\n... storing 'comb_cellgrp' as categorical\n... storing 'SCN_class' as categorical\n... storing 'SCN_class_emp' as categorical\n... storing 'SCN_class_type' as categorical\n... storing 'comb_sampname' as categorical\n... storing 'comb_cellgrp' as categorical\n</pre> <pre>cell group: Epiblast_Ectoderm\ncell group: Ecto.Nascent.CN\n</pre> <pre>... storing 'SCN_class' as categorical\n... storing 'SCN_class_emp' as categorical\n... storing 'SCN_class_type' as categorical\n... storing 'comb_sampname' as categorical\n... storing 'comb_cellgrp' as categorical\n... storing 'SCN_class' as categorical\n... storing 'SCN_class_emp' as categorical\n... storing 'SCN_class_type' as categorical\n... storing 'comb_sampname' as categorical\n... storing 'comb_cellgrp' as categorical\n</pre> <pre>cell group: NMP\ncell group: Meso.Presomitic\ncell group: Meso.Somite\n</pre> <p>Now use GSEAPY to perform GSEA</p> In\u00a0[18]: Copied! <pre>gs_name = 'hallmarks'\ngsea_res = pySCN.gsea_on_deg(deg_res['geneTab_dict'], gs_name, genesets = hallmarks, permutation_num = p_num)\n</pre> gs_name = 'hallmarks' gsea_res = pySCN.gsea_on_deg(deg_res['geneTab_dict'], gs_name, genesets = hallmarks, permutation_num = p_num) <pre>2023-12-18 15:33:10,959 [WARNING] Duplicated values found in preranked stats: 49.47% of genes\nThe order of those genes will be arbitrary, which may produce unexpected results.\n2023-12-18 15:33:13,042 [WARNING] Duplicated values found in preranked stats: 38.84% of genes\nThe order of those genes will be arbitrary, which may produce unexpected results.\n2023-12-18 15:33:15,062 [WARNING] Duplicated values found in preranked stats: 41.40% of genes\nThe order of those genes will be arbitrary, which may produce unexpected results.\n2023-12-18 15:33:17,663 [WARNING] Duplicated values found in preranked stats: 60.66% of genes\nThe order of those genes will be arbitrary, which may produce unexpected results.\n</pre> <p>Now gather and visualize the results as a heatmap. Only significant enrichments will be colored. Gene sets that are significantly enriched in Standard will be colored red, those that are enriched in XEG will be colored blue. This coloring is determined by the order of the groups as defined above in <code>comp_grps</code>.</p> In\u00a0[19]: Copied! <pre>x = pySCN.collect_gsea_results_from_dict(gsea_res, fdr_thresh)\nplt.rcParams['figure.constrained_layout.use'] = False\npySCN.heatmap_gsea(x, clean_signatures = True, clean_cells=True)\n</pre> x = pySCN.collect_gsea_results_from_dict(gsea_res, fdr_thresh) plt.rcParams['figure.constrained_layout.use'] = False pySCN.heatmap_gsea(x, clean_signatures = True, clean_cells=True) <p>Now look at Signaling pathway targets</p> In\u00a0[20]: Copied! <pre>gs_name = 'signaling_targets'\ngsea_res = pySCN.gsea_on_deg(deg_res['geneTab_dict'], gs_name, genesets = signaling_targets, permutation_num = p_num)\nx = pySCN.collect_gsea_results_from_dict(gsea_res, fdr_thresh)\nplt.rcParams['figure.constrained_layout.use'] = False\npySCN.heatmap_gsea(x, clean_signatures = True, clean_cells=True)\n</pre> gs_name = 'signaling_targets' gsea_res = pySCN.gsea_on_deg(deg_res['geneTab_dict'], gs_name, genesets = signaling_targets, permutation_num = p_num) x = pySCN.collect_gsea_results_from_dict(gsea_res, fdr_thresh) plt.rcParams['figure.constrained_layout.use'] = False pySCN.heatmap_gsea(x, clean_signatures = True, clean_cells=True) <pre>2023-12-18 15:36:04,899 [WARNING] Duplicated values found in preranked stats: 49.47% of genes\nThe order of those genes will be arbitrary, which may produce unexpected results.\n2023-12-18 15:36:06,255 [WARNING] Duplicated values found in preranked stats: 38.84% of genes\nThe order of those genes will be arbitrary, which may produce unexpected results.\n2023-12-18 15:36:07,602 [WARNING] Duplicated values found in preranked stats: 41.40% of genes\nThe order of those genes will be arbitrary, which may produce unexpected results.\n2023-12-18 15:36:08,945 [WARNING] Duplicated values found in preranked stats: 60.66% of genes\nThe order of those genes will be arbitrary, which may produce unexpected results.\n</pre> <p>Note that the HH enrichment is consistent with higher levels of ventralization in gastruloids that were discussed in B\u00e9renger-Currias et al 2022.</p> <p>There is lots more to explore:</p> <ul> <li>Are the classification results reproducible in the replicates?</li> <li>For any given cell type, what pathways (if any) distinguish the 'Singular' cells across conditions?</li> <li>And what disintguishes the 'Singular' engineered cells from the 'Singluar' embryo cells?</li> <li>What is the nature of the 'None' cells in the embryo?</li> <li>Are the commonalities across the 'None' cells in terms of gene signatures or QC metrics?</li> </ul>"},{"location":"notebooks/explore.html#explore-in-vitro-development-with-pyscn","title":"Explore in vitro development with PySCN\u00b6","text":"<p>This tutorial walks through typical analysis steps for the analysis of engineered cell populations. We will first use PySCN to figure out the extent to which mouse embryonic stem cells prompted to form 'gastruoilds' approximate the transcriptional state of their natural counterparts from the mouse embryo. Then, we will see how a variation on the gastruloid protocol impacts their transcriptional fidelity. Finally, we will end by identifying pathways that distguish 'good' engineered cells from less good ones.</p>"},{"location":"notebooks/explore.html#data","title":"Data\u00b6","text":""},{"location":"notebooks/explore.html#training-data","title":"Training data\u00b6","text":"<p>The training data is a subset of the mouse gastrulation atlas described in Pijuan-Sala et al Nature 2019. We have reduced the size of this dataset to make running this tutorial more accessible. We have also re-annotated the cell lineages based on recent spatial transcriptomics studies of mouse gastrulation (see Lohoff et al 2021 and Kumar et al 2023).</p> <ul> <li>You can download the training data from here</li> <li>There are 18,023 cells</li> <li>27,636 genes</li> <li>25 cell types or lineages</li> <li>Sampled from E7.0 to E8.5</li> </ul>"},{"location":"notebooks/explore.html#query-data","title":"Query data\u00b6","text":"<p>The cells that we will examine are derived via differentiation of mouse embryonic stem cells (mESCs) in the form of gastruloids. There are two conditions here, one is standard gastruloid formation (standard), and the second is gastruloid formation from a mixture of mESCs and extraembryonic endoderm (XEN) cells. This second group is referred to as XEG. The data were generated by the Semrau lab and are described in B\u00e9renger-Currias et al 2022. There are replicates for each condition.</p> <ul> <li>Raw data in H5ad form:<ul> <li>Standard 1</li> <li>Standard 2</li> <li>XEG 1</li> <li>XEG 2</li> </ul> </li> <li>Or, you can fetch the data in its original form from GEO here</li> </ul>"},{"location":"notebooks/explore.html#load-packages","title":"Load packages\u00b6","text":""},{"location":"notebooks/explore.html#load-training-data-and-query-data","title":"Load training data and query data\u00b6","text":""},{"location":"notebooks/explore.html#limit-to-genes-shared-in-both-data-sets","title":"Limit to genes shared in both data sets\u00b6","text":""},{"location":"notebooks/explore.html#split-up-training-data-and-then-train-classifier","title":"Split up training data, and then train classifier\u00b6","text":"<p>First, we will split the reference data into the training set made up of equal numbers of cells per cell type, and a held out data set.</p>"},{"location":"notebooks/explore.html#assess-performance-on-heldout-data","title":"Assess performance on heldout data\u00b6","text":""},{"location":"notebooks/explore.html#now-analyze-the-query-data","title":"Now analyze the query data\u00b6","text":""},{"location":"notebooks/explore.html#empirical-categorization-of-classification-calls","title":"Empirical categorization of classification calls\u00b6","text":"<p>Classification calls are based on the category with the highest SCN score, which is just the proportion of decision trees in the random forest that vote for the class. In some instances, it is useful to apply a more stingent threshold for making a classification call. For example, when one or more categories have scores nearly as high as that of the maximum. We can empirically select cell-type specific thresholds that, when applied to held out data, results a given False Negative Rate (FNR). pySCN.comp_ct_thresh() will compute these values:</p>"},{"location":"notebooks/explore.html#gene-set-enrichment-analysis","title":"Gene set enrichment analysis\u00b6","text":"<p>What pathways distinguish the Gastruloid cells from the XEGs? Run GSEA on these samples after integrating them to answer this question. Note that this analysis uses GSEAPY.</p> <p>Here are some useful genesets:</p> <ul> <li>Signaling pathway effector targets that we previously curated from Chip-Atlas</li> <li>Mouse MSigDB Hallmarks as described here</li> <li>Signaling pathways in development</li> <li>GOBP development subset</li> </ul>"},{"location":"notebooks/how-to_prepare_reference_data.html","title":"Prepare reference data","text":"In\u00a0[1]: Copied! <pre>import pandas as pd\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport scanpy as sc\nimport scipy as sp\nimport numpy as np\nimport anndata\nimport pySingleCellNet as pySCN\nimport igraph as ig\nimport altair as alt\nfrom joblib import dump, load\nimport sys\n\nsc.settings.verbosity = 3 \nsc.logging.print_header()\n</pre> import pandas as pd import matplotlib import matplotlib.pyplot as plt import seaborn as sns import scanpy as sc import scipy as sp import numpy as np import anndata import pySingleCellNet as pySCN import igraph as ig import altair as alt from joblib import dump, load import sys  sc.settings.verbosity = 3  sc.logging.print_header() <pre>scanpy==1.9.3 anndata==0.8.0 umap==0.5.3 numpy==1.23.5 scipy==1.10.1 pandas==2.0.0 scikit-learn==1.2.2 statsmodels==0.13.5 python-igraph==0.9.11 pynndescent==0.5.8\n</pre> <p>Load 10k PBMC data</p> In\u00a0[2]: Copied! <pre>ad10f = sc.read_10x_h5(\"../../dat/pbmc/pbmc_10k_v3_filtered_feature_bc_matrix.h5\")\nad10f.var_names_make_unique()\nad10f\n</pre> ad10f = sc.read_10x_h5(\"../../dat/pbmc/pbmc_10k_v3_filtered_feature_bc_matrix.h5\") ad10f.var_names_make_unique() ad10f <pre>reading ../../dat/pbmc/pbmc_10k_v3_filtered_feature_bc_matrix.h5\n (0:00:00)\n</pre> <pre>/opt/homebrew/Caskroom/miniforge/base/envs/test1/lib/python3.10/site-packages/anndata/_core/anndata.py:1830: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n  utils.warn_names_duplicates(\"var\")\n</pre> Out[2]: <pre>AnnData object with n_obs \u00d7 n_vars = 11769 \u00d7 33538\n    var: 'gene_ids', 'feature_types', 'genome'</pre> In\u00a0[3]: Copied! <pre>adstart = ad10f.copy()\nadstart = pySCN.mito_rib(adstart, species='HS', clean = True)\nadstart\n</pre> adstart = ad10f.copy() adstart = pySCN.mito_rib(adstart, species='HS', clean = True) adstart Out[3]: <pre>AnnData object with n_obs \u00d7 n_vars = 11769 \u00d7 33421\n    obs: 'n_genes_by_counts', 'total_counts', 'total_counts_ribo', 'pct_counts_ribo', 'total_counts_mt', 'pct_counts_mt'\n    var: 'gene_ids', 'feature_types', 'genome', 'mt', 'ribo', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'</pre> In\u00a0[4]: Copied! <pre>fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8,4), gridspec_kw={'wspace':0.25})\nax1_dict = sc.pl.scatter(adstart, x='total_counts', y='pct_counts_mt', ax=ax1, show=False)\nax2_dict = sc.pl.scatter(adstart, x='total_counts', y='n_genes_by_counts',ax=ax2, show=False)\nplt.show()\n</pre> fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8,4), gridspec_kw={'wspace':0.25}) ax1_dict = sc.pl.scatter(adstart, x='total_counts', y='pct_counts_mt', ax=ax1, show=False) ax2_dict = sc.pl.scatter(adstart, x='total_counts', y='n_genes_by_counts',ax=ax2, show=False) plt.show() <p>Let's keep cells that ...</p> <ul> <li>mt% &lt; 20</li> <li>n_genes &gt;= 500</li> <li>n_counts &lt;= 30,000</li> </ul> <p>And exclude genes that are detected in 2 or fewer cells</p> In\u00a0[5]: Copied! <pre>adstart = adstart[adstart.obs['pct_counts_mt']&lt;20,:].copy()\nadstart.n_obs\nsc.pp.filter_cells(adstart, min_genes=500)\nadstart.n_obs\nsc.pp.filter_cells(adstart, max_counts=30000)\nadstart.n_obs\nsc.pp.filter_genes(adstart, min_cells=3)\nadstart.n_vars\n</pre> adstart = adstart[adstart.obs['pct_counts_mt']&lt;20,:].copy() adstart.n_obs sc.pp.filter_cells(adstart, min_genes=500) adstart.n_obs sc.pp.filter_cells(adstart, max_counts=30000) adstart.n_obs sc.pp.filter_genes(adstart, min_cells=3) adstart.n_vars  <pre>filtered out 139 cells that have less than 500 genes expressed\nfiltered out 7 cells that have more than 30000 counts\nfiltered out 13317 genes that are detected in less than 3 cells\n</pre> Out[5]: <pre>20104</pre> In\u00a0[6]: Copied! <pre>adNorm = pySCN.norm_hvg_scale_pca(adstart)\n</pre> adNorm = pySCN.norm_hvg_scale_pca(adstart) <pre>normalizing counts per cell\n    finished (0:00:00)\nextracting highly variable genes\n    finished (0:00:00)\n--&gt; added\n    'highly_variable', boolean vector (adata.var)\n    'means', float vector (adata.var)\n    'dispersions', float vector (adata.var)\n    'dispersions_norm', float vector (adata.var)\ncomputing PCA\n    on highly variable genes\n    with n_comps=100\n    finished (0:00:03)\n</pre> <p>Plot variance ratios</p> In\u00a0[7]: Copied! <pre>plt.rcParams[\"figure.figsize\"] = (8,4)\nsc.pl.pca_variance_ratio(adNorm, 50)\n</pre> plt.rcParams[\"figure.figsize\"] = (8,4) sc.pl.pca_variance_ratio(adNorm, 50) In\u00a0[8]: Copied! <pre>npcs = 11\nsc.pp.neighbors(adNorm, n_neighbors=20, n_pcs=npcs)\nsc.tl.leiden(adNorm,.1)\n\nsc.tl.paga(adNorm)\nsc.pl.paga(adNorm, plot=False)\nsc.tl.umap(adNorm, 0.25, init_pos='paga')\n\nplt.rcdefaults()\n#plt.subplots(layout=\"constrained\")\nsc.pl.umap(adNorm,color=['n_counts', 'n_genes', 'pct_counts_mt', 'pct_counts_ribo'], alpha=.75, s=10)\n</pre> npcs = 11 sc.pp.neighbors(adNorm, n_neighbors=20, n_pcs=npcs) sc.tl.leiden(adNorm,.1)  sc.tl.paga(adNorm) sc.pl.paga(adNorm, plot=False) sc.tl.umap(adNorm, 0.25, init_pos='paga')  plt.rcdefaults() #plt.subplots(layout=\"constrained\") sc.pl.umap(adNorm,color=['n_counts', 'n_genes', 'pct_counts_mt', 'pct_counts_ribo'], alpha=.75, s=10) <pre>computing neighbors\n    using 'X_pca' with n_pcs = 11\n    finished: added to `.uns['neighbors']`\n    `.obsp['distances']`, distances for each pair of neighbors\n    `.obsp['connectivities']`, weighted adjacency matrix (0:00:05)\nrunning Leiden clustering\n    finished: found 9 clusters and added\n    'leiden', the cluster labels (adata.obs, categorical) (0:00:00)\nrunning PAGA\n    finished: added\n    'paga/connectivities', connectivities adjacency (adata.uns)\n    'paga/connectivities_tree', connectivities subtree (adata.uns) (0:00:00)\n--&gt; added 'pos', the PAGA positions (adata.uns['paga'])\ncomputing UMAP\n    finished: added\n    'X_umap', UMAP coordinates (adata.obsm) (0:00:04)\n</pre> In\u00a0[9]: Copied! <pre>marker_genes_dict = {\n    'B cell': ['CD79A', 'MS4A1', \"PAX5\"],\n    'Dendritic': ['FCER1A', \"FLT3\",\"CD1C\"],\n    'CD14 monocyte': ['CD14', \"CD36\"],\n    'FCGR3A monocyte': ['FCGR3A', 'MS4A7'],\n    'NK cell': ['GNLY',\"KLRD1\", \"PRF1\"],\n    'Megakaryocyte': ['PPBP',\"PF4\", \"GNG11\"],\n    'CD4 T cell': ['CD3D', 'IL7R', \"CD3E\"],\n    'CD8 T cell': ['CD8A', \"EOMES\"]\n}\n</pre> marker_genes_dict = {     'B cell': ['CD79A', 'MS4A1', \"PAX5\"],     'Dendritic': ['FCER1A', \"FLT3\",\"CD1C\"],     'CD14 monocyte': ['CD14', \"CD36\"],     'FCGR3A monocyte': ['FCGR3A', 'MS4A7'],     'NK cell': ['GNLY',\"KLRD1\", \"PRF1\"],     'Megakaryocyte': ['PPBP',\"PF4\", \"GNG11\"],     'CD4 T cell': ['CD3D', 'IL7R', \"CD3E\"],     'CD8 T cell': ['CD8A', \"EOMES\"] } In\u00a0[10]: Copied! <pre>fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,4), gridspec_kw={'wspace':0.25})\nax1_dict = sc.pl.umap(adNorm,color=['leiden'], alpha=.75, s=10, legend_loc='on data', ax=ax1, show=False)\nax2_dict = sc.pl.dotplot(adNorm, marker_genes_dict, 'leiden', dendrogram=True,ax=ax2, show=False)\nplt.show()\n</pre>  fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,4), gridspec_kw={'wspace':0.25}) ax1_dict = sc.pl.umap(adNorm,color=['leiden'], alpha=.75, s=10, legend_loc='on data', ax=ax1, show=False) ax2_dict = sc.pl.dotplot(adNorm, marker_genes_dict, 'leiden', dendrogram=True,ax=ax2, show=False) plt.show() <pre>WARNING: dendrogram data not found (using key=dendrogram_leiden). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently.\n    using 'X_pca' with n_pcs = 100\nStoring dendrogram info using `.uns['dendrogram_leiden']`\nWARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different.\ncategories: 0, 1, 2, etc.\nvar_group_labels: B cell, Dendritic, CD14 monocyte, etc.\n</pre> <p>Based on the expression of these marker genes, here is an initial guess at their identities:</p> <ul> <li>6: dendritic, but split more because it looks like there might be some monocytes in there</li> <li>1: CD14+ monocyte</li> <li>4: split more (dual monocyte type) or doublet</li> <li>2: b-cell possible pre/pro</li> <li>7: split further (dual T- B-cell) or doublet</li> <li>8: megakaryocyte</li> <li>0: CD4+ T-cell</li> <li>3: CD8+ T-cell</li> <li>5: NK cell</li> </ul> <p>Since some of the clusters might contain mixtures of cell types, or are doublets, try to fractionate them further.</p> In\u00a0[11]: Copied! <pre>sc.tl.leiden(adNorm,.15, restrict_to=[\"leiden\",[\"4\", \"6\", \"7\"]])\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,4), gridspec_kw={'wspace':0.25})\nax1_dict = sc.pl.umap(adNorm,color=['leiden_R'], alpha=.75, s=10, legend_loc='on data', ax=ax1, show=False)\nax2_dict = sc.pl.dotplot(adNorm, marker_genes_dict, 'leiden_R', dendrogram=True,ax=ax2, show=False)\nplt.show()\n</pre> sc.tl.leiden(adNorm,.15, restrict_to=[\"leiden\",[\"4\", \"6\", \"7\"]])  fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,4), gridspec_kw={'wspace':0.25}) ax1_dict = sc.pl.umap(adNorm,color=['leiden_R'], alpha=.75, s=10, legend_loc='on data', ax=ax1, show=False) ax2_dict = sc.pl.dotplot(adNorm, marker_genes_dict, 'leiden_R', dendrogram=True,ax=ax2, show=False) plt.show() <pre>running Leiden clustering\n    finished: found 13 clusters and added\n    'leiden_R', the cluster labels (adata.obs, categorical) (0:00:00)\nWARNING: dendrogram data not found (using key=dendrogram_leiden_R). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently.\n    using 'X_pca' with n_pcs = 100\nStoring dendrogram info using `.uns['dendrogram_leiden_R']`\nWARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different.\ncategories: 0, 1, 2, etc.\nvar_group_labels: B cell, Dendritic, CD14 monocyte, etc.\n</pre> <p>Based on these results, our final cluster annotation is as follows:</p> <ul> <li>4-6-7,2: dendritic</li> <li>4-6-7,0: FCGR3A+ monocyte</li> <li>4-6-7,5: doublet</li> <li>1: CD14+ monocyte</li> <li>4-6-7,1:doublet</li> <li>2: B cell</li> <li>4-6-7,3: doublet</li> <li>4-6-7,4: doublet</li> <li>4-6-7,6: doublet</li> <li>8: Megakaryocyte</li> <li>0: CD4 T cell</li> <li>3: CD8 T cell</li> <li>5: NK cell</li> </ul> <p>Leaving 8 legitimate clusters. So let's remove the clusters that seem to be doublets.</p> In\u00a0[12]: Copied! <pre>tokeep = [\"4-6-7,2\",\"4-6-7,0\", \"1\", \"2\", \"8\", \"0\", \"3\", \"5\"]\nadClean2 = adstart.copy()\nadClean2 = adClean2[adNorm.obs['leiden_R'].isin(tokeep)].copy()\nadClean2\n</pre> tokeep = [\"4-6-7,2\",\"4-6-7,0\", \"1\", \"2\", \"8\", \"0\", \"3\", \"5\"] adClean2 = adstart.copy() adClean2 = adClean2[adNorm.obs['leiden_R'].isin(tokeep)].copy() adClean2 Out[12]: <pre>AnnData object with n_obs \u00d7 n_vars = 10309 \u00d7 20104\n    obs: 'n_genes_by_counts', 'total_counts', 'total_counts_ribo', 'pct_counts_ribo', 'total_counts_mt', 'pct_counts_mt', 'n_genes', 'n_counts'\n    var: 'gene_ids', 'feature_types', 'genome', 'mt', 'ribo', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'n_cells'</pre> In\u00a0[13]: Copied! <pre>adNorm2 = pySCN.norm_hvg_scale_pca(adClean2)\nadNorm2.obs['cluster'] = adNorm[adNorm2.obs.index].obs['leiden_R'].copy()\nnpcs = 11\nsc.pp.neighbors(adNorm2, n_neighbors=20, n_pcs=npcs)\nsc.tl.leiden(adNorm2,.1)\nsc.tl.paga(adNorm2)\nsc.pl.paga(adNorm2, plot=False)\nsc.tl.umap(adNorm2, 0.25, init_pos='paga')\n</pre> adNorm2 = pySCN.norm_hvg_scale_pca(adClean2) adNorm2.obs['cluster'] = adNorm[adNorm2.obs.index].obs['leiden_R'].copy() npcs = 11 sc.pp.neighbors(adNorm2, n_neighbors=20, n_pcs=npcs) sc.tl.leiden(adNorm2,.1) sc.tl.paga(adNorm2) sc.pl.paga(adNorm2, plot=False) sc.tl.umap(adNorm2, 0.25, init_pos='paga') <pre>normalizing counts per cell\n    finished (0:00:00)\nextracting highly variable genes\n    finished (0:00:00)\n--&gt; added\n    'highly_variable', boolean vector (adata.var)\n    'means', float vector (adata.var)\n    'dispersions', float vector (adata.var)\n    'dispersions_norm', float vector (adata.var)\ncomputing PCA\n    on highly variable genes\n    with n_comps=100\n    finished (0:00:03)\ncomputing neighbors\n    using 'X_pca' with n_pcs = 11\n    finished: added to `.uns['neighbors']`\n    `.obsp['distances']`, distances for each pair of neighbors\n    `.obsp['connectivities']`, weighted adjacency matrix (0:00:00)\nrunning Leiden clustering\n    finished: found 8 clusters and added\n    'leiden', the cluster labels (adata.obs, categorical) (0:00:00)\nrunning PAGA\n    finished: added\n    'paga/connectivities', connectivities adjacency (adata.uns)\n    'paga/connectivities_tree', connectivities subtree (adata.uns) (0:00:00)\n--&gt; added 'pos', the PAGA positions (adata.uns['paga'])\ncomputing UMAP\n    finished: added\n    'X_umap', UMAP coordinates (adata.obsm) (0:00:04)\n</pre> In\u00a0[14]: Copied! <pre>fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8,4), gridspec_kw={'wspace':0.25})\nax1_dict = sc.pl.umap(adNorm2,color=['cluster'], alpha=.75, s=10, legend_loc='on data', ax=ax1, show=False)\nax2_dict = sc.pl.umap(adNorm2,color=['leiden'], alpha=.75, s=10, legend_loc='on data', ax=ax2, show=False)\nplt.show()\n</pre> fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8,4), gridspec_kw={'wspace':0.25}) ax1_dict = sc.pl.umap(adNorm2,color=['cluster'], alpha=.75, s=10, legend_loc='on data', ax=ax1, show=False) ax2_dict = sc.pl.umap(adNorm2,color=['leiden'], alpha=.75, s=10, legend_loc='on data', ax=ax2, show=False) plt.show() In\u00a0[15]: Copied! <pre>fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,4), gridspec_kw={'wspace':0.25})\nax1_dict = sc.pl.umap(adNorm2,color=['leiden'], alpha=.75, s=10, legend_loc='on data', ax=ax1, show=False)\nax2_dict = sc.pl.dotplot(adNorm2, marker_genes_dict, 'leiden', dendrogram=True,ax=ax2, show=False)\nplt.show()\n</pre> fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,4), gridspec_kw={'wspace':0.25}) ax1_dict = sc.pl.umap(adNorm2,color=['leiden'], alpha=.75, s=10, legend_loc='on data', ax=ax1, show=False) ax2_dict = sc.pl.dotplot(adNorm2, marker_genes_dict, 'leiden', dendrogram=True,ax=ax2, show=False) plt.show() <pre>WARNING: dendrogram data not found (using key=dendrogram_leiden). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently.\n    using 'X_pca' with n_pcs = 100\nStoring dendrogram info using `.uns['dendrogram_leiden']`\nWARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different.\ncategories: 0, 1, 2, etc.\nvar_group_labels: B cell, Dendritic, CD14 monocyte, etc.\n</pre> <p>Add the final cell annotations to the annData object:</p> <ul> <li>6: Dendritic</li> <li>1: CD14+ monocyte</li> <li>5: FCGR3A+ monocyte</li> <li>2: B cell</li> <li>7: Megakaryocyte</li> <li>0: CD4 T cell</li> <li>3: CD8 T cell</li> <li>4: NK cell</li> </ul> In\u00a0[16]: Copied! <pre>cell_dict = {'Dendritic': ['6'],\n             'CD14 monocyte': ['1'],\n             'FCGR3A monocyte': ['5'],\n             'B cell': ['2'],\n             'Megakaryocyte': ['7'],\n             'CD4 T cell': ['0'],\n             'CD8 T cell': ['3'],\n             'NK cell': ['4']\n}\n</pre> cell_dict = {'Dendritic': ['6'],              'CD14 monocyte': ['1'],              'FCGR3A monocyte': ['5'],              'B cell': ['2'],              'Megakaryocyte': ['7'],              'CD4 T cell': ['0'],              'CD8 T cell': ['3'],              'NK cell': ['4'] } In\u00a0[17]: Copied! <pre>new_obs_name = 'cell_type'\nadNorm2.obs[new_obs_name] = np.nan\n\nfor i in cell_dict.keys():\n    ind = pd.Series(adNorm2.obs.leiden).isin(cell_dict[i])\n    adNorm2.obs.loc[ind,new_obs_name] = i\n\nadNorm2.obs['cell_type'] = adNorm2.obs['cell_type'].astype(\"category\")\n</pre> new_obs_name = 'cell_type' adNorm2.obs[new_obs_name] = np.nan  for i in cell_dict.keys():     ind = pd.Series(adNorm2.obs.leiden).isin(cell_dict[i])     adNorm2.obs.loc[ind,new_obs_name] = i  adNorm2.obs['cell_type'] = adNorm2.obs['cell_type'].astype(\"category\")  In\u00a0[18]: Copied! <pre>sc.tl.dendrogram(adNorm2, \"cell_type\")\n</pre> sc.tl.dendrogram(adNorm2, \"cell_type\") <pre>    using 'X_pca' with n_pcs = 100\nStoring dendrogram info using `.uns['dendrogram_cell_type']`\n</pre> In\u00a0[19]: Copied! <pre>fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,5), gridspec_kw={'wspace':0.4})\nax1_dict = sc.pl.umap(adNorm2,color=['cell_type'], alpha=.75, s=10, legend_loc='on data', ax=ax1, show=False)\nax2_dict = sc.pl.dotplot(adNorm2, marker_genes_dict, 'cell_type', dendrogram=True,ax=ax2, show=False)\nplt.show()\n</pre> fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,5), gridspec_kw={'wspace':0.4}) ax1_dict = sc.pl.umap(adNorm2,color=['cell_type'], alpha=.75, s=10, legend_loc='on data', ax=ax1, show=False) ax2_dict = sc.pl.dotplot(adNorm2, marker_genes_dict, 'cell_type', dendrogram=True,ax=ax2, show=False) plt.show() In\u00a0[20]: Copied! <pre>adNorm2.obs['cell_type'].value_counts()\n</pre> adNorm2.obs['cell_type'].value_counts() Out[20]: <pre>cell_type\nCD4 T cell         3554\nCD14 monocyte      3128\nB cell             1450\nCD8 T cell         1029\nNK cell             608\nFCGR3A monocyte     327\nDendritic           154\nMegakaryocyte        59\nName: count, dtype: int64</pre> <p>Add cell_type annotation to cleaned raw data and save for use as reference data.</p> In\u00a0[21]: Copied! <pre>adTrainPBMC = adClean2.copy()\nadTrainPBMC.obs['cell_type'] = adNorm2.obs['cell_type'].copy()\nadTrainPBMC.write_h5ad(\"adPBMC_ref_040623.h5ad\")\n</pre> adTrainPBMC = adClean2.copy() adTrainPBMC.obs['cell_type'] = adNorm2.obs['cell_type'].copy() adTrainPBMC.write_h5ad(\"adPBMC_ref_040623.h5ad\")"},{"location":"notebooks/how-to_prepare_reference_data.html#prepare-reference-data","title":"Prepare reference data\u00b6","text":""},{"location":"notebooks/how-to_prepare_reference_data.html#summary","title":"Summary\u00b6","text":"<p>Below is a brief tutorial that shows you how we prepared a scRNA-seq data set so that it is ready to be used to train a PySCN classifier. In general, any scRNA-seq data can be used as training data, as long as it is carefully annotated and the raw expression counts are maintained. See Reference data to browse other reference data sets that we have compiled. In this tutorial, we assume that you have already installed PySCN. We use the terms \"reference\" and \"training\" interchangebly.</p>"},{"location":"notebooks/how-to_prepare_reference_data.html#training-data","title":"Training data\u00b6","text":"<p>We use the \"10k PBMCs from a Healthy Donor (v3 chemistry) Single Cell Gene Expression Dataset by Cell Ranger 3.0.0\" data set from 10X Genomics.</p> <ul> <li>You can learn more about 10k PBMC data from the 10X page</li> <li>Healthy human donor Peripheral blood mononuclear cells (PBMC).</li> <li>11,769 cells</li> <li>54,000 reads per cell</li> <li>filtered data set in h5 format</li> </ul>"},{"location":"notebooks/how-to_prepare_reference_data.html#load-packages-and-raw-data","title":"Load packages and raw data\u00b6","text":""},{"location":"notebooks/how-to_prepare_reference_data.html#quality-control","title":"Quality control\u00b6","text":"<p>Start the QC process. <code>pySCN.mito_rib</code> computes the proportion of counts derived from mitochondrially-encoded genes and ribosomal genes. By default, it will also remove these genes from the annData object.</p>"},{"location":"notebooks/how-to_prepare_reference_data.html#normalize-and-reduce-dimentionality","title":"Normalize and reduce dimentionality\u00b6","text":"<p>Normalize expression, detect highly variable genes (HVG), and run PCA.</p> <p>:::{note} <code>pySCN.norm_hvg_scale_pca</code> does not scale expression values by default. Set gene_scale = True if you want to scale gene expression. :::</p>"},{"location":"notebooks/how-to_prepare_reference_data.html#embed-data-and-cluster","title":"Embed data and cluster\u00b6","text":"<p>Embed with UMAP based on first 11 PCs, and see how QC metrics track with clusters.</p>"},{"location":"notebooks/how-to_prepare_reference_data.html#cluster-annotation","title":"Cluster annotation\u00b6","text":"<p>Manually annotate the cells based on established markers of various PBMC cell types.</p>"},{"location":"notebooks/old_quickstart.html","title":"Old quickstart","text":"<p>In this brief tutorial, we show you how to train a pySCN classifier, assess its performance, and use it to annotate independent data.</p> <p>Import requisite packages</p> In\u00a0[1]: Copied! <pre>import warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\nimport os, sys\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport scanpy as sc\nimport pySingleCellNet as cn\n</pre> import warnings warnings.filterwarnings(\"ignore\", category=FutureWarning) import os, sys import numpy as np import pandas as pd import matplotlib.pyplot as plt import scanpy as sc import pySingleCellNet as cn <pre>/opt/homebrew/Caskroom/miniforge/base/envs/scnpy/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n</pre> <p>Load the data</p> In\u00a0[2]: Copied! <pre>adRef = sc.read_h5ad(\"data/adPBMC_ref_040623.h5ad\")\nadQuery = sc.read_h5ad(\"data/adPBMC_query_1_20k_HT_040723.h5ad\")\nadQ2 = sc.datasets.pbmc3k()\n</pre> adRef = sc.read_h5ad(\"data/adPBMC_ref_040623.h5ad\") adQuery = sc.read_h5ad(\"data/adPBMC_query_1_20k_HT_040723.h5ad\") adQ2 = sc.datasets.pbmc3k() <p>Limit to common genes</p> In\u00a0[3]: Copied! <pre>cn.ut.limit_anndata_to_common_genes([adRef, adQuery, adQ2])\n</pre> cn.ut.limit_anndata_to_common_genes([adRef, adQuery, adQ2]) In\u00a0[4]: Copied! <pre>adRef.obs['cell_type'].value_counts()\n</pre> adRef.obs['cell_type'].value_counts() Out[4]: <pre>cell_type\nCD4 T cell         3554\nCD14 monocyte      3128\nB cell             1450\nCD8 T cell         1029\nNK cell             608\nFCGR3A monocyte     327\nDendritic           154\nMegakaryocyte        59\nName: count, dtype: int64</pre> <p>Set aside some cells for training and some held out cells for assessment. Note that we will not be able to properly assess megakaryocytes</p> In\u00a0[5]: Copied! <pre>n_cells = 100\ngroupby = 'cell_type'\ntids, vids = cn.ut.split_adata_indices(adRef, n_cells, groupby=groupby, cellid=None)\nadTrain = adRef[tids].copy()\nadHO = adRef[vids].copy()\n</pre> n_cells = 100 groupby = 'cell_type' tids, vids = cn.ut.split_adata_indices(adRef, n_cells, groupby=groupby, cellid=None) adTrain = adRef[tids].copy() adHO = adRef[vids].copy() <p>Do some pre-processing in preparation for classifier training</p> In\u00a0[6]: Copied! <pre>adTrain.layers['counts'] = adTrain.X.copy()\nsc.pp.normalize_total(adTrain)\nsc.pp.log1p(adTrain)\nsc.pp.highly_variable_genes(adTrain, n_top_genes=2000, flavor='seurat_v3', layer='counts')\n</pre> adTrain.layers['counts'] = adTrain.X.copy() sc.pp.normalize_total(adTrain) sc.pp.log1p(adTrain) sc.pp.highly_variable_genes(adTrain, n_top_genes=2000, flavor='seurat_v3', layer='counts') <p>Train the classifier</p> In\u00a0[7]: Copied! <pre>n_rand = n_cells\nnTopGenes = 30\nnTopGenePairs = 40\nn_comps = 30\n\nclf = cn.cl.train_classifier(adTrain, groupby, nRand = n_rand, nTopGenes = nTopGenes, nTopGenePairs = nTopGenePairs, n_comps = n_comps)\n</pre> n_rand = n_cells nTopGenes = 30 nTopGenePairs = 40 n_comps = 30  clf = cn.cl.train_classifier(adTrain, groupby, nRand = n_rand, nTopGenes = nTopGenes, nTopGenePairs = nTopGenePairs, n_comps = n_comps) <pre>Training classifier |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [100%] in 1.6s (3.18/s) \n</pre> <p>Classify the held out cells</p> In\u00a0[8]: Copied! <pre>cn.cl.classify_anndata(adHO, clf, nrand = 0)\ncn.pl.heatmap_scores(adHO, groupby='SCN_class_argmax')\n</pre> cn.cl.classify_anndata(adHO, clf, nrand = 0) cn.pl.heatmap_scores(adHO, groupby='SCN_class_argmax') <p>Assess performance</p> In\u00a0[9]: Copied! <pre>obs_pred=\"SCN_class_argmax\"\nc_report = cn.cl.create_classifier_report(adHO, ground_truth=groupby, prediction=obs_pred)\ncn.pl.heatmap_classifier_report(c_report)\nplt.show()\n</pre> obs_pred=\"SCN_class_argmax\" c_report = cn.cl.create_classifier_report(adHO, ground_truth=groupby, prediction=obs_pred) cn.pl.heatmap_classifier_report(c_report) plt.show() <p>Classify query data sets</p> In\u00a0[10]: Copied! <pre>for adx in [adQuery, adQ2]:\n    cn.cl.classify_anndata(adx, clf)\n\ncn.pl.heatmap_scores(adQuery, groupby='SCN_class_argmax')\n</pre> for adx in [adQuery, adQ2]:     cn.cl.classify_anndata(adx, clf)  cn.pl.heatmap_scores(adQuery, groupby='SCN_class_argmax') In\u00a0[11]: Copied! <pre>cn.pl.heatmap_scores(adQ2, groupby='SCN_class_argmax')\n</pre> cn.pl.heatmap_scores(adQ2, groupby='SCN_class_argmax') <p>Plot the proportion of cell types across samples</p> In\u00a0[12]: Copied! <pre>adlist = [adHO, adQuery, adQ2]\nadlabels = [\"HO\", \"Query\", \"Q2\"]\nafig = cn.pl.stackedbar_composition_list(adlist, labels=adlabels, color_dict=clf['ctColors'], obs_column = 'SCN_class_argmax', bar_width=.5)\nplt.show()\n</pre> adlist = [adHO, adQuery, adQ2] adlabels = [\"HO\", \"Query\", \"Q2\"] afig = cn.pl.stackedbar_composition_list(adlist, labels=adlabels, color_dict=clf['ctColors'], obs_column = 'SCN_class_argmax', bar_width=.5) plt.show() <p>UMAP embedding of query data + classification</p> In\u00a0[13]: Copied! <pre>def_npcs = 15\ndef_nneigh = 10\n\nfor adx in [adQuery, adQ2]:\n    adx.layers['counts'] = adx.X.copy()\n    sc.pp.normalize_total(adx)\n    sc.pp.log1p(adx)\n    sc.pp.highly_variable_genes(adx, n_top_genes=2000, flavor='seurat_v3', layer='counts')\n    sc.tl.pca(adx, mask_var='highly_variable')\n    sc.pp.neighbors(adx, n_neighbors = def_nneigh,  n_pcs = def_npcs)\n    sc.tl.umap(adx)\n\n\nfig, axs = plt.subplots(1, 2, figsize=(9, 3), constrained_layout=True)\nsc.pl.umap(adQuery, color=['SCN_class_argmax'], alpha=.8, legend_loc=None, show=False, ax=axs[0], title=\"Query 1\")\nsc.pl.umap(adQ2, color=['SCN_class_argmax'], alpha=.8, ax=axs[1], title=\"Query 2\")\n</pre> def_npcs = 15 def_nneigh = 10  for adx in [adQuery, adQ2]:     adx.layers['counts'] = adx.X.copy()     sc.pp.normalize_total(adx)     sc.pp.log1p(adx)     sc.pp.highly_variable_genes(adx, n_top_genes=2000, flavor='seurat_v3', layer='counts')     sc.tl.pca(adx, mask_var='highly_variable')     sc.pp.neighbors(adx, n_neighbors = def_nneigh,  n_pcs = def_npcs)     sc.tl.umap(adx)   fig, axs = plt.subplots(1, 2, figsize=(9, 3), constrained_layout=True) sc.pl.umap(adQuery, color=['SCN_class_argmax'], alpha=.8, legend_loc=None, show=False, ax=axs[0], title=\"Query 1\") sc.pl.umap(adQ2, color=['SCN_class_argmax'], alpha=.8, ax=axs[1], title=\"Query 2\") <p>We can also calculate an embedding based on a combination of the SCN scores and top PCs as follows.</p> In\u00a0[14]: Copied! <pre>for adx in [adQuery, adQ2]:\n    sc.pp.neighbors(adx, n_neighbors = def_nneigh,  use_rep = 'SCN_score', key_added='SCN_score_NN')\n    cn.ut.generate_joint_graph(adx, connectivity_keys = [\"connectivities\", \"SCN_score_NN_connectivities\"], weights=[0.5, 0.5], output_key='jointNN')\n    sc.tl.umap(adx, neighbors_key='jointNN')\n\nfig, axs = plt.subplots(1, 2, figsize=(9, 3), constrained_layout=True)\nsc.pl.umap(adQuery, color=['SCN_class_argmax'], alpha=.8, legend_loc=None, show=False, ax=axs[0], title=\"Query 1\")\nsc.pl.umap(adQ2, color=['SCN_class_argmax'], alpha=.8, ax=axs[1], title=\"Query 2\")\n</pre> for adx in [adQuery, adQ2]:     sc.pp.neighbors(adx, n_neighbors = def_nneigh,  use_rep = 'SCN_score', key_added='SCN_score_NN')     cn.ut.generate_joint_graph(adx, connectivity_keys = [\"connectivities\", \"SCN_score_NN_connectivities\"], weights=[0.5, 0.5], output_key='jointNN')     sc.tl.umap(adx, neighbors_key='jointNN')  fig, axs = plt.subplots(1, 2, figsize=(9, 3), constrained_layout=True) sc.pl.umap(adQuery, color=['SCN_class_argmax'], alpha=.8, legend_loc=None, show=False, ax=axs[0], title=\"Query 1\") sc.pl.umap(adQ2, color=['SCN_class_argmax'], alpha=.8, ax=axs[1], title=\"Query 2\")"},{"location":"notebooks/old_quickstart.html#data","title":"Data\u00b6","text":""},{"location":"notebooks/old_quickstart.html#training-data","title":"Training data\u00b6","text":"<p>We will use \u201c10k PBMCs from a Healthy Donor (v3 chemistry) Single Cell Gene Expression Dataset by Cell Ranger 3.0.0\u201d data set from 10X Genomics. link to processed training data</p>"},{"location":"notebooks/old_quickstart.html#query-data-sets","title":"Query data sets\u00b6","text":"<ol> <li>20k Human PBMCs, 3\u2019 HT v3.1, Chromium X</li> </ol> <ul> <li>download h5ad here</li> </ul> <ol> <li>[3k human PBMCs from 10x as provided via Scanpy]</li> </ol> <ul> <li>Data will be loaded via Scanpy's <code>datasets.pbmc3k()</code> function</li> </ul>"},{"location":"notebooks/quickstart.html","title":"Quickstart","text":"<p>In this brief tutorial, we show you how to train a pySCN classifier, assess its performance, and use it to annotate independent data. It assumes that we already have a reference data set that has been annotated.</p> In\u00a0[1]: Copied! <pre>import warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\nimport os, sys\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport scanpy as sc\nimport pySingleCellNet as cn\n</pre> import warnings warnings.filterwarnings(\"ignore\", category=FutureWarning) import os, sys import numpy as np import pandas as pd import matplotlib.pyplot as plt import scanpy as sc import pySingleCellNet as cn <p>Load the data</p> In\u00a0[2]: Copied! <pre>adRef = sc.read_h5ad(\"data/adPBMC_ref_040623.h5ad\")\nadQuery = sc.read_h5ad(\"data/adPBMC_query_1_20k_HT_040723.h5ad\")\nadQ2 = sc.datasets.pbmc3k()\n</pre> adRef = sc.read_h5ad(\"data/adPBMC_ref_040623.h5ad\") adQuery = sc.read_h5ad(\"data/adPBMC_query_1_20k_HT_040723.h5ad\") adQ2 = sc.datasets.pbmc3k() In\u00a0[3]: Copied! <pre>cn.ut.limit_anndata_to_common_genes([adRef, adQuery, adQ2])\n</pre> cn.ut.limit_anndata_to_common_genes([adRef, adQuery, adQ2]) In\u00a0[4]: Copied! <pre>adRef.obs['cell_type'].value_counts()\n</pre> adRef.obs['cell_type'].value_counts() Out[4]: <pre>cell_type\nCD4 T cell         3554\nCD14 monocyte      3128\nB cell             1450\nCD8 T cell         1029\nNK cell             608\nFCGR3A monocyte     327\nDendritic           154\nMegakaryocyte        59\nName: count, dtype: int64</pre> <p>We will use 100 cells per type for training even though this means that we will not be able to properly assess the megakaryocyte class. n_cells is the target number of cells per cell type for the training data set. groupby indicates the obs column that defines cell types.</p> In\u00a0[5]: Copied! <pre>n_cells = 100\ngroupby = 'cell_type'\ntids, vids = cn.ut.split_adata_indices(adRef, n_cells, groupby=groupby)\nadTrain = adRef[tids].copy()\nadHO = adRef[vids].copy()\n</pre> n_cells = 100 groupby = 'cell_type' tids, vids = cn.ut.split_adata_indices(adRef, n_cells, groupby=groupby) adTrain = adRef[tids].copy() adHO = adRef[vids].copy() In\u00a0[6]: Copied! <pre>adTrain.layers['counts'] = adTrain.X.copy()\nsc.pp.normalize_total(adTrain)\nsc.pp.log1p(adTrain)\nsc.pp.highly_variable_genes(adTrain, n_top_genes=2000, flavor='seurat_v3', layer='counts')\n</pre> adTrain.layers['counts'] = adTrain.X.copy() sc.pp.normalize_total(adTrain) sc.pp.log1p(adTrain) sc.pp.highly_variable_genes(adTrain, n_top_genes=2000, flavor='seurat_v3', layer='counts') In\u00a0[7]: Copied! <pre>n_rand = n_cells\nnTopGenes = 30\nnTopGenePairs = 40\nn_comps = 30\n\nclf = cn.cl.train_classifier(adTrain, groupby, nRand = n_rand, nTopGenes = nTopGenes, nTopGenePairs = nTopGenePairs, n_comps = n_comps)\n</pre> n_rand = n_cells nTopGenes = 30 nTopGenePairs = 40 n_comps = 30  clf = cn.cl.train_classifier(adTrain, groupby, nRand = n_rand, nTopGenes = nTopGenes, nTopGenePairs = nTopGenePairs, n_comps = n_comps) <pre>Training classifier |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5/5 [100%] in 1.7s (3.01/s) \n</pre> In\u00a0[8]: Copied! <pre>cn.cl.classify_anndata(adHO, clf)\ncn.pl.heatmap_scores(adHO, groupby='SCN_class_argmax')\n</pre> cn.cl.classify_anndata(adHO, clf) cn.pl.heatmap_scores(adHO, groupby='SCN_class_argmax') In\u00a0[9]: Copied! <pre>c_report = cn.cl.create_classifier_report(adHO, ground_truth=\"cell_type\", prediction=\"SCN_class_argmax\")\ncn.pl.heatmap_classifier_report(c_report)\nplt.show()\n</pre> c_report = cn.cl.create_classifier_report(adHO, ground_truth=\"cell_type\", prediction=\"SCN_class_argmax\") cn.pl.heatmap_classifier_report(c_report) plt.show() In\u00a0[10]: Copied! <pre>obs_pred = \"SCN_class_argmax\"\nfor adx in [adQuery, adQ2]:\n    cn.cl.classify_anndata(adx, clf)\n\ncn.pl.heatmap_scores(adQuery, groupby=obs_pred)\n</pre> obs_pred = \"SCN_class_argmax\" for adx in [adQuery, adQ2]:     cn.cl.classify_anndata(adx, clf)  cn.pl.heatmap_scores(adQuery, groupby=obs_pred) In\u00a0[11]: Copied! <pre>cn.pl.heatmap_scores(adQ2, groupby=obs_pred)\n</pre> cn.pl.heatmap_scores(adQ2, groupby=obs_pred) In\u00a0[12]: Copied! <pre>adlist = [adHO, adQuery, adQ2]\nadlabels = [\"HO\", \"Query\", \"Q2\"]\nafig = cn.pl.stackedbar_composition_list(adlist, labels=adlabels, color_dict=clf['ctColors'], obs_column = obs_pred, bar_width=.5)\nplt.show()\n</pre> adlist = [adHO, adQuery, adQ2] adlabels = [\"HO\", \"Query\", \"Q2\"] afig = cn.pl.stackedbar_composition_list(adlist, labels=adlabels, color_dict=clf['ctColors'], obs_column = obs_pred, bar_width=.5) plt.show() <p>UMAP embedding of query data + classification</p> In\u00a0[13]: Copied! <pre>def_npcs = 15\ndef_nneigh = 10\n\nfor adx in [adQuery, adQ2]:\n    adx.layers['counts'] = adx.X.copy()\n    sc.pp.normalize_total(adx)\n    sc.pp.log1p(adx)\n    sc.pp.highly_variable_genes(adx, n_top_genes=2000, flavor='seurat_v3', layer='counts')\n    sc.tl.pca(adx, mask_var='highly_variable')\n    sc.pp.neighbors(adx, n_neighbors = def_nneigh,  n_pcs = def_npcs)\n    sc.tl.umap(adx)\n</pre> def_npcs = 15 def_nneigh = 10  for adx in [adQuery, adQ2]:     adx.layers['counts'] = adx.X.copy()     sc.pp.normalize_total(adx)     sc.pp.log1p(adx)     sc.pp.highly_variable_genes(adx, n_top_genes=2000, flavor='seurat_v3', layer='counts')     sc.tl.pca(adx, mask_var='highly_variable')     sc.pp.neighbors(adx, n_neighbors = def_nneigh,  n_pcs = def_npcs)     sc.tl.umap(adx)  In\u00a0[14]: Copied! <pre>fig, axs = plt.subplots(1, 2, figsize=(9, 3), constrained_layout=True)\nsc.pl.umap(adQuery, color=[obs_pred], palette = clf['ctColors'], alpha=.8, legend_loc=None, show=False, ax=axs[0], title=\"Query 1\")\nsc.pl.umap(adQ2, color=[obs_pred],palette = clf['ctColors'], alpha=.8, ax=axs[1], title=\"Query 2\")\n</pre>  fig, axs = plt.subplots(1, 2, figsize=(9, 3), constrained_layout=True) sc.pl.umap(adQuery, color=[obs_pred], palette = clf['ctColors'], alpha=.8, legend_loc=None, show=False, ax=axs[0], title=\"Query 1\") sc.pl.umap(adQ2, color=[obs_pred],palette = clf['ctColors'], alpha=.8, ax=axs[1], title=\"Query 2\") <p>We can also calculate an embedding based on a combination of the SCN scores and top PCs. To do so, we compute kNN using the SCN_score as the basis of determinging cell-cell distances, then we take a weighted average of the original kNN adjacency matrix (based on the top PCs) and the SCN_score kNN adjacency matrix. The results are stored <code>adata.obsp[\"jointNN_connectivities\"]</code> and <code>adata.obsp[\"jointNN_distances\"]</code> and can be used for UMAP (and clustering).</p> In\u00a0[15]: Copied! <pre>for adx in [adQuery, adQ2]:\n    sc.pp.neighbors(adx, n_neighbors = def_nneigh,  use_rep = 'SCN_score', key_added='SCN_score_NN')\n    cn.ut.generate_joint_graph(adx, connectivity_keys = [\"connectivities\", \"SCN_score_NN_connectivities\"], weights=[0.5, 0.5], output_key='jointNN')\n    sc.tl.umap(adx, neighbors_key='jointNN')\n\nfig, axs = plt.subplots(1, 2, figsize=(9, 3), constrained_layout=True)\nsc.pl.umap(adQuery, color=['SCN_class_argmax'], palette = clf['ctColors'],alpha=.8, legend_loc=None, show=False, ax=axs[0], title=\"Query 1\")\nsc.pl.umap(adQ2, color=['SCN_class_argmax'], palette = clf['ctColors'],alpha=.8, ax=axs[1], title=\"Query 2\")\n</pre> for adx in [adQuery, adQ2]:     sc.pp.neighbors(adx, n_neighbors = def_nneigh,  use_rep = 'SCN_score', key_added='SCN_score_NN')     cn.ut.generate_joint_graph(adx, connectivity_keys = [\"connectivities\", \"SCN_score_NN_connectivities\"], weights=[0.5, 0.5], output_key='jointNN')     sc.tl.umap(adx, neighbors_key='jointNN')  fig, axs = plt.subplots(1, 2, figsize=(9, 3), constrained_layout=True) sc.pl.umap(adQuery, color=['SCN_class_argmax'], palette = clf['ctColors'],alpha=.8, legend_loc=None, show=False, ax=axs[0], title=\"Query 1\") sc.pl.umap(adQ2, color=['SCN_class_argmax'], palette = clf['ctColors'],alpha=.8, ax=axs[1], title=\"Query 2\") <p>We can also show the SCN_scores in the UMAP embedding.</p> In\u00a0[16]: Copied! <pre>cn.pl.umap_scores(adQuery, [\"B cell\", \"CD4 T cell\", \"CD8 T cell\"])\n</pre> cn.pl.umap_scores(adQuery, [\"B cell\", \"CD4 T cell\", \"CD8 T cell\"]) In\u00a0[17]: Copied! <pre>cn.pl.umap_scores(adQ2, [\"B cell\", \"CD4 T cell\", \"CD8 T cell\"], s=30)\n</pre> cn.pl.umap_scores(adQ2, [\"B cell\", \"CD4 T cell\", \"CD8 T cell\"], s=30)"},{"location":"notebooks/quickstart.html#data","title":"Data\u00b6","text":""},{"location":"notebooks/quickstart.html#training-data","title":"Training data\u00b6","text":"<ul> <li>10k PBMCs from a Healthy Donor (v3 chemistry) Single Cell Gene Expression Dataset by Cell Ranger 3.0.0</li> <li>From 10X Genomics click here to download the processed data in h5ad</li> <li>We have already annotated this data. The cell type labels are in <code>.obs['cell_type']</code>.</li> </ul>"},{"location":"notebooks/quickstart.html#query-data-sets","title":"Query data sets\u00b6","text":"<ol> <li>20k Human PBMCs, 3\u2019 HT v3.1, Chromium X</li> </ol> <ul> <li>download h5ad here</li> </ul> <ol> <li>3k human PBMCs from 10X Genomics as provided via Scanpy</li> </ol> <ul> <li>Data will be loaded via Scanpy's <code>datasets.pbmc3k()</code> function</li> </ul>"},{"location":"notebooks/quickstart.html#setting-up","title":"Setting up\u00b6","text":"<p>Import requisite packages</p>"},{"location":"notebooks/quickstart.html#pre-training-steps","title":"Pre-training steps\u00b6","text":"<p>There are three things that need to be done before we can train the classifier:</p> <ol> <li>We should limit our data to genes in common between the reference data and query data sets.</li> <li>Subset the training data so that there are approximately the same number of cells per type. Use the remaining cells for assessment.</li> <li>Normalize the training data and find highly variable genes</li> </ol>"},{"location":"notebooks/quickstart.html#1-limit-to-common-genes","title":"1. Limit to common genes\u00b6","text":""},{"location":"notebooks/quickstart.html#2-split-the-reference-data","title":"2. Split the reference data\u00b6","text":"<p>Set aside some cells for training and some held out cells for assessment. IDeally there will be the same number of cells per type so let's see how many cells per type we have to work with:</p>"},{"location":"notebooks/quickstart.html#3-pre-process-training-data","title":"3. Pre-process training data\u00b6","text":""},{"location":"notebooks/quickstart.html#classifier-training","title":"Classifier training\u00b6","text":""},{"location":"notebooks/quickstart.html#training-parameters","title":"training parameters\u00b6","text":"<p>PySCN is fast in part because it limits the set of genes considered for the top-scoring pair transformation and subsequent training to a sub-set of all possible genes. It pre-selects genes that are enriched in each category and some genes that are expressed consistently across all categories. Also, PySCN identifies cell types that are similar to each other in the top n_comps principle components and uses this information to include genes that distinguish these cell types from each other. nTopGenes is the number of genes selected per cell type, and nTopGenePairs is the number of gene-pairs per cell type selected as predictors to train the Random forest. Once the gene-pairs have been defined, PySCN randomly generates n_rand top-scoring pair profiles to serve as a random class.</p>"},{"location":"notebooks/quickstart.html#classify-the-held-out-cells","title":"Classify the held out cells\u00b6","text":"<p><code>cl.classify_anndata</code> adds the SCN_class_argmax column to the query anndata.obs. This is the cell type label that received the most votes from the Random forest classifier. The scores (or proportion of votes) are stored as a matrix in .obsm['SCN_score']. We can visualize these scores as a heatmap. (NB color block at bottom not synchronized with <code>clf['ctColors']</code> because <code>sc.pl.heatmap</code>, which is called by <code>cn.pl.heatmap_scores</code> does not pull colors from <code>adata.uns['SCN_class_argmax_colors']</code>).</p>"},{"location":"notebooks/quickstart.html#assess-performance","title":"Assess performance\u00b6","text":"<p><code>cl.create_classifier_report</code> compares predicted labels in the SCN_class_argmax obs column to the ground truth labels in the cell_type obs column to compute Precision, Recall and F1-scores.</p>"},{"location":"notebooks/quickstart.html#classify-query-data","title":"Classify query data\u00b6","text":""},{"location":"notebooks/quickstart.html#compare-cell-type-proportions","title":"Compare cell type proportions\u00b6","text":"<p>Training the classifier will assign colors to cell types that can be used in other functions to make coloring consistent across figures. The colors are stored in then be accessed in <code>clf['ctColors']</code>.</p>"},{"location":"notebooks/train_classifier.html","title":"Train, assess, and use pySCN classifier","text":"In\u00a0[1]: Copied! <pre>import pandas as pd\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport scanpy as sc\nimport scipy as sp\nimport numpy as np\nimport anndata\nimport pySingleCellNet as pySCN\nimport igraph as ig\nfrom joblib import dump, load\nimport sys\n\nsc.settings.verbosity = 3 \nsc.logging.print_header()\n</pre> import pandas as pd import matplotlib import matplotlib.pyplot as plt import seaborn as sns import scanpy as sc import scipy as sp import numpy as np import anndata import pySingleCellNet as pySCN import igraph as ig from joblib import dump, load import sys  sc.settings.verbosity = 3  sc.logging.print_header() <pre>/opt/homebrew/Caskroom/miniforge/base/envs/simple_pyscn/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n</pre> <pre>scanpy==1.10.0 anndata==0.10.6 umap==0.5.5 numpy==1.26.4 scipy==1.12.0 pandas==2.2.1 scikit-learn==1.4.1.post1 statsmodels==0.14.1 igraph==0.11.4 pynndescent==0.5.12\n</pre> In\u00a0[2]: Copied! <pre>adRef = sc.read_h5ad(\"../../data/adPBMC_ref_040623.h5ad\")\nadQ1 = sc.read_h5ad(\"../../data/adPBMC_query_1_20k_HT_040723.h5ad\")\n</pre> adRef = sc.read_h5ad(\"../../data/adPBMC_ref_040623.h5ad\") adQ1 = sc.read_h5ad(\"../../data/adPBMC_query_1_20k_HT_040723.h5ad\") In\u00a0[3]: Copied! <pre>pySCN.limit_anndata_to_common_genes([adRef, adQ1])\n</pre> pySCN.limit_anndata_to_common_genes([adRef, adQ1]) In\u00a0[4]: Copied! <pre>adTrain, adHeldOut = pySCN.splitCommonAnnData(adRef, ncells=50,dLevel=\"cell_type\")\n</pre> adTrain, adHeldOut = pySCN.splitCommonAnnData(adRef, ncells=50,dLevel=\"cell_type\") <pre>CD4 T cell : \n3554\nB cell : \n1450\nMegakaryocyte : \n59\nFCGR3A monocyte : \n327\nCD8 T cell : \n1029\nNK cell : \n608\nCD14 monocyte : \n3128\nDendritic : \n154\n</pre> <p>Now, we will train the pySCN classifier.</p> In\u00a0[5]: Copied! <pre>clf = pySCN.scn_train(adTrain, dLevel = 'cell_type', nTopGenes = 200, nTopGenePairs = 200, nRand = 100, nTrees = 1000, stratify=False, propOther=0.4)\n</pre> clf = pySCN.scn_train(adTrain, dLevel = 'cell_type', nTopGenes = 200, nTopGenePairs = 200, nRand = 100, nTrees = 1000, stratify=False, propOther=0.4) <pre>normalizing by total count per cell\n    finished (0:00:00): normalized adata.X and added    'n_counts', counts per cell before normalization (adata.obs)\nHVG\nextracting highly variable genes\n    finished (0:00:00)\n--&gt; added\n    'highly_variable', boolean vector (adata.var)\n    'means', float vector (adata.var)\n    'dispersions', float vector (adata.var)\n    'dispersions_norm', float vector (adata.var)\n... as `zero_center=True`, sparse input is densified and may lead to large memory consumption\nMatrix normalized\nranking genes\n    finished: added to `.uns['rank_genes_groups']`\n    'names', sorted np.recarray to be indexed by group ids\n    'scores', sorted np.recarray to be indexed by group ids\n    'logfoldchanges', sorted np.recarray to be indexed by group ids\n    'pvals', sorted np.recarray to be indexed by group ids\n    'pvals_adj', sorted np.recarray to be indexed by group ids (0:00:00)\nThere are  1096  classification genes\n\nB cell\nCD14 monocyte\nCD4 T cell\nCD8 T cell\nDendritic\nFCGR3A monocyte\nMegakaryocyte\nNK cell\nThere are 6042 top gene pairs\n\nFinished pair transforming the data\n\n</pre> In\u00a0[6]: Copied! <pre>pySCN.scn_classify(adHeldOut, clf, nrand = 0)\npySCN.barplot_classifier_f1(adHeldOut, ground_truth=\"cell_type\", class_prediction=\"SCN_class\")\n</pre> pySCN.scn_classify(adHeldOut, clf, nrand = 0) pySCN.barplot_classifier_f1(adHeldOut, ground_truth=\"cell_type\", class_prediction=\"SCN_class\") <pre>0.9967753493371552\n0.9833305826043902\n0.9576460098082925\n0.8952110004741584\n0.9107142857142857\n0.8722044728434505\n0.4864864864864865\n0.9655781112091791\n</pre> In\u00a0[7]: Copied! <pre>pySCN.scn_classify(adQ1, clf, nrand = 0)\n\n# Note that the \"cell_type\" obs is derived from manual annotation based on marker expression. \npySCN.heatmap_scores(adQ1, groupby='cell_type')\n</pre> pySCN.scn_classify(adQ1, clf, nrand = 0)  # Note that the \"cell_type\" obs is derived from manual annotation based on marker expression.  pySCN.heatmap_scores(adQ1, groupby='cell_type') <p>We can also arrange the cells based on the cell type in which the received the highest classification score (softmax).</p> In\u00a0[8]: Copied! <pre>pySCN.heatmap_scores(adQ1, groupby='SCN_class')\n</pre> pySCN.heatmap_scores(adQ1, groupby='SCN_class') <p>We can embed the query data and see how SCN classification and SCN scores are distributed across clusters</p> In\u00a0[10]: Copied! <pre>adQ1_norm = pySCN.norm_hvg_scale_pca(adQ1)\n\nnpcs = 11\nsc.pp.neighbors(adQ1_norm, n_neighbors=25, n_pcs=npcs)\nsc.tl.leiden(adQ1_norm,.1)\n\nsc.tl.paga(adQ1_norm)\nsc.pl.paga(adQ1_norm, plot=False)\nsc.tl.umap(adQ1_norm, 0.25, init_pos='paga')\n\nplt.rcdefaults()\n# plt.subplots(layout=\"constrained\")\n#plt.rcParams.update({\"figure.autolayout\": True})\nsc.pl.umap(adQ1_norm,color=['SCN_class', 'cell_type'], alpha=.75, s=10)\n</pre> adQ1_norm = pySCN.norm_hvg_scale_pca(adQ1)  npcs = 11 sc.pp.neighbors(adQ1_norm, n_neighbors=25, n_pcs=npcs) sc.tl.leiden(adQ1_norm,.1)  sc.tl.paga(adQ1_norm) sc.pl.paga(adQ1_norm, plot=False) sc.tl.umap(adQ1_norm, 0.25, init_pos='paga')  plt.rcdefaults() # plt.subplots(layout=\"constrained\") #plt.rcParams.update({\"figure.autolayout\": True}) sc.pl.umap(adQ1_norm,color=['SCN_class', 'cell_type'], alpha=.75, s=10) <pre>normalizing counts per cell\n    finished (0:00:00)\nextracting highly variable genes\n    finished (0:00:02)\n--&gt; added\n    'highly_variable', boolean vector (adata.var)\n    'means', float vector (adata.var)\n    'dispersions', float vector (adata.var)\n    'dispersions_norm', float vector (adata.var)\ncomputing PCA\n    with n_comps=100\n    finished (0:00:07)\ncomputing neighbors\n    using 'X_pca' with n_pcs = 11\n    finished: added to `.uns['neighbors']`\n    `.obsp['distances']`, distances for each pair of neighbors\n    `.obsp['connectivities']`, weighted adjacency matrix (0:00:02)\nrunning Leiden clustering\n    finished: found 6 clusters and added\n    'leiden', the cluster labels (adata.obs, categorical) (0:00:06)\nrunning PAGA\n    finished: added\n    'paga/connectivities', connectivities adjacency (adata.uns)\n    'paga/connectivities_tree', connectivities subtree (adata.uns) (0:00:00)\n--&gt; added 'pos', the PAGA positions (adata.uns['paga'])\ncomputing UMAP\n    finished: added\n    'X_umap', UMAP coordinates (adata.obsm) (0:00:10)\n</pre> <p>Examining the SCN_score can help to explain why there are differences in the manual annotation and pySCN classification in the CD8 T cells and NK cell groups.</p> In\u00a0[11]: Copied! <pre>pySCN.umap_scores(adQ1_norm, [\"CD8 T cell\", \"NK cell\"])\n</pre> pySCN.umap_scores(adQ1_norm, [\"CD8 T cell\", \"NK cell\"]) In\u00a0[12]: Copied! <pre>pySCN.plot_cell_type_proportions([adHeldOut,adQ1_norm], obs_column = \"SCN_class\", labels=[\"HeldOut\", \"Query\"])\n</pre> pySCN.plot_cell_type_proportions([adHeldOut,adQ1_norm], obs_column = \"SCN_class\", labels=[\"HeldOut\", \"Query\"]) In\u00a0[14]: Copied! <pre>adRef = sc.read_h5ad(\"../../data/adPBMC_ref_040623.h5ad\")\nadQ1 = sc.read_h5ad(\"../../data/adPBMC_query_1_20k_HT_040723.h5ad\")\n\nadRef_Norm = pySCN.norm_hvg_scale_pca(adRef)\ntopgenes = pySCN.top_genes_pca(adRef_Norm, n_pcs=7, top_x_genes = 10)\nlen(topgenes)\n</pre> adRef = sc.read_h5ad(\"../../data/adPBMC_ref_040623.h5ad\") adQ1 = sc.read_h5ad(\"../../data/adPBMC_query_1_20k_HT_040723.h5ad\")  adRef_Norm = pySCN.norm_hvg_scale_pca(adRef) topgenes = pySCN.top_genes_pca(adRef_Norm, n_pcs=7, top_x_genes = 10) len(topgenes) <pre>normalizing counts per cell\n    finished (0:00:00)\nextracting highly variable genes\n    finished (0:00:00)\n--&gt; added\n    'highly_variable', boolean vector (adata.var)\n    'means', float vector (adata.var)\n    'dispersions', float vector (adata.var)\n    'dispersions_norm', float vector (adata.var)\ncomputing PCA\n    with n_comps=100\n    finished (0:00:03)\n</pre> Out[14]: <pre>54</pre> In\u00a0[16]: Copied! <pre>adRef = adRef[:,topgenes].copy()\npySCN.limit_anndata_to_common_genes([adRef, adQ1])\n\nadTrain, adHeldOut = pySCN.splitCommonAnnData(adRef, ncells=50,dLevel=\"cell_type\")\nclf_rank = pySCN.train_rank_classifier(adTrain, dLevel=\"cell_type\")\npySCN.rank_classify(adHeldOut, clf_rank)\npySCN.heatmap_scores(adHeldOut, groupby='SCN_class')\n</pre> adRef = adRef[:,topgenes].copy() pySCN.limit_anndata_to_common_genes([adRef, adQ1])  adTrain, adHeldOut = pySCN.splitCommonAnnData(adRef, ncells=50,dLevel=\"cell_type\") clf_rank = pySCN.train_rank_classifier(adTrain, dLevel=\"cell_type\") pySCN.rank_classify(adHeldOut, clf_rank) pySCN.heatmap_scores(adHeldOut, groupby='SCN_class') <pre>CD4 T cell : \n3554\nB cell : \n1450\nMegakaryocyte : \n59\nFCGR3A monocyte : \n327\nCD8 T cell : \n1029\nNK cell : \n608\nCD14 monocyte : \n3128\nDendritic : \n154\n</pre> In\u00a0[17]: Copied! <pre>pySCN.barplot_classifier_f1(adHeldOut, ground_truth=\"cell_type\", class_prediction=\"SCN_class\")\n</pre> pySCN.barplot_classifier_f1(adHeldOut, ground_truth=\"cell_type\", class_prediction=\"SCN_class\")  <pre>0.998211091234347\n0.9823228151329919\n0.9638483104618563\n0.8880631676730144\n0.7157894736842105\n0.9551724137931035\n0.5142857142857142\n0.9830508474576272\n</pre> In\u00a0[18]: Copied! <pre>pySCN.rank_classify(adQ1, clf_rank)\npySCN.heatmap_scores(adQ1, groupby='SCN_class')\n</pre> pySCN.rank_classify(adQ1, clf_rank) pySCN.heatmap_scores(adQ1, groupby='SCN_class') In\u00a0[19]: Copied! <pre>pySCN.plot_cell_type_proportions([adHeldOut,adQ1], obs_column = \"SCN_class\", labels=[\"HeldOut\", \"Query\"])\n</pre> pySCN.plot_cell_type_proportions([adHeldOut,adQ1], obs_column = \"SCN_class\", labels=[\"HeldOut\", \"Query\"]) In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"notebooks/train_classifier.html#train-assess-and-use-pyscn-classifier","title":"Train, assess, and use pySCN classifier\u00b6","text":"<p>In this brief tutorial, we show you how to train a pySCN classifier, assess its performance, and use it to predict the cell type of independent data.</p>"},{"location":"notebooks/train_classifier.html#data","title":"Data\u00b6","text":"<p>We will use the training data that was processed in the prepare training data tutorial. And we will use another PBMC data as the query data:</p> <ul> <li>h5ad file of the query data</li> <li>20k Human PBMCs, 3' HT v3.1, Chromium X</li> <li>Sourced from a healthy female donor</li> <li>23,837 cells</li> <li>35,000 reads per cell</li> <li>Filtered data in .h5 format</li> <li>original file from 10X</li> </ul>"},{"location":"notebooks/train_classifier.html#load-packages","title":"Load packages\u00b6","text":""},{"location":"notebooks/train_classifier.html#load-data","title":"Load data\u00b6","text":"<p>:::{important} pySCN assumes that the expression estimates are in their raw, un-transformed state. While a shifted log normalization should not be a detriment to classifier performance, inputing scaled data will reduce performance. :::</p>"},{"location":"notebooks/train_classifier.html#limit-to-genes-shared-in-both-data-sets","title":"Limit to genes shared in both data sets\u00b6","text":""},{"location":"notebooks/train_classifier.html#train-classifier","title":"Train classifier\u00b6","text":"<p>First, we will split the reference data into the training set made up of equal numbers of cells per cell type, and a held out data set.</p>"},{"location":"notebooks/train_classifier.html#classify-held-out-data-and-assess","title":"Classify held out data and assess\u00b6","text":""},{"location":"notebooks/train_classifier.html#classify-query-data","title":"Classify query data\u00b6","text":""},{"location":"notebooks/train_classifier.html#cell-type-composition","title":"Cell type composition\u00b6","text":"<p>We can visualize the cell type composition of samples as follows:</p>"},{"location":"notebooks/train_classifier.html#rank-based-classifier","title":"Rank-based classifier\u00b6","text":"<p>Sometimes it is useful to skip the Top-scoring pair transformation. Below, we show how you can use pySCN using rank-transformed expression data after limiting the set of predictors to genes associated with the first x principal components.</p>"}]}